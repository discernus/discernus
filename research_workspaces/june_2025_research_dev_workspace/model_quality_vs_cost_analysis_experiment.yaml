# =============================================================================
# MODEL QUALITY vs COST ANALYSIS EXPERIMENT (v3.1 Format)
# =============================================================================
# Strategic experiment to determine if cheap high-TPM models provide sufficient
# quality vs flagship models for narrative analysis - avoiding LiteLLM complexity

experiment_meta:
  name: "Model_Quality_vs_Cost_Analysis_Experiment"
  version: "v1.0.0"
  created: "2025-06-25T16:00:00Z"
  description: "Strategic experiment to determine if cheap high-TPM models (GPT-3.5-turbo, Claude Haiku) provide sufficient quality vs flagship models (GPT-4o, Claude Sonnet) for narrative analysis"
  hypothesis: "Cheap models with high TPM limits provide sufficient quality for academic research, eliminating need for complex LiteLLM architecture"
  research_context: "Critical decision point: Build simple high-throughput system vs complex multi-tier architecture"
  principal_investigator: "Discernus Research Team"
  institution: "Discernus Research Lab"
  ethical_clearance: "ACADEMIC-2025-COST-001"
  funding_source: "Internal Development"
  data_classification: "research"
  publication_intent: true
  tags: ["model_comparison", "cost_analysis", "tpm_testing", "flagship_vs_throughput", "academic_feasibility"]
  
  research_question: "Do flagship models (GPT-4o, Claude Sonnet) provide sufficient quality improvement over high-TPM models (GPT-3.5-turbo, Claude Haiku) to justify 10-20x higher cost and TPM complexity?"
  
  hypotheses:
    - "Cheap models (GPT-3.5-turbo, Claude Haiku) achieve >85% quality of premium models across text sizes"
    - "Premium models show significant quality advantage only on extra-large texts (>15K tokens)"
    - "TPM constraints create practical limitations for premium models in large-scale research"
    - "Cost per quality point favors cheap models for most academic use cases"
  
  success_criteria:
    - "Clear quality differentiation between cheap and premium models measured"
    - "Cost per quality point calculated for academic decision framework"
    - "TPM boundary effects identified and quantified"
    - "Actionable architecture recommendations generated for each academic use case"

components:
  frameworks:
    - id: "moral_foundations_theory"
      version: "v2025.06.19"
      type: "file_path"
      file_path: "research_workspaces/june_2025_research_dev_workspace/frameworks/moral_foundations_theory/moral_foundations_theory_framework.yaml"
      
  prompt_templates:
    - id: "moral_foundations_analysis"
      version: "v1.0"
      type: "workspace_asset"
      file_path: "research_workspaces/june_2025_research_dev_workspace/prompt_templates/moral_foundations_analysis/template.yaml"
      
  weighting_schemes:
    - id: "foundation_pairs"
      version: "v1.0"
      type: "workspace_asset"
      file_path: "research_workspaces/june_2025_research_dev_workspace/weighting_schemes/foundation_pairs/scheme.yaml"
      
  models:
    - id: "gpt-3.5-turbo"
      provider: "openai"
      version: "latest"
      
    - id: "claude-3-5-haiku"
      provider: "anthropic"
      version: "20241022"
      
    - id: "gpt-4o"
      provider: "openai"
      version: "2024-05-13"
      
    - id: "claude-3-5-sonnet"
      provider: "anthropic"
      version: "20241022"
      
  corpus:
    # Conservative and Progressive dignity collections for model comparison
    - id: "conservative_dignity"
      type: "file_collection"
      file_path: "corpus/validation_set/conservative_dignity"
      pattern: "*.txt"
      description: "Conservative dignity texts - includes Reagan Challenger address (1,153 tokens)"
      
    - id: "progressive_dignity"
      type: "file_collection"
      file_path: "corpus/validation_set/progressive_dignity"
      pattern: "*.txt"
      description: "Progressive dignity texts - includes Obama 2004 DNC keynote (3,272 tokens)"

execution:
  description: "Systematic comparison of cheap high-TPM vs premium flagship models across text sizes"
  
  matrix:
    # Phase 1: Baseline Validation with conservative texts
    - run_id: "gpt35_conservative_dignity"
      description: "GPT-3.5-turbo - conservative dignity texts (high TPM model)"
      framework: "moral_foundations_theory"
      prompt_template: "moral_foundations_analysis"
      weighting_scheme: "foundation_pairs"
      model: "gpt-3.5-turbo"
      corpus_subset: "conservative_dignity"
      
    - run_id: "claude_haiku_conservative_dignity"
      description: "Claude Haiku - conservative dignity texts (high TPM model)"
      framework: "moral_foundations_theory"
      prompt_template: "moral_foundations_analysis"
      weighting_scheme: "foundation_pairs"
      model: "claude-3-5-haiku"
      corpus_subset: "conservative_dignity"
      
    - run_id: "gpt4o_conservative_dignity"
      description: "GPT-4o - conservative dignity texts (premium model with TPM protection)"
      framework: "moral_foundations_theory"
      prompt_template: "moral_foundations_analysis"
      weighting_scheme: "foundation_pairs"
      model: "gpt-4o"
      corpus_subset: "conservative_dignity"
      
    - run_id: "claude_sonnet_conservative_dignity"
      description: "Claude Sonnet - conservative dignity texts (premium model)"
      framework: "moral_foundations_theory"
      prompt_template: "moral_foundations_analysis"
      weighting_scheme: "foundation_pairs"
      model: "claude-3-5-sonnet"
      corpus_subset: "conservative_dignity"
      
    # Phase 2: Progressive texts for comparison
    - run_id: "gpt35_progressive_dignity"
      description: "GPT-3.5-turbo - progressive dignity texts (high TPM model)"
      framework: "moral_foundations_theory"
      prompt_template: "moral_foundations_analysis"
      weighting_scheme: "foundation_pairs"
      model: "gpt-3.5-turbo"
      corpus_subset: "progressive_dignity"
      
    - run_id: "gpt4o_progressive_dignity"
      description: "GPT-4o - progressive dignity texts (premium model with TPM protection)"
      framework: "moral_foundations_theory"
      prompt_template: "moral_foundations_analysis"
      weighting_scheme: "foundation_pairs"
      model: "gpt-4o"
      corpus_subset: "progressive_dignity"

  cost_controls:
    max_total_cost: 50.0  # Reduced for conservative approach
    cost_per_analysis_limit: 3.00
    
  quality_controls:
    min_framework_fit_score: 0.7
    enable_qa_validation: true
    require_evidence: true
    
  quality_assurance:
    enable_qa_validation: true
    confidence_threshold: 0.75
    require_evidence: true
    manual_review_triggers: ["low_confidence", "cost_anomaly", "quality_degradation"]

enhanced_analysis:
  enabled: true
  generate_html_report: true
  generate_academic_exports: true
  
  configuration:
    cost_benefit_analysis:
      enabled: true
      quality_weight: 0.4
      cost_weight: 0.3
      tpm_efficiency_weight: 0.3
      
    model_comparison_analysis:
      enabled: true
      cheap_vs_premium_comparison: true
      size_dependent_patterns: true
      academic_use_case_recommendations: true
      
    statistical_testing:
      enabled: true
      significance_level: 0.05
      tests: ["quality_comparison", "cost_efficiency", "academic_suitability"]
      
    visualizations:
      enabled: true
      types: ["cost_vs_quality_scatter", "size_comparison_plots", "model_recommendation_matrix"]

outputs:
  save_to_database: true
  export_formats: ["json", "csv", "r_data"]
  include_raw_responses: true
  include_provenance: true
  
  academic_exports:
    enabled: true
    formats: ["csv", "r_data"]
    include_replication_package: true
    
  decision_report:
    enabled: true
    include_recommendations: true
    include_cost_projections: true
    include_architecture_implications: true

validation_criteria:
  min_successful_analyses: 6  # All 6 planned analyses
  max_total_cost: 50.0
  required_quality_score: 0.70
  
  success_metrics:
    quality_differentiation: "Clear quality differences between cheap and premium models measured"
    cost_efficiency: "Cost per quality point calculated for each model"
    academic_recommendations: "Actionable recommendations for each academic use case generated"
    
  decision_outcomes:
    simple_architecture: "If cheap models score >85 across sizes → Build simple high-throughput system"
    complex_architecture: "If premium models significantly outperform → Implement LiteLLM multi-tier"
    hybrid_architecture: "If size-dependent patterns emerge → Smart routing based on complexity" 