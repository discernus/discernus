# Coordinate-Free Discourse Analysis Framework: Enhanced Ensemble Methodology
# Advancing from Manual Chatbot Interaction (sim3) to Sophisticated Ensemble API Interaction
# Direct scoring with real-time QA validation and adversarial review
#
# METHODOLOGICAL EVOLUTION: This experiment advances the coordinate-free framework
# from sim3's manual chatbot interaction to a sophisticated ensemble API approach,
# incorporating direct scoring, real-time QA validation, and adversarial review.
#
# INNOVATION FOCUS: Multi-LLM ensemble with integrated qualitative reasoning + 
# numerical scoring enables both expert-level replication and enhanced analytical insights.
#
# VALIDATION ADVANCEMENT: Moving from ad-hoc interpretation to systematic methodology
# with real-time consistency validation against expert assessments like Eduardo's T&F 2019 scores.
#
# DISCERNUS VISION: Implements "Thick LLM + Thin Software = Epistemic Trust" through
# institutionalized contestation, error tracking, and adversarial review at every stage.
#
# Version: 3.0-enhanced-direct-scoring  
# Date: 2025-07-03
# Status: Ready for enhanced ensemble testing

# ================================================================
# EXPERIMENT IDENTIFICATION
# ================================================================

experiment_name: coordinate_free_enhanced_ensemble
version: v3.0-enhanced-direct-scoring
display_name: "Coordinate-Free Discourse Analysis: Enhanced Ensemble with Direct Scoring"

description: |
  This experiment advances the coordinate-free discourse analysis framework using
  enhanced ensemble methodology with direct scoring, real-time QA validation, and
  adversarial review. LLMs provide integrated qualitative reasoning and numerical
  scoring simultaneously, enabling immediate consistency validation and superior
  analytical transparency aligned with the Discernus Epistemic Trust vision.

# ================================================================
# RESEARCH QUESTIONS & HYPOTHESES (ENHANCED METHODOLOGY)
# ================================================================

research_questions:
  primary: "Can enhanced ensemble methodology with direct scoring achieve expert-level replication while providing superior analytical capabilities?"
  
  secondary:
    - "How does direct scoring compare to post-hoc qualitative-to-quantitative conversion?"
    - "What analytical insights emerge from real-time QA validation and adversarial review?"
    - "Can integrated reasoning + scoring enable more robust validation methodology?"
    - "Does enhanced ensemble approach provide stronger epistemic trust than manual analysis?"

enhanced_hypotheses:
  # HYPOTHESES FOCUSED ON ENHANCED METHODOLOGY
  
  h1_direct_scoring_advantage:
    hypothesis: "Direct scoring will achieve higher expert correlation than post-hoc conversion"
    # RATIONALE: Integrated analysis more natural than artificial separation
    operationalization: "Direct scoring ensemble vs Eduardo's expert scores"
    measurement: "Correlation, MAE, and reasoning-score consistency validation"
    # ADVANCEMENT TEST: Demonstrate superior methodology over Stage 5 conversion
    success_criteria: "Correlation ≥ 0.75 and MAE ≤ 0.12 with high consistency scores"
  
  h2_qa_validation_effectiveness:
    hypothesis: "Real-time QA validation will identify and correct analytical inconsistencies"
    # RATIONALE: Immediate validation prevents error propagation
    operationalization: "Consistency scores between reasoning and numerical scores"
    measurement: "QA flag detection rate and escalation accuracy"
    # QA VALUE: Demonstrate systematic error detection and correction
    success_criteria: "≥95% consistency rate with meaningful escalation for genuine issues"
  
  h3_adversarial_review_value:
    hypothesis: "Adversarial review will identify meaningful alternative interpretations"
    # RATIONALE: Institutionalized contestation improves analytical robustness
    operationalization: "Alternative interpretations and minority report quality"
    measurement: "Adversarial challenge success rate and analytical depth enhancement"
    # CONTESTATION VALUE: Document systematic improvement through adversarial review
    success_criteria: "≥80% adversarial reviews provide meaningful analytical insights"
  
  h4_ensemble_reliability:
    hypothesis: "Enhanced ensemble will demonstrate superior analytical stability"
    # RATIONALE: QA-weighted aggregation more reliable than simple averaging
    operationalization: "QA-weighted ensemble scores vs unweighted scores"
    measurement: "Inter-model agreement and confidence interval analysis"
    # RELIABILITY TEST: Demonstrate enhanced stability through QA weighting
    success_criteria: "Higher inter-rater reliability and narrower confidence intervals"
  
  h5_epistemic_trust:
    hypothesis: "Enhanced methodology will demonstrate superior epistemic trust characteristics"
    # RATIONALE: Transparency, contestation, and error tracking build trust
    operationalization: "Explainability, auditability, and error detection capabilities"
    measurement: "Transparency metrics, error detection rate, and analytical traceability"
    # TRUST VALUE: Demonstrate alignment with Discernus epistemic trust vision
    success_criteria: "Full analytical traceability with systematic error detection and correction"

# ================================================================
# ENHANCED EXPERIMENTAL DESIGN
# ================================================================

experimental_design:
  design_type: "Enhanced multi-LLM ensemble with direct scoring and real-time QA validation"
  # DESIGN RATIONALE: Integrate reasoning + scoring for superior methodology
  
  corpus_description:
    source: "Tamaki & Fuks (2019) Bolsonaro campaign speech corpus subset"
    # CORPUS RATIONALE: Same speeches as Eduardo's expert analysis for direct comparison
    temporal_scope: "August-October 2018 Brazilian presidential campaign"
    # TEMPORAL LOGIC: Campaign progression enables contextual analysis validation
    speech_count: "7 speeches (cleaned corpus for methodological advancement)"
    # OPTIMIZED SIZE: Focused corpus for methodological development and validation
    validation_benchmark: "Eduardo Tamaki expert populism scores (0.0-1.0 scale)"
    # REPLICATION TARGET: Expert-level performance with enhanced capabilities
    
  enhanced_methodology:
    from_approach: "Post-hoc qualitative-to-quantitative conversion (Stage 5)"
    to_approach: "Direct integrated reasoning + scoring with real-time QA validation"
    # METHODOLOGICAL SHIFT: From artificial separation to natural integration
    
    ensemble_architecture:
      primary_models: ["claude-3-sonnet", "gpt-4o", "claude-3-haiku"]
      qc_model: "gpt-4o-mini"  # Real-time QA validation
      adversarial_model: "claude-3-opus"  # Adversarial review and challenge
      research_referee: "gpt-4o"  # Consensus evaluation and synthesis
      context_isolation: "Fresh conversation per analysis for analytical independence"
      qa_integration: "Real-time consistency validation and error detection"
      adversarial_protocol: "Systematic challenge and alternative interpretation generation"
    
    enhanced_stage_sequence:
      stage_1: "Discovery Analysis - Comprehensive theme identification"
      stage_2a: "Integrated Populism Assessment - Simultaneous reasoning + scoring"  
      stage_2b: "Real-time QA Validation - Consistency checking and error detection"
      stage_2c: "Adversarial Review - Challenge and alternative interpretation"
      stage_3: "Ensemble Aggregation - QA-weighted scoring with minority reports"
      stage_4: "Research Referee Synthesis - Consensus evaluation and final validation"
    # ENHANCED WORKFLOW: Integrated analysis with systematic validation and contestation

# ================================================================
# DISCERNUS VISION ALIGNMENT
# ================================================================

discernus_alignment:
  epistemic_trust_implementation:
    thick_llm_components:
      - "Integrated qualitative reasoning and numerical scoring"
      - "Real-time QA validation with consistency checking"
      - "Adversarial review with systematic challenge protocols"
      - "Research referee synthesis with consensus evaluation"
      - "Minority report generation for meaningful disagreement"
    
    thin_software_orchestration:
      - "Lightweight coordination of sophisticated LLM reasoning"
      - "Systematic aggregation without algorithmic replacement"
      - "Transparent logging and auditability infrastructure"
      - "Error detection and escalation protocols"
      - "Database integration for multi-stage result capture"
    
    radical_transparency:
      - "Full reasoning-to-scoring pipeline visibility"
      - "Explicit evidence citations and uncertainty acknowledgment"
      - "Complete audit trail from individual analysis to ensemble result"
      - "Error detection logs and correction documentation"
      - "Minority report preservation and analysis"
    
    institutionalized_contestation:
      - "Built-in adversarial review at every stage"
      - "Systematic challenge of assumptions and interpretations"
      - "Alternative interpretation identification and documentation"
      - "Minority report protocols for significant disagreement"
      - "Escalation procedures for analytical complexity"

# ================================================================
# ENHANCED ANALYTICAL CAPABILITIES
# ================================================================

analytical_enhancements:
  description: "Superior analytical capabilities through enhanced ensemble methodology"
  
  direct_scoring_advantages:
    integrated_analysis: "Natural combination of reasoning and scoring eliminates conversion artifacts"
    real_time_validation: "Immediate consistency checking prevents error propagation"
    enhanced_transparency: "Direct observation of LLM reasoning-to-scoring process"
    stronger_validation: "Simultaneous validation of both reasoning quality and scoring accuracy"
    
  qa_validation_capabilities:
    consistency_checking: "Real-time validation of reasoning-score alignment"
    confidence_calibration: "Assessment of claimed confidence vs actual accuracy"
    evidence_validation: "Verification of qualitative claims against textual evidence"
    escalation_protocols: "Systematic flagging of analytical complexity and uncertainty"
    
  adversarial_review_benefits:
    systematic_challenge: "Built-in questioning of assumptions and interpretations"
    alternative_perspectives: "Identification of competing analytical frameworks"
    blind_spot_detection: "Systematic identification of potential analytical biases"
    minority_report_generation: "Documentation of meaningful disagreement and complexity"
    
  ensemble_sophistication:
    qa_weighted_aggregation: "Ensemble scores weighted by reasoning quality and consistency"
    multi_dimensional_validation: "Validation across reasoning, scoring, and consistency dimensions"
    enhanced_reliability: "Superior stability through systematic quality assessment"
    epistemic_transparency: "Full analytical pipeline visibility and auditability"

# ================================================================
# DATABASE SCHEMA REQUIREMENTS
# ================================================================

database_requirements:
  description: "Enhanced schema to capture multi-stage ensemble analysis results"
  
  new_tables_required:
    ensemble_analysis_stages:
      purpose: "Capture individual LLM stage-by-stage results"
      key_fields: ["qualitative_assessment", "numerical_score", "confidence_level", "consistency_score"]
      
    qa_validation_results:
      purpose: "Track real-time QA validation outcomes"
      key_fields: ["reasoning_quality_score", "evidence_support_score", "consistency_score", "qa_flags"]
      
    adversarial_review_results:
      purpose: "Document adversarial challenges and alternative interpretations"
      key_fields: ["adversarial_findings", "alternative_interpretations", "challenge_success_rate"]
      
    ensemble_aggregations:
      purpose: "Store ensemble results with QA weighting and minority reports"
      key_fields: ["individual_scores", "qa_weights", "ensemble_score", "minority_report"]
      
    research_referee_synthesis:
      purpose: "Capture final consensus evaluation and validation"
      key_fields: ["consensus_assessment", "epistemic_confidence", "final_validation"]

# ================================================================
# ENHANCED SUCCESS CRITERIA
# ================================================================

success_criteria:
  # SUCCESS CRITERIA: Demonstrate enhanced methodology superiority
  
  direct_scoring_validation:
    - "REQUIRED: Correlation ≥ 0.75 with Eduardo's expert scores (higher than conversion approach)"
    - "TARGET: MAE ≤ 0.12 demonstrating superior accuracy"
    - "CRITICAL: ≥95% reasoning-score consistency validation"
    - "MEASUREMENT: Statistical agreement with enhanced consistency metrics"
    
  qa_validation_effectiveness:
    - "REQUIRED: ≥95% consistency rate between reasoning and scoring"
    - "TARGET: Meaningful escalation for genuine analytical complexity"
    - "CRITICAL: Real-time error detection and correction capability"
    - "MEASUREMENT: QA flag accuracy and escalation appropriateness"
    
  adversarial_review_value:
    - "REQUIRED: ≥80% adversarial reviews provide meaningful analytical insights"
    - "TARGET: Systematic identification of alternative interpretations"
    - "CRITICAL: Demonstrated improvement in analytical robustness"
    - "MEASUREMENT: Alternative interpretation quality and challenge success rate"
    
  ensemble_reliability:
    - "REQUIRED: Higher analytical stability than unweighted approaches"
    - "TARGET: QA-weighted aggregation demonstrates superior reliability"
    - "CRITICAL: Narrow confidence intervals with high inter-model agreement"
    - "MEASUREMENT: Enhanced reliability metrics and stability analysis"
    
  epistemic_trust_demonstration:
    - "REQUIRED: Full analytical traceability and auditability"
    - "TARGET: Systematic error detection and correction capability"
    - "CRITICAL: Alignment with Discernus Thick LLM + Thin Software vision"
    - "MEASUREMENT: Transparency metrics, error detection rate, and trust indicators"

# ================================================================
# ENHANCED IMPLEMENTATION PLAN
# ================================================================

implementation_plan:
  phase_1_direct_scoring:
    description: "Implement enhanced prompts with direct scoring"
    deliverables: ["integrated_assessment_prompts", "direct_scoring_validation"]
    success_metrics: ["reasoning_score_consistency", "expert_correlation_improvement"]
    
  phase_2_qa_integration:
    description: "Add real-time QA validation layers"
    deliverables: ["qa_validation_system", "consistency_checking_protocols"]
    success_metrics: ["qa_flag_accuracy", "error_detection_rate"]
    
  phase_3_adversarial_review:
    description: "Integrate adversarial review and challenge protocols"
    deliverables: ["adversarial_llm_integration", "minority_report_system"]
    success_metrics: ["challenge_success_rate", "alternative_interpretation_quality"]
    
  phase_4_database_enhancement:
    description: "Implement enhanced database schema for multi-stage results"
    deliverables: ["enhanced_schema", "multi_stage_data_capture"]
    success_metrics: ["data_completeness", "analytical_traceability"]
    
  phase_5_full_validation:
    description: "Comprehensive validation against expert scores and methodology comparison"
    deliverables: ["expert_validation_study", "methodology_comparison_analysis"]
    success_metrics: ["enhanced_correlation", "epistemic_trust_demonstration"]

# ================================================================
# PROTOTYPE STATUS
# ================================================================

prototype_status:
  corpus_preparation: "COMPLETE - 7 speeches optimized for enhanced methodology testing"
  validation_data: "COMPLETE - Eduardo scores for expert replication target"
  direct_scoring_demo: "COMPLETE - Demonstration of enhanced approach implemented"
  enhanced_methodology: "COMPLETE - Direct scoring with QA validation designed"
  database_schema: "PENDING - Enhanced schema for multi-stage results"
  full_ensemble_orchestrator: "PENDING - Complete Discernus vision implementation"
  comprehensive_validation: "PENDING - Expert validation with enhanced metrics"
  
ready_for_enhancement: true
methodological_advancement: "From post-hoc conversion to direct scoring with real-time QA validation"
innovation_focus: "Integrated reasoning + scoring with adversarial review and epistemic trust"
core_contribution: "Enhanced ensemble methodology aligned with Discernus Thick LLM + Thin Software vision"
validation_target: "Superior expert replication with enhanced analytical capabilities and epistemic trust" 