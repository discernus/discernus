# Narrative Gravity Wells - Cursor AI Assistant Rules
# This file provides consistent guidance for AI assistants working on this project

## Project Organization Philosophy

### Root Directory Standards
ONLY place these file types in the root directory:
- **Operational files**: README.md, CHANGELOG.md, LICENSE
- **Launch/access tools**: launch.py, launch_streamlit.py, check_database.py
- **Configuration**: requirements.txt, env.example, alembic.ini, pytest.ini
- **Build/deploy**: .gitignore, setup.py (if needed)

NEVER place in root:
- Analysis results (→ analysis_results/)
- Test files (→ tests/)
- Utility scripts (→ scripts/)
- Documentation (→ docs/)
- Temporary files (→ tmp/YYYY_MM_DD/)

### Documentation Organization
- **docs/architecture/**: All architectural documentation
- **docs/user-guides/**: End-user focused guides
- **docs/development/**: Developer/contributor guides
- **docs/api/**: API documentation
- **Root level docs**: Only operational guides (LAUNCH_GUIDE.md)

### Research Data Organization
- **exports/academic_formats/**: Research data exports for external analysis
  - R scripts with pre-written statistical analysis
  - CSV/Parquet files formatted for academic tools (R, Python, Stata)
  - Timestamped exports for version tracking
  - Publication-ready datasets with analysis code

### Package Structure Standards
Follow Python packaging standards:
- **src/narrative_gravity/**: Main package with proper __init__.py files
- **Use relative imports**: Within package modules
- **Absolute imports**: For external modules and when executed directly
- **Import compatibility**: Support both direct execution and module imports

## Database Architecture (CRITICAL)

### Default Database Assumptions
- **PRIMARY DATABASE**: Always PostgreSQL for application data
- **SQLite usage**: ONLY for unit testing (in-memory) and logging fallback
- **Connection**: postgresql://postgres:postgres@localhost:5432/narrative_gravity

### Database Rules
1. **NEVER assume SQLite** for main application data
2. **PostgreSQL for**: Main app, API server, Celery workers, production
3. **SQLite for**: Unit tests (`:memory:`), logging fallback (`logs/narrative_gravity_stats.db`)
4. **Reference**: docs/architecture/database_architecture.md for details

### Database Troubleshooting
When database issues arise:
1. Check PostgreSQL connection first
2. Reference `python check_database.py`
3. Setup with `python launch.py --setup-db`
4. Point to docs/architecture/database_architecture.md

## Service Architecture

### Port Allocation
- **3000**: React Research Workbench (main interface)
- **8000**: FastAPI server (REST API + docs at /api/docs)
- **8002**: Chainlit Chat Interface (conversational analysis)  
- **5432**: PostgreSQL database
- **6379**: Redis (if using Celery)
- **8501**: Streamlit UI (DEPRECATED - moved to archive/)

### Launch Patterns
- **Backend services**: `python launch.py`
- **React frontend**: `cd frontend && npm run dev`
- **Individual services**: Use --api-only, --celery-only, --chainlit-only flags
- **Frontend info**: `python launch.py --frontend-info`
- **Database setup**: `python launch.py --setup-db`

## Development Environment Setup (CRITICAL)

### Path Configuration Requirements
**ALWAYS set up the development environment before running Python commands:**

#### Mandatory Setup for Each Session
```bash
# Activate virtual environment (if not already active)
source venv/bin/activate

# Setup development paths (REQUIRED)
source scripts/setup_dev_env.sh
```

#### Why This is Critical
The project uses `src/narrative_gravity/` structure, but `src/` is not automatically in Python's module search path. Without proper setup:
- ❌ `from narrative_gravity.engine import NarrativeGravityWellsElliptical` fails
- ❌ AI assistants struggle with import paths
- ❌ Inconsistent working directory problems

#### Environment Variables Set by setup_dev_env.sh
- `PROJECT_ROOT`: `/Users/jeffwhatcott/narrative_gravity_analysis`
- `PYTHONPATH`: Includes project root AND `src/` directory
- `NARRATIVE_GRAVITY_*`: Helper variables for scripts
- Automatically loads all `.env` variables

#### Verification Commands
**Before running any Python code, verify setup:**
```bash
python3 -c "from src.narrative_gravity.engine import NarrativeGravityWellsElliptical; print('✅ Imports working!')"
```

#### Import Pattern Standards
**After environment setup, use these patterns:**
```python
# Preferred (works after setup)
from src.narrative_gravity.engine import NarrativeGravityWellsElliptical
from src.narrative_gravity.framework_manager import FrameworkManager

# Also works (shorter)
from narrative_gravity.engine import NarrativeGravityWellsElliptical
```

#### Troubleshooting Import Issues
1. **First step**: Always run `source scripts/setup_dev_env.sh`
2. **Verify PYTHONPATH**: Check that `src/` is in Python path
3. **Reference**: DEV_ENVIRONMENT.md for detailed setup guide
4. **Never guess paths**: Use the established environment setup

#### Critical Command Consistency Rules
**ALWAYS follow these patterns to avoid environment issues:**
- **Use `python3`** (never `python` - it may not exist)
- **Use `pip3`** (or `pip` only AFTER confirming venv is active)
- **Verify venv activation** before pip installs
- **Check import availability** before claiming packages are installed
- **Environment setup is MANDATORY** - never skip `source scripts/setup_dev_env.sh`
- **ALWAYS get current date from system** - never assume dates, use `./scripts/get_current_date.sh` or `date` command
- **Terminal commands must be single line** - no newlines in `run_terminal_cmd`, use `&&` to chain commands

#### Date and Time Handling (CRITICAL)
**NEVER hardcode dates - always use system date/time:**
```bash
# Get current date for documentation
./scripts/get_current_date.sh              # Returns: June 11, 2025
./scripts/get_current_date.sh iso          # Returns: 2025-06-11
./scripts/get_current_date.sh timestamp    # Returns: 2025-06-11 08:49:35

# Or use date command directly
date "+%B %-d, %Y"                         # Returns: June 11, 2025
date "+%Y-%m-%d"                           # Returns: 2025-06-11
```

#### Common Environment Issues & Solutions
- **"command not found: python"** → Use `python3` instead
- **"command not found: pip"** → Use `pip3` or ensure venv is active
- **"alembic not found"** → Alembic installed in system, not venv - verify with setup script
- **Import failures** → Run setup script, check PYTHONPATH configuration
- **Wrong dates in files** → Always use `./scripts/get_current_date.sh` or `date` command

## Code Standards

### Import Path Updates
When files are moved, update ALL references:
- Import statements in Python files
- Documentation references
- Configuration files (alembic/env.py, etc.)
- Test files

### Change Documentation
- **ALL significant changes**: Add to CHANGELOG.md with proper versioning
- **NO separate summary files**: Use the master changelog
- **Version format**: [vX.Y.Z] - Description - YYYY-MM-DD

### Testing Standards
- **Unit tests**: Use in-memory SQLite (`:memory:`)
- **Integration tests**: Can use PostgreSQL
- **Test organization**: tests/unit/, tests/integration/, tests/utilities/

## Import Guidelines

### Package Imports (Preferred)
```python
from src.narrative_gravity.engine import NarrativeGravityWellsElliptical
from src.narrative_gravity.framework_manager import FrameworkManager
```

### Dual Import Pattern (For Streamlit compatibility)
```python
try:
    from .module import Class  # Relative import
except ImportError:
    from src.package.module import Class  # Absolute fallback
```

## Error Handling Philosophy

### User-Friendly Errors
- **Database errors**: Point to check_database.py and setup instructions
- **Import errors**: Suggest package structure fixes
- **Service errors**: Reference launch.py options and LAUNCH_GUIDE.md

### Documentation References
Always reference specific documentation:
- Database issues → docs/architecture/database_architecture.md
- Launch issues → LAUNCH_GUIDE.md
- Architecture questions → docs/architecture/
- Changes → CHANGELOG.md

## Text Data Organization

### Corpus Structure
All text data is centralized under the `corpus/` directory:
- **corpus/golden_set/**: Curated, analysis-ready datasets (standardized format)
- **corpus/raw_sources/**: Original source materials (presidential speeches, synthetic narratives)
- **corpus/processing_scripts/**: Scripts that transform raw sources into golden sets

### Examples Directory
The `examples/` directory provides demonstrations and tutorials:
- **examples/**: Demo scripts showing how to use corpus generation tools
- **Sample data files**: Example inputs in various formats (Markdown, CSV, text)
- **Generated outputs**: Demonstration of expected JSONL and schema formats
- **Purpose**: Developer onboarding, user training, tool testing

### Data Processing Philosophy
- Raw sources preserved for reference and reprocessing
- Golden sets are standardized, validated, and analysis-ready
- Processing scripts document transformation logic
- Examples directory maintains working demonstrations of tooling

## Framework Philosophy

### Modularity First
- Support multiple frameworks (civic_virtue, political_spectrum, etc.)
- Avoid hardcoded assumptions about specific frameworks
- Use framework-agnostic design patterns

### Configuration Management
- Environment variables in .env (copy from env.example)
- Framework configs in frameworks/ directory
- Database config through DATABASE_URL

## File Movement Protocols

When reorganizing files:
1. **Check dependencies**: Use grep/search to find all references
2. **Update imports**: Fix all Python import statements
3. **Update docs**: Fix all documentation references
4. **Update configs**: Fix alembic, tests, etc.
5. **Test**: Verify imports work after changes
6. **Document**: Add to CHANGELOG.md

## Release Management

### Release Process Standards
- **All releases**: Use `python scripts/release.py` for consistency
- **Pre-release requirements**: All tests pass, documentation current, git clean
- **Version types**: patch (fixes), minor (features), major (breaking changes)
- **CHANGELOG.md**: Must have [Unreleased] section for ongoing changes

### Release Commands
```bash
python scripts/release.py --dry-run patch --message "Test release"
python scripts/release.py patch --message "Bug fixes"
python scripts/release.py minor --message "New features"
python scripts/release.py major --message "Breaking changes"
```

## Quality Standards

### Before Completing Tasks
- [ ] **Setup development environment**: Run `source scripts/setup_dev_env.sh`
- [ ] **Verify imports work**: Test with verification command
- [ ] Verify PostgreSQL is primary database assumption
- [ ] Check that files are in correct directories
- [ ] Update all references when moving files
- [ ] Add significant changes to CHANGELOG.md
- [ ] Test that imports work correctly
- [ ] Ensure documentation references are accurate

### Validation Requirements (CRITICAL)
**NEVER declare victory or completion until functionality is validated through:**
- [ ] **Automated unit tests** (for individual functions/components)
- [ ] **Integration tests** (for API endpoints and database operations)
- [ ] **Playwright end-to-end tests** (for full user workflows)
- [ ] **Manual verification** of complete user scenarios

**ALL claimed functionality must be demonstrably working through automated testing before declaring success.**

### Temporary File Management
- **Temporary files**: Always use `tmp/YYYY_MM_DD/` format
- **Naming pattern**: `tmp/2025_06_09/experiment_name/`
- **Auto-cleanup**: Temporary directories older than 30 days can be removed
- **Git ignore**: All `tmp/` contents should be ignored by git

### Cleanup Philosophy
- Prefer organizing existing files over creating new ones
- Move temporary/analysis files to appropriate subdirectories
- Keep root directory minimal and purposeful
- Document changes in changelog, not separate files

This ensures consistent, professional project organization across all AI assistant interactions. 