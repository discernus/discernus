
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>CloudResearch + MTurk Validation Study Complete G - Discernus Project</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cloudresearch-mturk-validation-study-complete-gameplan" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Discernus Project" class="md-header__button md-logo" aria-label="Discernus Project" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Discernus Project
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CloudResearch + MTurk Validation Study  Complete G
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Discernus Project" class="md-nav__button md-logo" aria-label="Discernus Project" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Discernus Project
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/DOCUMENTATION_INDEX.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Documentation Index
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/CONTRIBUTING.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/platform-development/DEV_ENVIRONMENT.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Development Environment
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/CODE_ORGANIZATION_STANDARDS.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code Standards
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/platform-development/RELEASE_PROCESS.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Release Process
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#week-1-foundation-building" class="md-nav__link">
    <span class="md-ellipsis">
      Week 1: Foundation Building
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#week-2-platform-configuration-and-pilot" class="md-nav__link">
    <span class="md-ellipsis">
      Week 2: Platform Configuration and Pilot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#week-3-main-study-launch" class="md-nav__link">
    <span class="md-ellipsis">
      Week 3: Main Study Launch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#week-4-completion-and-initial-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Week 4: Completion and Initial Analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#week-5-reporting-and-documentation" class="md-nav__link">
    <span class="md-ellipsis">
      Week 5: Reporting and Documentation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-bottom-line-what-youve-achieved" class="md-nav__link">
    <span class="md-ellipsis">
      The Bottom Line: What You've Achieved
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<p><img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/></p>
<h1 id="cloudresearch-mturk-validation-study-complete-gameplan">CloudResearch + MTurk Validation Study: Complete Gameplan</h1>
<p>Picture yourself three months from now, sitting at your computer with a spreadsheet full of statistically robust data proving (or disproving) that your Civic Virtue framework aligns with human moral intuition. Here's exactly how you get there.</p>
<h2 id="week-1-foundation-building"><strong>Week 1: Foundation Building</strong></h2>
<p><strong>Monday Morning: Account Setup</strong>
You create accounts on both CloudResearch Connect and Amazon MTurk. CloudResearch's interface feels like a more sophisticated version of MTurk—cleaner, with demographic targeting that would make a pollster jealous. You upload tax documents for 1099 reporting and deposit \$300 as your initial funding.</p>
<p><strong>Tuesday-Wednesday: Codebook Development</strong>
You spend two intensive days crafting the annotation manual that will make or break your study. This isn't just definitions—it's a 12-page document with:</p>
<ul>
<li>One-paragraph definitions for each of the 10 wells</li>
<li>Example text snippets showing high vs. low presence of each well</li>
<li>A scoring rubric for the 0.0-1.0 scale</li>
<li>Step-by-step instructions for the relative weighting task</li>
<li>Screenshots of the actual interface workers will see</li>
</ul>
<p><strong>Thursday: Gold Standard Creation</strong>
You personally annotate 5 "gold standard" narratives—texts where you're confident about the correct answers. One is a synthetic extreme (all Tribalism, zero everything else), another is a balanced historical speech, and three are moderate cases. These become your quality control anchors.</p>
<p><strong>Friday: Materials Assembly</strong>
You finalize your 30-text corpus: 5 synthetic extremes, 10 well-studied historical speeches, 10 contemporary political texts, and 5 moderately ambiguous cases. Each text is 200-400 words—long enough to show moral architecture, short enough for 15-minute annotation.</p>
<h2 id="week-2-platform-configuration-and-pilot"><strong>Week 2: Platform Configuration and Pilot</strong></h2>
<p><strong>Monday: CloudResearch Setup</strong>
Logging into CloudResearch Connect, you configure your demographic filters:</p>
<ul>
<li>US residents only</li>
<li>Ages 25-65</li>
<li>Bachelor's degree or higher</li>
<li>Self-reported political engagement score of 4+ (on 1-7 scale)</li>
<li>MTurk approval rate ≥ 98%</li>
<li>At least 1,000 completed HITs</li>
</ul>
<p>The platform shows you have access to ~8,500 qualified workers. Perfect.</p>
<p><strong>Tuesday: HIT Design</strong>
Using CloudResearch's HIT builder, you create the annotation interface:</p>
<ul>
<li>Consent form and codebook link at the top</li>
<li>Text display with highlighting capability</li>
<li>Two-step annotation: first identify dominant themes, then score all 10 wells</li>
<li>Text boxes for evidence excerpts</li>
<li>Built-in attention checks ("Select 'Fantasy' for this item to continue")</li>
<li>Estimated completion time: 15 minutes</li>
<li>Payment: \$1.50 per HIT (factoring in the higher complexity)</li>
</ul>
<p><strong>Wednesday: Soft Launch Pilot</strong>
You launch a pilot with just 3 texts and 5 workers each (15 total HITs). Within 2 hours, all slots are filled. You watch the data stream in real-time through CloudResearch's dashboard—completion times, attention check pass rates, and preliminary results.</p>
<p><strong>Thursday: Pilot Analysis</strong>
The results are mixed but encouraging:</p>
<ul>
<li>Average completion time: 12.3 minutes (good for your 15-minute estimate)</li>
<li>Attention check pass rate: 80% (acceptable, but you'll monitor)</li>
<li>Inter-rater reliability on your gold standard: κ = 0.67 (moderate agreement)</li>
<li>Workers' feedback mentions some confusing language in your Pragmatism definition</li>
</ul>
<p><strong>Friday: Refinements</strong>
You revise the codebook based on pilot feedback, clarify the most confusing definitions, and adjust one attention check that was too obvious. The interface gets minor UI tweaks for mobile compatibility.</p>
<h2 id="week-3-main-study-launch"><strong>Week 3: Main Study Launch</strong></h2>
<p><strong>Monday: Full Deployment</strong>
At 9 AM EST, you launch the full study: 30 texts × 4 workers each = 120 HITs. CloudResearch's algorithm distributes these across qualified workers to prevent any single person from dominating your sample. Your funding account shows \$200 reserved for participant payments plus fees.</p>
<p><strong>Tuesday-Wednesday: Active Monitoring</strong>
You become obsessed with the real-time dashboard. Workers are completing HITs steadily—about 15-20 per day. You see the geographic distribution: heavy on California and Texas, decent representation from the Northeast and Midwest. The attention check failure rate holds steady at 18%.</p>
<p><strong>Wednesday Evening: First Quality Review</strong>
You spot-check the first 30 completed HITs. The data looks promising—workers are providing thoughtful text excerpts, their relative weightings seem reasonable, and the free-text feedback suggests they're taking the task seriously. One worker writes: "This was challenging but interesting. Made me think about how politicians really structure their arguments."</p>
<p><strong>Thursday: Automated Adjustments</strong>
CloudResearch's fraud detection flags 3 workers for suspicious activity (completing HITs too quickly, identical responses). Their submissions are automatically excluded, and replacement HITs are posted. You appreciate not having to manage this manually.</p>
<p><strong>Friday: Week 1 Milestone</strong>
By end-of-week, you have 85 completed HITs with valid data. The completion rate is excellent, and preliminary inter-rater reliability calculations show promising consistency.</p>
<h2 id="week-4-completion-and-initial-analysis"><strong>Week 4: Completion and Initial Analysis</strong></h2>
<p><strong>Monday-Tuesday: Final Collection</strong>
The last HITs trickle in. Final count: 118 valid annotations out of 120 launched (98.3% completion rate). Two workers failed multiple attention checks and were excluded, but CloudResearch automatically recruited replacements.</p>
<p><strong>Wednesday: Data Export and Cleaning</strong>
You download the full dataset—a beautiful Excel file with 118 rows and 45 columns covering demographics, completion times, all well scores, relative weights, text excerpts, and quality metrics. The cleaning process takes 3 hours: removing obvious outliers, standardizing text responses, and flagging any remaining quality concerns.</p>
<p><strong>Thursday: Statistical Analysis Day</strong>
This is the moment of truth. Using R (or Python), you calculate:</p>
<p><strong>Inter-rater Reliability:</strong></p>
<ul>
<li>Fleiss's κ for absolute well scores: 0.71 (substantial agreement)</li>
<li>Spearman's ρ for relative weight rankings: 0.68 (moderate-strong correlation)</li>
<li>Percentage agreement on dominant themes: 78%</li>
</ul>
<p><strong>Human-LLM Alignment:</strong></p>
<ul>
<li>Correlation between human and Claude scores: r = 0.62 (moderate)</li>
<li>Systematic biases: Humans rate Tribalism higher, LLMs rate Hope higher</li>
<li>Agreement on narrative extremes: 85% (encouraging)</li>
</ul>
<p><strong>Friday: Results Interpretation</strong>
Your data tells a nuanced story. Human annotators show solid agreement with each other, suggesting the task is coherent and the codebook works. The moderate correlation with LLM outputs indicates alignment isn't perfect, but it's substantial enough to be meaningful. Most importantly, the system reliably distinguishes between extreme cases—your synthetic narratives cluster exactly where they should.</p>
<h2 id="week-5-reporting-and-documentation"><strong>Week 5: Reporting and Documentation</strong></h2>
<p><strong>Monday-Tuesday: Statistical Report</strong>
You draft a 15-page technical appendix documenting:</p>
<ul>
<li>Sampling methodology and demographic breakdown</li>
<li>Inter-rater reliability across all metrics</li>
<li>Human-LLM correlation analysis</li>
<li>Systematic bias identification</li>
<li>Quality control outcomes</li>
</ul>
<p><strong>Wednesday: Visual Analysis</strong>
You create compelling visualizations:</p>
<ul>
<li>Scatter plots showing human vs. LLM well scores</li>
<li>Heat maps of inter-annotator agreement</li>
<li>Box plots comparing extreme vs. moderate narratives</li>
<li>Demographic breakdowns of scoring patterns</li>
</ul>
<p><strong>Thursday: Implications and Next Steps</strong>
Armed with solid empirical evidence, you can now make defensible claims about your framework's validity. The moderate correlation suggests room for improvement, but the strong performance on extreme cases validates the core concept.</p>
<h2 id="the-bottom-line-what-youve-achieved"><strong>The Bottom Line: What You've Achieved</strong></h2>
<p><strong>Financial Outcome:</strong></p>
<ul>
<li>Total cost: \$187 (\$118 × \$1.50 + CloudResearch fees)</li>
<li>Under budget with \$313 remaining for additional validation or platform development</li>
</ul>
<p><strong>Scientific Outcome:</strong></p>
<ul>
<li>Statistically robust evidence of moderate human-LLM alignment</li>
<li>Clear identification of where the system works well (extreme cases) and where it struggles (nuanced political rhetoric)</li>
<li>Baseline metrics for measuring improvement as you refine prompts</li>
<li>Publication-ready methodology and results</li>
</ul>
<p><strong>Strategic Outcome:</strong></p>
<ul>
<li>You can confidently position your framework as "systematically validated against human judgment"</li>
<li>You have concrete targets for improvement (addressing the Hope/Tribalism systematic biases)</li>
<li>You've established a replicable methodology for ongoing validation as you refine the system</li>
</ul>
<p><strong>The Feeling:</strong>
That Friday afternoon in Week 5, reviewing your final results, you experience the researcher's high—solid empirical evidence supporting your theoretical framework, methodological rigor that will satisfy academic reviewers, and practical insights that will improve your system. Your demanding political science professor would nod approvingly at the statistical rigor, while your stakeholders will appreciate that you've moved beyond prototyping into validated measurement.</p>
<p>You've transformed an interesting idea into a credible analytical tool.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>