
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Plugin Architecture Enhancement Specification - Discernus Project</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#narrative-gravity-wells-plugin-architecture-enhancement-specification" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Discernus Project" class="md-header__button md-logo" aria-label="Discernus Project" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Discernus Project
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Plugin Architecture Enhancement Specification
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Discernus Project" class="md-nav__button md-logo" aria-label="Discernus Project" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Discernus Project
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/DOCUMENTATION_INDEX.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Documentation Index
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/CONTRIBUTING.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/platform-development/DEV_ENVIRONMENT.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Development Environment
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/CODE_ORGANIZATION_STANDARDS.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code Standards
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/platform-development/RELEASE_PROCESS.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Release Process
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#executive-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Executive Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#architectural-vision" class="md-nav__link">
    <span class="md-ellipsis">
      Architectural Vision
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Architectural Vision">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-philosophy" class="md-nav__link">
    <span class="md-ellipsis">
      Core Philosophy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#design-principles" class="md-nav__link">
    <span class="md-ellipsis">
      Design Principles
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#strategic-benefits" class="md-nav__link">
    <span class="md-ellipsis">
      Strategic Benefits
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#current-system-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Current System Analysis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Current System Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#existing-architecture-strengths" class="md-nav__link">
    <span class="md-ellipsis">
      Existing Architecture Strengths
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-configuration-pattern" class="md-nav__link">
    <span class="md-ellipsis">
      Framework Configuration Pattern
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#extension-points" class="md-nav__link">
    <span class="md-ellipsis">
      Extension Points
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limitations-requiring-enhancement" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations Requiring Enhancement
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#plugin-framework-specification" class="md-nav__link">
    <span class="md-ellipsis">
      Plugin Framework Specification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Plugin Framework Specification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-plugin-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Core Plugin Interface
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plugin-registry-system" class="md-nav__link">
    <span class="md-ellipsis">
      Plugin Registry System
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-package-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Framework Package Structure
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#custom-metrics-system" class="md-nav__link">
    <span class="md-ellipsis">
      Custom Metrics System
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Custom Metrics System">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#metric-calculator-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Metric Calculator Interface
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-custom-metric-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Example Custom Metric Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metric-integration-system" class="md-nav__link">
    <span class="md-ellipsis">
      Metric Integration System
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#weighting-algorithm-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Weighting Algorithm Framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Weighting Algorithm Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#weighting-algorithm-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Weighting Algorithm Interface
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-weighting-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Example Weighting Algorithm
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#declarative-visualization-schema" class="md-nav__link">
    <span class="md-ellipsis">
      Declarative Visualization Schema
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Declarative Visualization Schema">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visualization-definition-format" class="md-nav__link">
    <span class="md-ellipsis">
      Visualization Definition Format
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualization-engine-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Visualization Engine Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#security-and-validation" class="md-nav__link">
    <span class="md-ellipsis">
      Security and Validation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Security and Validation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#security-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Security Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-validation-system" class="md-nav__link">
    <span class="md-ellipsis">
      Framework Validation System
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-phases" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Phases
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implementation Phases">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#phase-1-core-plugin-infrastructure-4-6-weeks" class="md-nav__link">
    <span class="md-ellipsis">
      Phase 1: Core Plugin Infrastructure (4-6 weeks)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-2-declarative-visualization-system-3-4-weeks" class="md-nav__link">
    <span class="md-ellipsis">
      Phase 2: Declarative Visualization System (3-4 weeks)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-3-advanced-features-and-validation-2-3-weeks" class="md-nav__link">
    <span class="md-ellipsis">
      Phase 3: Advanced Features and Validation (2-3 weeks)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#migration-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Migration Strategy
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Migration Strategy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backward-compatibility-plan" class="md-nav__link">
    <span class="md-ellipsis">
      Backward Compatibility Plan
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#user-experience-continuity" class="md-nav__link">
    <span class="md-ellipsis">
      User Experience Continuity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Considerations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Considerations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#computational-overhead" class="md-nav__link">
    <span class="md-ellipsis">
      Computational Overhead
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-management" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Management
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#developer-experience" class="md-nav__link">
    <span class="md-ellipsis">
      Developer Experience
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Developer Experience">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#framework-creation-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Framework Creation Workflow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ide-integration-and-tooling" class="md-nav__link">
    <span class="md-ellipsis">
      IDE Integration and Tooling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quality-assurance" class="md-nav__link">
    <span class="md-ellipsis">
      Quality Assurance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quality Assurance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#automated-testing-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Automated Testing Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#peer-review-process" class="md-nav__link">
    <span class="md-ellipsis">
      Peer Review Process
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#future-extensions" class="md-nav__link">
    <span class="md-ellipsis">
      Future Extensions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Future Extensions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#advanced-plugin-capabilities" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Plugin Capabilities
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ecosystem-development" class="md-nav__link">
    <span class="md-ellipsis">
      Ecosystem Development
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resource-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      Resource Requirements
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Resource Requirements">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#development-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Development Resources
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infrastructure-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      Infrastructure Requirements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#budget-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      Budget Estimation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<p><img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/></p>
<h1 id="narrative-gravity-wells-plugin-architecture-enhancement-specification">Narrative Gravity Wells: Plugin Architecture Enhancement Specification</h1>
<p><strong>Version</strong>: 1.0.0
<strong>Date</strong>: June 11, 2025
<strong>Status</strong>: Future Enhancement - Post-Validation Implementation
<strong>Priority</strong>: Medium (After Academic Validation Completion)</p>
<h2 id="executive-summary">Executive Summary</h2>
<p>This document specifies a comprehensive plugin architecture enhancement for the Narrative Gravity Wells system, enabling framework creators to develop custom metrics, weighting algorithms, and visualizations without modifying core system code. The enhancement transforms the project from a specific analytical framework into a platform for building analytical frameworks while maintaining the rigor and reliability of the current system.</p>
<p><strong>Implementation Timeline</strong>: Post-Milestone 2 completion (after LLM reliability validation and human subject studies)</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#architectural-vision">Architectural Vision</a></li>
<li><a href="#current-system-analysis">Current System Analysis</a></li>
<li><a href="#plugin-framework-specification">Plugin Framework Specification</a></li>
<li><a href="#custom-metrics-system">Custom Metrics System</a></li>
<li><a href="#weighting-algorithm-framework">Weighting Algorithm Framework</a></li>
<li><a href="#declarative-visualization-schema">Declarative Visualization Schema</a></li>
<li><a href="#security-and-validation">Security and Validation</a></li>
<li><a href="#framework-package-structure">Framework Package Structure</a></li>
<li><a href="#implementation-phases">Implementation Phases</a></li>
<li><a href="#migration-strategy">Migration Strategy</a></li>
<li><a href="#performance-considerations">Performance Considerations</a></li>
<li><a href="#developer-experience">Developer Experience</a></li>
<li><a href="#quality-assurance">Quality Assurance</a></li>
<li><a href="#future-extensions">Future Extensions</a></li>
<li><a href="#resource-requirements">Resource Requirements</a></li>
</ol>
<h2 id="architectural-vision">Architectural Vision</h2>
<h3 id="core-philosophy">Core Philosophy</h3>
<p>Transform the Narrative Gravity Wells system from a collection of specific analytical frameworks into a <strong>meta-framework</strong> for building analytical frameworks. Enable unlimited innovation in political narrative analysis while maintaining system stability, security, and academic rigor.</p>
<h3 id="design-principles">Design Principles</h3>
<ol>
<li><strong>Extensibility Without Modification</strong>: New frameworks require no changes to core system code</li>
<li><strong>Constrained Innovation</strong>: Plugin guardrails prevent security issues and performance degradation</li>
<li><strong>Backward Compatibility</strong>: Existing frameworks continue functioning unchanged</li>
<li><strong>Academic Rigor</strong>: Plugin validation ensures analytical quality and reproducibility</li>
<li><strong>Developer Experience</strong>: Framework creation should be accessible to researchers with basic programming skills</li>
</ol>
<h3 id="strategic-benefits">Strategic Benefits</h3>
<ul>
<li><strong>Research Scalability</strong>: Academic community can contribute novel analytical approaches</li>
<li><strong>System Longevity</strong>: Core infrastructure remains stable while supporting unlimited innovation</li>
<li><strong>Reduced Maintenance</strong>: Framework-specific bugs isolated from core system</li>
<li><strong>Academic Adoption</strong>: Lower barriers to framework development increase research usage</li>
<li><strong>Methodological Diversity</strong>: Support for emerging analytical approaches in political communication</li>
</ul>
<h2 id="current-system-analysis">Current System Analysis</h2>
<h3 id="existing-architecture-strengths">Existing Architecture Strengths</h3>
<p>The current system provides an excellent foundation for plugin architecture:</p>
<pre><code class="language-python"># Current modular design
class FrameworkManager:
    def load_framework(self, framework_name: str) -&gt; Dict
    def validate_framework_config(self, config: Dict) -&gt; bool
    def get_available_frameworks(self) -&gt; List[str]

class NarrativeGravityElliptical:
    def calculate_elliptical_metrics(self, x: float, y: float, scores: Dict) -&gt; Dict
    def calculate_narrative_position(self, well_scores: Dict) -&gt; Tuple[float, float]
    def create_visualization_data(self, data: Dict) -&gt; Dict
</code></pre>
<h3 id="framework-configuration-pattern">Framework Configuration Pattern</h3>
<pre><code class="language-json">{
  &quot;framework_name&quot;: &quot;civic_virtue&quot;, 
  &quot;dipoles&quot;: [...],
  &quot;wells&quot;: {...},
  &quot;metrics&quot;: {
    &quot;com&quot;: {&quot;name&quot;: &quot;Center of Mass&quot;, &quot;description&quot;: &quot;...&quot;},
    &quot;nps&quot;: {&quot;name&quot;: &quot;Narrative Polarity Score&quot;, &quot;description&quot;: &quot;...&quot;}
  }
}
</code></pre>
<h3 id="extension-points">Extension Points</h3>
<p>Current system already supports:</p>
<ul>
<li><strong>Hot-swappable frameworks</strong>: JSON-driven configuration</li>
<li><strong>Universal metrics</strong>: Framework-agnostic calculation engine</li>
<li><strong>Multi-LLM compatibility</strong>: Unified prompt generation and result processing</li>
<li><strong>Flexible visualization</strong>: Framework-independent data export</li>
</ul>
<h3 id="limitations-requiring-enhancement">Limitations Requiring Enhancement</h3>
<ol>
<li><strong>Custom Metrics</strong>: Currently hardcoded in <code>narrativegravityelliptical.py</code></li>
<li><strong>Weighting Systems</strong>: Limited to basic well weight multiplication</li>
<li><strong>Visualization Types</strong>: Fixed elliptical and polar charts</li>
<li><strong>Validation Logic</strong>: Framework-specific validation requires core code changes</li>
<li><strong>Mathematical Algorithms</strong>: No support for custom positioning or metric calculations</li>
</ol>
<h2 id="plugin-framework-specification">Plugin Framework Specification</h2>
<h3 id="core-plugin-interface">Core Plugin Interface</h3>
<pre><code class="language-python">from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, Type
from dataclasses import dataclass
from enum import Enum

class PluginType(Enum):
    METRIC_CALCULATOR = &quot;metric_calculator&quot;
    WEIGHTING_ALGORITHM = &quot;weighting_algorithm&quot; 
    VISUALIZATION_RENDERER = &quot;visualization_renderer&quot;
    VALIDATION_RULE = &quot;validation_rule&quot;

@dataclass
class PluginMetadata:
    name: str
    version: str
    author: str
    description: str
    plugin_type: PluginType
    framework_compatibility: List[str]
    python_requirements: List[str]
    academic_citations: List[str]

class FrameworkPlugin(ABC):
    &quot;&quot;&quot;Base class for all framework plugins&quot;&quot;&quot;

    @property
    @abstractmethod
    def metadata(self) -&gt; PluginMetadata:
        &quot;&quot;&quot;Plugin identification and compatibility information&quot;&quot;&quot;
        pass

    @abstractmethod
    def validate_configuration(self, config: Dict[str, Any]) -&gt; 'ValidationResult':
        &quot;&quot;&quot;Validate framework-specific configuration&quot;&quot;&quot;
        pass

    @abstractmethod
    def register_components(self) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;Register custom components with the system&quot;&quot;&quot;
        pass
</code></pre>
<h3 id="plugin-registry-system">Plugin Registry System</h3>
<pre><code class="language-python">class PluginRegistry:
    def __init__(self):
        self.registered_plugins: Dict[str, FrameworkPlugin] = {}
        self.component_registry: Dict[PluginType, Dict[str, Type]] = {
            PluginType.METRIC_CALCULATOR: {},
            PluginType.WEIGHTING_ALGORITHM: {},
            PluginType.VISUALIZATION_RENDERER: {},
            PluginType.VALIDATION_RULE: {}
        }

    def register_plugin(self, plugin: FrameworkPlugin) -&gt; bool:
        &quot;&quot;&quot;Register a plugin and its components&quot;&quot;&quot;
        try:
            # Validate plugin security and compatibility
            if not self._validate_plugin_security(plugin):
                return False

            # Register plugin
            self.registered_plugins[plugin.metadata.name] = plugin

            # Register components
            components = plugin.register_components()
            for component_type, component_map in components.items():
                self.component_registry[component_type].update(component_map)

            return True
        except Exception as e:
            logger.error(f&quot;Plugin registration failed: {e}&quot;)
            return False

    def get_component(self, component_type: PluginType, name: str) -&gt; Optional[Type]:
        &quot;&quot;&quot;Retrieve registered component by type and name&quot;&quot;&quot;
        return self.component_registry[component_type].get(name)

    def list_plugins(self) -&gt; List[PluginMetadata]:
        &quot;&quot;&quot;List all registered plugins&quot;&quot;&quot;
        return [plugin.metadata for plugin in self.registered_plugins.values()]
</code></pre>
<h3 id="framework-package-structure">Framework Package Structure</h3>
<pre><code>frameworks/
├── mft_persuasive_force/
│   ├── framework.json              # Core framework configuration
│   ├── dipoles.json               # Narrative dipole definitions
│   ├── prompt.md                  # LLM analysis prompt
│   ├── plugin.py                  # Custom plugin implementation
│   ├── visualizations.json       # Visualization definitions
│   ├── tests/                     # Framework-specific tests
│   │   ├── test_metrics.py
│   │   ├── test_weighting.py
│   │   └── validation_data.json
│   ├── docs/                      # Framework documentation
│   │   ├── README.md
│   │   ├── theoretical_foundation.md
│   │   └── validation_studies.md
│   └── examples/                  # Usage examples and demos
│       ├── sample_analyses.json
│       └── cultural_comparison.py
</code></pre>
<h2 id="custom-metrics-system">Custom Metrics System</h2>
<h3 id="metric-calculator-interface">Metric Calculator Interface</h3>
<pre><code class="language-python">from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

class MetricOutputType(Enum):
    SCALAR = &quot;scalar&quot;           # Single numerical value
    VECTOR = &quot;vector&quot;           # Multiple related values
    COORDINATE = &quot;coordinate&quot;   # X,Y position
    CATEGORICAL = &quot;categorical&quot; # Discrete categories

@dataclass
class MetricDefinition:
    name: str
    display_name: str
    description: str
    output_type: MetricOutputType
    output_range: Tuple[float, float]
    required_inputs: List[str]
    optimal_inputs: List[str]
    academic_references: List[str]

class MetricCalculator(ABC):
    &quot;&quot;&quot;Abstract base class for custom metric calculations&quot;&quot;&quot;

    @property
    @abstractmethod
    def definition(self) -&gt; MetricDefinition:
        &quot;&quot;&quot;Metric specification and metadata&quot;&quot;&quot;
        pass

    @abstractmethod
    def calculate(self, 
                  well_scores: Dict[str, float],
                  context: Optional[Dict[str, Any]] = None) -&gt; Any:
        &quot;&quot;&quot;
        Calculate metric value from well scores and optional context

        Args:
            well_scores: Framework-specific well scores {well_name: score}
            context: Optional contextual information (cultural segments, etc.)

        Returns:
            Metric value matching declared output_type
        &quot;&quot;&quot;
        pass

    @abstractmethod
    def validate_inputs(self, 
                        well_scores: Dict[str, float],
                        context: Optional[Dict[str, Any]] = None) -&gt; bool:
        &quot;&quot;&quot;Validate that inputs are suitable for this metric&quot;&quot;&quot;
        pass

    def explain_calculation(self, 
                           well_scores: Dict[str, float],
                           context: Optional[Dict[str, Any]] = None) -&gt; str:
        &quot;&quot;&quot;Optional: Provide human-readable explanation of calculation&quot;&quot;&quot;
        return f&quot;Calculated {self.definition.name} from {len(well_scores)} well scores&quot;
</code></pre>
<h3 id="example-custom-metric-implementation">Example Custom Metric Implementation</h3>
<pre><code class="language-python">class CulturalResonanceCalculator(MetricCalculator):
    &quot;&quot;&quot;Calculate alignment between narrative appeals and cultural priorities&quot;&quot;&quot;

    @property
    def definition(self) -&gt; MetricDefinition:
        return MetricDefinition(
            name=&quot;cultural_resonance_score&quot;,
            display_name=&quot;Cultural Resonance Score&quot;,
            description=&quot;Measures alignment between narrative moral appeals and target demographic moral foundation priorities&quot;,
            output_type=MetricOutputType.SCALAR,
            output_range=(0.0, 1.0),
            required_inputs=[&quot;well_scores&quot;, &quot;cultural_segment&quot;],
            optimal_inputs=[&quot;narrative_context&quot;, &quot;demographic_metadata&quot;],
            academic_references=[
                &quot;Haidt, J. (2012). The righteous mind: Why good people are divided by politics and religion&quot;,
                &quot;Graham, J., et al. (2013). Moral foundations theory: The pragmatic validity of moral pluralism&quot;
            ]
        )

    def calculate(self, 
                  well_scores: Dict[str, float],
                  context: Optional[Dict[str, Any]] = None) -&gt; float:
        if not context or &quot;cultural_segment&quot; not in context:
            raise ValueError(&quot;Cultural segment required for resonance calculation&quot;)

        cultural_segment = context[&quot;cultural_segment&quot;]
        cultural_weights = self._get_cultural_weights(cultural_segment)

        # Calculate weighted correlation between narrative and cultural priorities
        resonance_score = 0.0
        total_weight = 0.0

        for well_name, narrative_score in well_scores.items():
            if well_name in cultural_weights:
                cultural_weight = cultural_weights[well_name]
                resonance_score += narrative_score * abs(cultural_weight)
                total_weight += abs(cultural_weight)

        return resonance_score / total_weight if total_weight &gt; 0 else 0.0

    def validate_inputs(self, 
                        well_scores: Dict[str, float],
                        context: Optional[Dict[str, Any]] = None) -&gt; bool:
        if not well_scores:
            return False
        if not context or &quot;cultural_segment&quot; not in context:
            return False
        if context[&quot;cultural_segment&quot;] not in self._get_available_segments():
            return False
        return True

    def explain_calculation(self, 
                           well_scores: Dict[str, float],
                           context: Optional[Dict[str, Any]] = None) -&gt; str:
        cultural_segment = context.get(&quot;cultural_segment&quot;, &quot;unknown&quot;)
        return f&quot;Calculated cultural alignment for {cultural_segment} segment using weighted correlation of {len(well_scores)} moral foundation scores&quot;

    def _get_cultural_weights(self, segment: str) -&gt; Dict[str, float]:
        # Load cultural weight matrices from framework configuration
        cultural_matrices = {
            &quot;progressive_urban&quot;: {
                &quot;compassion&quot;: 1.0, &quot;equity&quot;: 0.95, &quot;solidarity&quot;: 0.4,
                &quot;hierarchy&quot;: 0.2, &quot;purity&quot;: 0.15
            },
            &quot;conservative_religious&quot;: {
                &quot;compassion&quot;: 0.8, &quot;equity&quot;: 0.6, &quot;solidarity&quot;: 0.9,
                &quot;hierarchy&quot;: 1.0, &quot;purity&quot;: 1.0
            }
            # ... additional segments
        }
        return cultural_matrices.get(segment, {})

    def _get_available_segments(self) -&gt; List[str]:
        return [&quot;progressive_urban&quot;, &quot;conservative_religious&quot;, &quot;libertarian_independent&quot;, 
                &quot;working_class_traditional&quot;, &quot;multicultural_urban&quot;, &quot;rural_traditional&quot;]
</code></pre>
<h3 id="metric-integration-system">Metric Integration System</h3>
<pre><code class="language-python">class MetricEngine:
    def __init__(self):
        self.builtin_metrics = {
            &quot;com&quot;: CenterOfMassCalculator(),
            &quot;nps&quot;: NarrativePolarityCalculator(),
            &quot;dps&quot;: DirectionalPurityCalculator()
        }
        self.custom_metrics: Dict[str, MetricCalculator] = {}

    def register_metric(self, calculator: MetricCalculator) -&gt; bool:
        &quot;&quot;&quot;Register a custom metric calculator&quot;&quot;&quot;
        try:
            metric_name = calculator.definition.name

            # Validate metric implementation
            if not self._validate_metric_calculator(calculator):
                return False

            # Check for name conflicts
            if metric_name in self.builtin_metrics:
                logger.warning(f&quot;Metric {metric_name} conflicts with builtin metric&quot;)
                return False

            self.custom_metrics[metric_name] = calculator
            return True
        except Exception as e:
            logger.error(f&quot;Metric registration failed: {e}&quot;)
            return False

    def calculate_metrics(self, 
                          well_scores: Dict[str, float],
                          framework_config: Dict[str, Any],
                          context: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;Calculate all applicable metrics for framework&quot;&quot;&quot;
        results = {}

        # Calculate builtin metrics
        for name, calculator in self.builtin_metrics.items():
            if self._metric_applicable(name, framework_config):
                try:
                    results[name] = calculator.calculate(well_scores, context)
                except Exception as e:
                    logger.error(f&quot;Builtin metric {name} calculation failed: {e}&quot;)

        # Calculate custom metrics
        for name, calculator in self.custom_metrics.items():
            if self._metric_applicable(name, framework_config):
                try:
                    if calculator.validate_inputs(well_scores, context):
                        results[name] = calculator.calculate(well_scores, context)
                    else:
                        logger.warning(f&quot;Custom metric {name} input validation failed&quot;)
                except Exception as e:
                    logger.error(f&quot;Custom metric {name} calculation failed: {e}&quot;)

        return results
</code></pre>
<h2 id="weighting-algorithm-framework">Weighting Algorithm Framework</h2>
<h3 id="weighting-algorithm-interface">Weighting Algorithm Interface</h3>
<pre><code class="language-python">from abc import ABC, abstractmethod
from typing import Dict, Any, List
from dataclasses import dataclass

@dataclass
class WeightingDefinition:
    name: str
    display_name: str
    description: str
    algorithm_type: str
    input_requirements: List[str]
    parameters: Dict[str, Any]
    academic_references: List[str]

class WeightingAlgorithm(ABC):
    &quot;&quot;&quot;Abstract base class for custom weighting algorithms&quot;&quot;&quot;

    @property
    @abstractmethod
    def definition(self) -&gt; WeightingDefinition:
        &quot;&quot;&quot;Weighting algorithm specification&quot;&quot;&quot;
        pass

    @abstractmethod
    def apply_weights(self, 
                      well_scores: Dict[str, float],
                      parameters: Dict[str, Any]) -&gt; Dict[str, float]:
        &quot;&quot;&quot;
        Apply framework-specific weighting to well scores

        Args:
            well_scores: Original well scores {well_name: score}
            parameters: Algorithm-specific parameters

        Returns:
            Weighted well scores {well_name: weighted_score}
        &quot;&quot;&quot;
        pass

    @abstractmethod
    def validate_parameters(self, parameters: Dict[str, Any]) -&gt; bool:
        &quot;&quot;&quot;Validate algorithm parameters&quot;&quot;&quot;
        pass

    def get_effective_weights(self, parameters: Dict[str, Any]) -&gt; Dict[str, float]:
        &quot;&quot;&quot;Return the actual weights that would be applied&quot;&quot;&quot;
        return {}
</code></pre>
<h3 id="example-weighting-algorithm">Example Weighting Algorithm</h3>
<pre><code class="language-python">class CulturalMatrixWeighting(WeightingAlgorithm):
    &quot;&quot;&quot;Apply cultural demographic-specific weighting to well scores&quot;&quot;&quot;

    @property
    def definition(self) -&gt; WeightingDefinition:
        return WeightingDefinition(
            name=&quot;cultural_matrix_weighting&quot;,
            display_name=&quot;Cultural Matrix Weighting&quot;,
            description=&quot;Applies demographic-specific weights based on empirical moral foundation research&quot;,
            algorithm_type=&quot;matrix_multiplication&quot;,
            input_requirements=[&quot;well_scores&quot;, &quot;cultural_segment&quot;],
            parameters={&quot;cultural_matrices&quot;: &quot;framework_defined&quot;},
            academic_references=[
                &quot;Graham, J., et al. (2011). Mapping the moral domain&quot;,
                &quot;Haidt, J., &amp; Graham, J. (2007). When morality opposes justice&quot;
            ]
        )

    def apply_weights(self, 
                      well_scores: Dict[str, float],
                      parameters: Dict[str, Any]) -&gt; Dict[str, float]:
        cultural_segment = parameters.get(&quot;cultural_segment&quot;)
        cultural_matrices = parameters.get(&quot;cultural_matrices&quot;, {})

        if not cultural_segment or cultural_segment not in cultural_matrices:
            return well_scores  # Return unmodified if no valid cultural context

        cultural_weights = cultural_matrices[cultural_segment]
        weighted_scores = {}

        for well_name, score in well_scores.items():
            cultural_multiplier = cultural_weights.get(well_name, 1.0)
            weighted_scores[well_name] = score * cultural_multiplier

        return weighted_scores

    def validate_parameters(self, parameters: Dict[str, Any]) -&gt; bool:
        required = [&quot;cultural_segment&quot;, &quot;cultural_matrices&quot;]
        return all(param in parameters for param in required)

    def get_effective_weights(self, parameters: Dict[str, Any]) -&gt; Dict[str, float]:
        cultural_segment = parameters.get(&quot;cultural_segment&quot;)
        cultural_matrices = parameters.get(&quot;cultural_matrices&quot;, {})

        if cultural_segment in cultural_matrices:
            return cultural_matrices[cultural_segment]
        return {}
</code></pre>
<h2 id="declarative-visualization-schema">Declarative Visualization Schema</h2>
<h3 id="visualization-definition-format">Visualization Definition Format</h3>
<pre><code class="language-json">{
  &quot;visualization_definitions&quot;: {
    &quot;cultural_comparison_polar&quot;: {
      &quot;id&quot;: &quot;cultural_comparison_polar&quot;,
      &quot;name&quot;: &quot;Cultural Demographic Comparison (Polar)&quot;,
      &quot;description&quot;: &quot;Multi-segment polar chart showing cultural resonance patterns&quot;,
      &quot;base_type&quot;: &quot;polar_chart&quot;,
      &quot;version&quot;: &quot;1.0.0&quot;,
      &quot;parameters&quot;: {
        &quot;radius_metric&quot;: &quot;cultural_resonance_score&quot;,
        &quot;angle_mapping&quot;: &quot;foundation_weights&quot;,
        &quot;color_scheme&quot;: &quot;cultural_segment_colors&quot;,
        &quot;interactive_elements&quot;: [&quot;cultural_selector&quot;, &quot;foundation_tooltip&quot;],
        &quot;normalization&quot;: &quot;z_score_by_segment&quot;
      },
      &quot;layout&quot;: {
        &quot;title_template&quot;: &quot;Cultural Resonance Analysis: {cultural_segment}&quot;,
        &quot;subtitle_template&quot;: &quot;Foundation prioritization across demographic segments&quot;,
        &quot;legend_position&quot;: &quot;bottom&quot;,
        &quot;grid_style&quot;: &quot;radial&quot;,
        &quot;axis_labels&quot;: &quot;foundation_names&quot;
      },
      &quot;data_requirements&quot;: {
        &quot;required_metrics&quot;: [&quot;cultural_resonance_score&quot;],
        &quot;required_context&quot;: [&quot;cultural_segment&quot;, &quot;foundation_weights&quot;],
        &quot;minimum_wells&quot;: 5
      },
      &quot;export_formats&quot;: [&quot;png&quot;, &quot;svg&quot;, &quot;interactive_html&quot;, &quot;pdf&quot;]
    },
    &quot;foundation_heatmap&quot;: {
      &quot;id&quot;: &quot;foundation_heatmap&quot;,
      &quot;name&quot;: &quot;Cross-Cultural Foundation Heatmap&quot;,
      &quot;description&quot;: &quot;Matrix heatmap showing foundation activation across cultural segments&quot;,
      &quot;base_type&quot;: &quot;matrix_heatmap&quot;,
      &quot;version&quot;: &quot;1.0.0&quot;,
      &quot;parameters&quot;: {
        &quot;rows&quot;: &quot;cultural_segments&quot;,
        &quot;columns&quot;: &quot;foundation_names&quot;,
        &quot;values&quot;: &quot;weighted_scores&quot;,
        &quot;color_scale&quot;: &quot;diverging_red_blue&quot;,
        &quot;clustering&quot;: &quot;hierarchical_by_similarity&quot;
      },
      &quot;layout&quot;: {
        &quot;title_template&quot;: &quot;Foundation Activation Heatmap&quot;,
        &quot;color_bar_label&quot;: &quot;Weighted Score&quot;,
        &quot;annotation_threshold&quot;: 0.1
      },
      &quot;data_requirements&quot;: {
        &quot;required_metrics&quot;: [&quot;weighted_scores&quot;],
        &quot;minimum_segments&quot;: 2,
        &quot;minimum_foundations&quot;: 3
      }
    }
  }
}
</code></pre>
<h3 id="visualization-engine-architecture">Visualization Engine Architecture</h3>
<pre><code class="language-python">from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
import plotly.graph_objects as go
from plotly.subplots import make_subplots

class VisualizationRenderer(ABC):
    &quot;&quot;&quot;Abstract base class for visualization renderers&quot;&quot;&quot;

    @property
    @abstractmethod
    def supported_base_type(self) -&gt; str:
        &quot;&quot;&quot;Base visualization type this renderer supports&quot;&quot;&quot;
        pass

    @abstractmethod
    def create(self, 
               definition: Dict[str, Any],
               data: Dict[str, Any],
               context: Optional[Dict[str, Any]] = None) -&gt; go.Figure:
        &quot;&quot;&quot;Create visualization from definition and data&quot;&quot;&quot;
        pass

    @abstractmethod
    def validate_definition(self, definition: Dict[str, Any]) -&gt; bool:
        &quot;&quot;&quot;Validate visualization definition&quot;&quot;&quot;
        pass

    @abstractmethod
    def validate_data(self, 
                      definition: Dict[str, Any],
                      data: Dict[str, Any]) -&gt; bool:
        &quot;&quot;&quot;Validate data meets visualization requirements&quot;&quot;&quot;
        pass

class PolarVisualizationRenderer(VisualizationRenderer):
    &quot;&quot;&quot;Render polar chart visualizations&quot;&quot;&quot;

    @property
    def supported_base_type(self) -&gt; str:
        return &quot;polar_chart&quot;

    def create(self, 
               definition: Dict[str, Any],
               data: Dict[str, Any],
               context: Optional[Dict[str, Any]] = None) -&gt; go.Figure:

        params = definition[&quot;parameters&quot;]
        layout_config = definition.get(&quot;layout&quot;, {})

        # Extract visualization data
        radius_values = data.get(params[&quot;radius_metric&quot;], [])
        angle_values = data.get(params[&quot;angle_mapping&quot;], [])

        # Create polar scatter plot
        fig = go.Figure()

        if context and &quot;cultural_segments&quot; in context:
            # Multi-segment comparison
            for segment in context[&quot;cultural_segments&quot;]:
                segment_data = data.get(segment, {})
                fig.add_trace(go.Scatterpolar(
                    r=segment_data.get(params[&quot;radius_metric&quot;], []),
                    theta=segment_data.get(params[&quot;angle_mapping&quot;], []),
                    mode='markers+lines',
                    name=segment.replace(&quot;_&quot;, &quot; &quot;).title(),
                    line=dict(width=2),
                    marker=dict(size=8)
                ))
        else:
            # Single visualization
            fig.add_trace(go.Scatterpolar(
                r=radius_values,
                theta=angle_values,
                mode='markers+lines',
                name='Narrative Position',
                line=dict(width=3),
                marker=dict(size=10)
            ))

        # Apply layout configuration
        title = layout_config.get(&quot;title_template&quot;, &quot;Polar Visualization&quot;)
        if context:
            title = title.format(**context)

        fig.update_layout(
            title=title,
            polar=dict(
                radialaxis=dict(visible=True, range=[0, 1]),
                angularaxis=dict(visible=True)
            ),
            showlegend=True
        )

        return fig

    def validate_definition(self, definition: Dict[str, Any]) -&gt; bool:
        required_params = [&quot;radius_metric&quot;, &quot;angle_mapping&quot;]
        params = definition.get(&quot;parameters&quot;, {})
        return all(param in params for param in required_params)

    def validate_data(self, 
                      definition: Dict[str, Any],
                      data: Dict[str, Any]) -&gt; bool:
        params = definition[&quot;parameters&quot;]
        required_data = [params[&quot;radius_metric&quot;], params[&quot;angle_mapping&quot;]]
        return all(key in data for key in required_data)

class VisualizationEngine:
    def __init__(self):
        self.renderers: Dict[str, VisualizationRenderer] = {
            &quot;polar_chart&quot;: PolarVisualizationRenderer(),
            &quot;matrix_heatmap&quot;: HeatmapVisualizationRenderer(),
            &quot;elliptical&quot;: EllipticalVisualizationRenderer(),
            &quot;radial_bar&quot;: RadialBarVisualizationRenderer()
        }
        self.custom_renderers: Dict[str, VisualizationRenderer] = {}

    def register_renderer(self, renderer: VisualizationRenderer) -&gt; bool:
        &quot;&quot;&quot;Register custom visualization renderer&quot;&quot;&quot;
        try:
            base_type = renderer.supported_base_type
            if base_type in self.renderers:
                logger.warning(f&quot;Overriding existing renderer for {base_type}&quot;)

            self.custom_renderers[base_type] = renderer
            return True
        except Exception as e:
            logger.error(f&quot;Renderer registration failed: {e}&quot;)
            return False

    def create_visualization(self, 
                           definition: Dict[str, Any],
                           data: Dict[str, Any],
                           context: Optional[Dict[str, Any]] = None) -&gt; go.Figure:
        &quot;&quot;&quot;Create visualization from definition&quot;&quot;&quot;
        base_type = definition.get(&quot;base_type&quot;)

        # Try custom renderers first
        if base_type in self.custom_renderers:
            renderer = self.custom_renderers[base_type]
        elif base_type in self.renderers:
            renderer = self.renderers[base_type]
        else:
            raise ValueError(f&quot;No renderer available for base_type: {base_type}&quot;)

        # Validate definition and data
        if not renderer.validate_definition(definition):
            raise ValueError(f&quot;Invalid visualization definition for {base_type}&quot;)

        if not renderer.validate_data(definition, data):
            raise ValueError(f&quot;Data does not meet requirements for {base_type}&quot;)

        return renderer.create(definition, data, context)
</code></pre>
<h2 id="security-and-validation">Security and Validation</h2>
<h3 id="security-framework">Security Framework</h3>
<pre><code class="language-python">import ast
import sys
import resource
from typing import Set, List
import importlib.util
from pathlib import Path

class PluginSecurityValidator:
    &quot;&quot;&quot;Comprehensive security validation for plugin code&quot;&quot;&quot;

    ALLOWED_IMPORTS = {
        'math', 'statistics', 'numpy', 'scipy', 'pandas',
        'typing', 'dataclasses', 'enum', 'abc', 'logging',
        'json', 'csv', 're', 'collections', 'itertools'
    }

    FORBIDDEN_FUNCTIONS = {
        'exec', 'eval', 'compile', '__import__', 'open',
        'file', 'input', 'raw_input', 'reload', 'vars',
        'dir', 'globals', 'locals', 'memoryview'
    }

    FORBIDDEN_MODULES = {
        'os', 'sys', 'subprocess', 'shutil', 'socket',
        'urllib', 'requests', 'pickle', 'marshal'
    }

    MAX_COMPUTATION_TIME = 10.0  # seconds
    MAX_MEMORY_USAGE = 256 * 1024 * 1024  # 256MB
    MAX_FILE_SIZE = 1024 * 1024  # 1MB

    def validate_plugin_file(self, plugin_path: Path) -&gt; 'SecurityValidationResult':
        &quot;&quot;&quot;Comprehensive plugin file validation&quot;&quot;&quot;
        try:
            # File size check
            if plugin_path.stat().st_size &gt; self.MAX_FILE_SIZE:
                return SecurityValidationResult(
                    is_valid=False,
                    error=&quot;Plugin file exceeds maximum size limit&quot;
                )

            # Parse AST for static analysis
            with open(plugin_path, 'r', encoding='utf-8') as f:
                code = f.read()

            tree = ast.parse(code)

            # Check for forbidden operations
            security_issues = self._analyze_ast(tree)
            if security_issues:
                return SecurityValidationResult(
                    is_valid=False,
                    error=f&quot;Security violations found: {security_issues}&quot;
                )

            # Test plugin loading in sandboxed environment
            sandbox_result = self._test_plugin_in_sandbox(plugin_path)
            if not sandbox_result.is_valid:
                return sandbox_result

            return SecurityValidationResult(is_valid=True)

        except Exception as e:
            return SecurityValidationResult(
                is_valid=False,
                error=f&quot;Plugin validation failed: {str(e)}&quot;
            )

    def _analyze_ast(self, tree: ast.AST) -&gt; List[str]:
        &quot;&quot;&quot;Static analysis of AST for security issues&quot;&quot;&quot;
        issues = []

        for node in ast.walk(tree):
            # Check for forbidden function calls
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name):
                    if node.func.id in self.FORBIDDEN_FUNCTIONS:
                        issues.append(f&quot;Forbidden function: {node.func.id}&quot;)

            # Check for forbidden imports
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    if alias.name in self.FORBIDDEN_MODULES:
                        issues.append(f&quot;Forbidden import: {alias.name}&quot;)
                    elif alias.name not in self.ALLOWED_IMPORTS:
                        issues.append(f&quot;Unauthorized import: {alias.name}&quot;)

            elif isinstance(node, ast.ImportFrom):
                if node.module in self.FORBIDDEN_MODULES:
                    issues.append(f&quot;Forbidden import from: {node.module}&quot;)
                elif node.module not in self.ALLOWED_IMPORTS:
                    issues.append(f&quot;Unauthorized import from: {node.module}&quot;)

        return issues

    def _test_plugin_in_sandbox(self, plugin_path: Path) -&gt; 'SecurityValidationResult':
        &quot;&quot;&quot;Test plugin loading with resource limits&quot;&quot;&quot;
        try:
            # Set memory limit
            resource.setrlimit(resource.RLIMIT_AS, (self.MAX_MEMORY_USAGE, self.MAX_MEMORY_USAGE))

            # Set CPU time limit
            resource.setrlimit(resource.RLIMIT_CPU, (int(self.MAX_COMPUTATION_TIME), int(self.MAX_COMPUTATION_TIME)))

            # Load plugin module
            spec = importlib.util.spec_from_file_location(&quot;test_plugin&quot;, plugin_path)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            # Test basic plugin functionality
            if hasattr(module, 'FrameworkPlugin'):
                plugin_class = getattr(module, 'FrameworkPlugin')
                test_plugin = plugin_class()

                # Test metadata access
                metadata = test_plugin.metadata

                # Test component registration
                components = test_plugin.register_components()

                return SecurityValidationResult(is_valid=True)
            else:
                return SecurityValidationResult(
                    is_valid=False,
                    error=&quot;Plugin does not contain required FrameworkPlugin class&quot;
                )

        except Exception as e:
            return SecurityValidationResult(
                is_valid=False,
                error=f&quot;Sandbox testing failed: {str(e)}&quot;
            )

@dataclass
class SecurityValidationResult:
    is_valid: bool
    error: Optional[str] = None
    warnings: List[str] = None
</code></pre>
<h3 id="framework-validation-system">Framework Validation System</h3>
<pre><code class="language-python">class FrameworkValidator:
    &quot;&quot;&quot;Comprehensive framework package validation&quot;&quot;&quot;

    def __init__(self):
        self.security_validator = PluginSecurityValidator()
        self.schema_validator = FrameworkSchemaValidator()
        self.academic_validator = AcademicValidityValidator()

    def validate_framework_package(self, framework_path: Path) -&gt; 'FrameworkValidationResult':
        &quot;&quot;&quot;Complete validation of framework package&quot;&quot;&quot;
        results = []

        # 1. Package structure validation
        structure_result = self._validate_package_structure(framework_path)
        results.append(structure_result)

        # 2. Configuration schema validation
        config_result = self.schema_validator.validate_configuration(framework_path)
        results.append(config_result)

        # 3. Plugin security validation
        plugin_file = framework_path / &quot;plugin.py&quot;
        if plugin_file.exists():
            security_result = self.security_validator.validate_plugin_file(plugin_file)
            results.append(security_result)

        # 4. Academic validity validation
        academic_result = self.academic_validator.validate_theoretical_foundation(framework_path)
        results.append(academic_result)

        # 5. Test suite validation
        test_result = self._validate_test_suite(framework_path)
        results.append(test_result)

        # 6. Performance benchmarking
        performance_result = self._validate_performance(framework_path)
        results.append(performance_result)

        return FrameworkValidationResult.aggregate(results)

    def _validate_package_structure(self, framework_path: Path) -&gt; 'ValidationResult':
        &quot;&quot;&quot;Validate required files and structure&quot;&quot;&quot;
        required_files = [
            &quot;framework.json&quot;,
            &quot;dipoles.json&quot;, 
            &quot;prompt.md&quot;,
            &quot;README.md&quot;
        ]

        required_dirs = [
            &quot;docs&quot;,
            &quot;tests&quot;
        ]

        missing_files = []
        missing_dirs = []

        for file_name in required_files:
            if not (framework_path / file_name).exists():
                missing_files.append(file_name)

        for dir_name in required_dirs:
            if not (framework_path / dir_name).is_dir():
                missing_dirs.append(dir_name)

        if missing_files or missing_dirs:
            return ValidationResult(
                is_valid=False,
                error=f&quot;Missing required files: {missing_files}, directories: {missing_dirs}&quot;
            )

        return ValidationResult(is_valid=True)
</code></pre>
<h2 id="implementation-phases">Implementation Phases</h2>
<h3 id="phase-1-core-plugin-infrastructure-4-6-weeks">Phase 1: Core Plugin Infrastructure (4-6 weeks)</h3>
<p><strong>Week 1-2: Plugin Registry and Base Classes</strong></p>
<pre><code class="language-python"># Deliverables:
- PluginRegistry class with component management
- Abstract base classes (MetricCalculator, WeightingAlgorithm, VisualizationRenderer)
- SecurityValidationFramework with AST analysis
- Basic plugin loading and registration system
</code></pre>
<p><strong>Week 3-4: Metric System Enhancement</strong></p>
<pre><code class="language-python"># Deliverables:
- Extended MetricEngine with custom metric support
- Integration with existing calculation pipeline
- Validation and error handling for custom metrics
- Example implementations (CulturalResonanceCalculator)
</code></pre>
<p><strong>Week 5-6: Framework Package Structure</strong></p>
<pre><code class="language-python"># Deliverables:
- Extended framework.json schema with plugin definitions
- Automatic plugin discovery and loading
- Framework validation pipeline
- Migration tools for existing frameworks
</code></pre>
<h3 id="phase-2-declarative-visualization-system-3-4-weeks">Phase 2: Declarative Visualization System (3-4 weeks)</h3>
<p><strong>Week 1-2: Visualization Engine Architecture</strong></p>
<pre><code class="language-python"># Deliverables:
- Base visualization renderer system
- Parametric visualization definitions (JSON schema)
- Integration with existing Plotly infrastructure
- Support for polar, heatmap, and radial visualizations
</code></pre>
<p><strong>Week 3-4: Custom Visualization Support</strong></p>
<pre><code class="language-python"># Deliverables:
- Custom visualization renderer registration
- Visualization validation and error handling
- Export format support for custom visualizations
- Documentation and examples
</code></pre>
<h3 id="phase-3-advanced-features-and-validation-2-3-weeks">Phase 3: Advanced Features and Validation (2-3 weeks)</h3>
<p><strong>Week 1-2: Performance and Security</strong></p>
<pre><code class="language-python"># Deliverables:
- Comprehensive security validation system
- Performance monitoring and limits
- Resource usage constraints
- Sandbox testing environment
</code></pre>
<p><strong>Week 3: Integration and Testing</strong></p>
<pre><code class="language-python"># Deliverables:
- Full integration with existing system
- Comprehensive test suite for plugin architecture
- Performance benchmarking
- Documentation and migration guides
</code></pre>
<h2 id="migration-strategy">Migration Strategy</h2>
<h3 id="backward-compatibility-plan">Backward Compatibility Plan</h3>
<p><strong>Existing Framework Preservation</strong></p>
<pre><code class="language-python"># All existing frameworks continue working unchanged
frameworks/
├── civic_virtue/           # No changes required
├── political_spectrum/     # No changes required  
├── fukuyama_identity/      # No changes required
└── mft_persuasive_force/   # New plugin-enhanced framework
</code></pre>
<p><strong>Gradual Enhancement Path</strong></p>
<ol>
<li><strong>Phase 1</strong>: Deploy plugin infrastructure alongside existing system</li>
<li><strong>Phase 2</strong>: Create plugin-enhanced versions of existing frameworks</li>
<li><strong>Phase 3</strong>: Migrate user configurations to plugin-enhanced versions</li>
<li><strong>Phase 4</strong>: Deprecate legacy framework loading system</li>
</ol>
<p><strong>Configuration Migration</strong></p>
<pre><code class="language-python">class FrameworkMigrator:
    def migrate_legacy_framework(self, legacy_config: Dict) -&gt; Dict:
        &quot;&quot;&quot;Convert legacy framework config to plugin-enhanced format&quot;&quot;&quot;
        enhanced_config = legacy_config.copy()

        # Add plugin configuration section
        enhanced_config[&quot;plugin_configuration&quot;] = {
            &quot;custom_metrics&quot;: [],
            &quot;weighting_algorithms&quot;: [&quot;default&quot;],
            &quot;visualization_types&quot;: [&quot;elliptical&quot;]
        }

        # Preserve existing well definitions and metrics
        return enhanced_config
</code></pre>
<h3 id="user-experience-continuity">User Experience Continuity</h3>
<p><strong>API Compatibility</strong></p>
<pre><code class="language-python"># Existing API calls continue working
analyzer = NarrativeGravityAnalyzer(&quot;civic_virtue&quot;)
result = analyzer.analyze(narrative_text)

# Enhanced API provides additional options
analyzer = NarrativeGravityAnalyzer(&quot;mft_persuasive_force&quot;)
result = analyzer.analyze(narrative_text, cultural_context=&quot;progressive_urban&quot;)
</code></pre>
<p><strong>UI/UX Preservation</strong></p>
<ul>
<li>Existing Streamlit interface remains unchanged</li>
<li>Plugin-enhanced features appear as optional advanced settings</li>
<li>Framework selection dropdown includes both legacy and enhanced frameworks</li>
<li>Results display adapts automatically to available metrics</li>
</ul>
<h2 id="performance-considerations">Performance Considerations</h2>
<h3 id="computational-overhead">Computational Overhead</h3>
<p><strong>Plugin Loading Optimization</strong></p>
<pre><code class="language-python">class PluginCache:
    &quot;&quot;&quot;Cache compiled plugins to avoid repeated loading&quot;&quot;&quot;

    def __init__(self):
        self._plugin_cache: Dict[str, FrameworkPlugin] = {}
        self._compilation_cache: Dict[str, Any] = {}

    def get_plugin(self, framework_name: str) -&gt; Optional[FrameworkPlugin]:
        if framework_name in self._plugin_cache:
            return self._plugin_cache[framework_name]

        # Load and cache plugin
        plugin = self._load_plugin(framework_name)
        if plugin:
            self._plugin_cache[framework_name] = plugin

        return plugin
</code></pre>
<p><strong>Metric Calculation Efficiency</strong></p>
<pre><code class="language-python">class MetricBatch:
    &quot;&quot;&quot;Batch metric calculations for efficiency&quot;&quot;&quot;

    def calculate_all_metrics(self, 
                              well_scores: Dict[str, float],
                              framework_config: Dict,
                              context: Optional[Dict] = None) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;Calculate all applicable metrics in single pass&quot;&quot;&quot;

        # Identify applicable metrics
        applicable_metrics = self._get_applicable_metrics(framework_config)

        # Batch calculations to minimize redundant operations
        shared_calculations = self._compute_shared_values(well_scores, context)

        results = {}
        for metric_name, calculator in applicable_metrics.items():
            try:
                results[metric_name] = calculator.calculate_with_shared(
                    well_scores, context, shared_calculations
                )
            except Exception as e:
                logger.error(f&quot;Metric {metric_name} calculation failed: {e}&quot;)

        return results
</code></pre>
<h3 id="memory-management">Memory Management</h3>
<p><strong>Resource Monitoring</strong></p>
<pre><code class="language-python">import psutil
import threading
from contextlib import contextmanager

class ResourceMonitor:
    &quot;&quot;&quot;Monitor and limit plugin resource usage&quot;&quot;&quot;

    def __init__(self, max_memory_mb: int = 256, max_cpu_seconds: int = 10):
        self.max_memory = max_memory_mb * 1024 * 1024
        self.max_cpu_seconds = max_cpu_seconds

    @contextmanager
    def monitor_plugin_execution(self, plugin_name: str):
        &quot;&quot;&quot;Context manager for monitoring plugin resource usage&quot;&quot;&quot;
        process = psutil.Process()
        start_memory = process.memory_info().rss
        start_time = time.time()

        try:
            yield
        finally:
            end_memory = process.memory_info().rss
            end_time = time.time()

            memory_used = end_memory - start_memory
            cpu_time = end_time - start_time

            if memory_used &gt; self.max_memory:
                logger.warning(f&quot;Plugin {plugin_name} exceeded memory limit: {memory_used / 1024 / 1024:.1f}MB&quot;)

            if cpu_time &gt; self.max_cpu_seconds:
                logger.warning(f&quot;Plugin {plugin_name} exceeded CPU time limit: {cpu_time:.1f}s&quot;)
</code></pre>
<h2 id="developer-experience">Developer Experience</h2>
<h3 id="framework-creation-workflow">Framework Creation Workflow</h3>
<p><strong>1. Framework Template Generation</strong></p>
<pre><code class="language-bash">$ narrative-gravity create-framework mft_persuasive_force
Creating framework package: mft_persuasive_force
├── framework.json (template generated)
├── dipoles.json (template generated)
├── prompt.md (template generated)
├── plugin.py (template generated)
├── tests/ (test templates generated)
└── docs/ (documentation templates generated)

Framework template created. Edit configuration files and implement custom logic.
</code></pre>
<p><strong>2. Development Environment Setup</strong></p>
<pre><code class="language-python"># frameworks/mft_persuasive_force/plugin.py
from narrative_gravity.plugins import FrameworkPlugin, MetricCalculator
from narrative_gravity.validation import ValidationResult

class MFTFrameworkPlugin(FrameworkPlugin):
    @property
    def metadata(self):
        return PluginMetadata(
            name=&quot;mft_persuasive_force&quot;,
            version=&quot;1.0.0&quot;,
            author=&quot;Research Team&quot;,
            description=&quot;MFT-based persuasive force analysis&quot;,
            plugin_type=PluginType.FRAMEWORK,
            framework_compatibility=[&quot;mft_persuasive_force&quot;],
            python_requirements=[&quot;numpy&gt;=1.20.0&quot;],
            academic_citations=[
                &quot;Haidt, J. (2012). The righteous mind&quot;
            ]
        )

    def register_components(self):
        return {
            PluginType.METRIC_CALCULATOR: {
                &quot;cultural_resonance_score&quot;: CulturalResonanceCalculator,
                &quot;foundation_diversity_index&quot;: FoundationDiversityCalculator
            },
            PluginType.WEIGHTING_ALGORITHM: {
                &quot;cultural_matrix_weighting&quot;: CulturalMatrixWeighting
            }
        }
</code></pre>
<p><strong>3. Testing and Validation</strong></p>
<pre><code class="language-bash">$ narrative-gravity validate-framework mft_persuasive_force
Validating framework package: mft_persuasive_force

✓ Package structure validation passed
✓ Configuration schema validation passed  
✓ Plugin security validation passed
✓ Academic validity validation passed
✓ Test suite validation passed
✓ Performance benchmarking passed

Framework validation successful. Ready for deployment.
</code></pre>
<p><strong>4. Local Testing Environment</strong></p>
<pre><code class="language-python"># frameworks/mft_persuasive_force/tests/test_integration.py
import unittest
from narrative_gravity import NarrativeGravityAnalyzer

class TestMFTFrameworkIntegration(unittest.TestCase):
    def setUp(self):
        self.analyzer = NarrativeGravityAnalyzer(&quot;mft_persuasive_force&quot;)

    def test_cultural_resonance_calculation(self):
        &quot;&quot;&quot;Test cultural resonance metric calculation&quot;&quot;&quot;
        test_narrative = &quot;We must protect our vulnerable communities...&quot;

        result = self.analyzer.analyze(
            test_narrative,
            cultural_context=&quot;progressive_urban&quot;
        )

        self.assertIn(&quot;cultural_resonance_score&quot;, result.metrics)
        self.assertBetween(result.metrics[&quot;cultural_resonance_score&quot;], 0.0, 1.0)

    def test_cross_cultural_comparison(self):
        &quot;&quot;&quot;Test cross-cultural analysis capabilities&quot;&quot;&quot;
        test_narrative = &quot;We must respect traditional authority...&quot;

        results = {}
        for culture in [&quot;progressive_urban&quot;, &quot;conservative_religious&quot;, &quot;rural_traditional&quot;]:
            results[culture] = self.analyzer.analyze(
                test_narrative,
                cultural_context=culture
            )

        # Verify different cultural responses
        progressive_score = results[&quot;progressive_urban&quot;].metrics[&quot;cultural_resonance_score&quot;]
        conservative_score = results[&quot;conservative_religious&quot;].metrics[&quot;cultural_resonance_score&quot;]

        self.assertGreater(conservative_score, progressive_score)
</code></pre>
<h3 id="ide-integration-and-tooling">IDE Integration and Tooling</h3>
<p><strong>VS Code Extension Support</strong></p>
<pre><code class="language-json">{
    &quot;name&quot;: &quot;narrative-gravity-framework-dev&quot;,
    &quot;displayName&quot;: &quot;Narrative Gravity Framework Development&quot;,
    &quot;description&quot;: &quot;Development support for Narrative Gravity Wells frameworks&quot;,
    &quot;version&quot;: &quot;1.0.0&quot;,
    &quot;contributes&quot;: {
        &quot;languages&quot;: [{
            &quot;id&quot;: &quot;framework-json&quot;,
            &quot;aliases&quot;: [&quot;Framework JSON&quot;],
            &quot;extensions&quot;: [&quot;.framework.json&quot;]
        }],
        &quot;jsonValidation&quot;: [{
            &quot;fileMatch&quot;: &quot;*/frameworks/*/framework.json&quot;, 
            &quot;url&quot;: &quot;./schemas/framework-schema.json&quot;
        }],
        &quot;commands&quot;: [{
            &quot;command&quot;: &quot;narrativeGravity.validateFramework&quot;,
            &quot;title&quot;: &quot;Validate Framework Package&quot;
        }]
    }
}
</code></pre>
<p><strong>Schema Validation and Autocomplete</strong></p>
<pre><code class="language-json">{
    &quot;$schema&quot;: &quot;http://json-schema.org/draft-07/schema#&quot;,
    &quot;title&quot;: &quot;Narrative Gravity Framework Configuration&quot;,
    &quot;type&quot;: &quot;object&quot;,
    &quot;required&quot;: [&quot;framework_name&quot;, &quot;version&quot;, &quot;dipoles&quot;, &quot;wells&quot;],
    &quot;properties&quot;: {
        &quot;framework_name&quot;: {
            &quot;type&quot;: &quot;string&quot;,
            &quot;pattern&quot;: &quot;^[a-z][a-z0-9_]*$&quot;,
            &quot;description&quot;: &quot;Unique framework identifier&quot;
        },
        &quot;custom_metrics&quot;: {
            &quot;type&quot;: &quot;array&quot;,
            &quot;items&quot;: {
                &quot;$ref&quot;: &quot;#/definitions/metric_definition&quot;
            }
        }
    },
    &quot;definitions&quot;: {
        &quot;metric_definition&quot;: {
            &quot;type&quot;: &quot;object&quot;,
            &quot;required&quot;: [&quot;name&quot;, &quot;calculator_class&quot;, &quot;output_type&quot;],
            &quot;properties&quot;: {
                &quot;name&quot;: {
                    &quot;type&quot;: &quot;string&quot;,
                    &quot;description&quot;: &quot;Metric identifier&quot;
                },
                &quot;calculator_class&quot;: {
                    &quot;type&quot;: &quot;string&quot;,
                    &quot;description&quot;: &quot;Python class name for metric calculator&quot;
                }
            }
        }
    }
}
</code></pre>
<h2 id="quality-assurance">Quality Assurance</h2>
<h3 id="automated-testing-framework">Automated Testing Framework</h3>
<p><strong>Plugin Validation Pipeline</strong></p>
<pre><code class="language-python">class PluginTestSuite:
    &quot;&quot;&quot;Comprehensive automated testing for framework plugins&quot;&quot;&quot;

    def __init__(self, framework_path: Path):
        self.framework_path = framework_path
        self.test_results = []

    def run_full_test_suite(self) -&gt; 'TestResults':
        &quot;&quot;&quot;Execute all plugin validation tests&quot;&quot;&quot;

        # 1. Static Analysis Tests
        self.test_results.append(self._run_static_analysis())

        # 2. Security Validation Tests
        self.test_results.append(self._run_security_tests())

        # 3. Functional Testing
        self.test_results.append(self._run_functional_tests())

        # 4. Performance Testing
        self.test_results.append(self._run_performance_tests())

        # 5. Integration Testing
        self.test_results.append(self._run_integration_tests())

        # 6. Regression Testing
        self.test_results.append(self._run_regression_tests())

        return TestResults.aggregate(self.test_results)

    def _run_functional_tests(self) -&gt; 'TestResult':
        &quot;&quot;&quot;Test all custom metrics and algorithms&quot;&quot;&quot;
        plugin = self._load_test_plugin()
        test_data = self._generate_test_data()

        results = []

        # Test each custom metric
        for metric_name, calculator in plugin.register_components()[PluginType.METRIC_CALCULATOR].items():
            try:
                # Test with valid inputs
                result = calculator.calculate(test_data[&quot;well_scores&quot;], test_data[&quot;context&quot;])

                # Validate output range
                if hasattr(calculator.definition, 'output_range'):
                    min_val, max_val = calculator.definition.output_range
                    if not (min_val &lt;= result &lt;= max_val):
                        results.append(TestResult(
                            test_name=f&quot;{metric_name}_output_range&quot;,
                            passed=False,
                            error=f&quot;Output {result} outside range [{min_val}, {max_val}]&quot;
                        ))

                # Test input validation
                invalid_inputs = self._generate_invalid_inputs()
                for invalid_input in invalid_inputs:
                    should_reject = not calculator.validate_inputs(**invalid_input)
                    if not should_reject:
                        results.append(TestResult(
                            test_name=f&quot;{metric_name}_input_validation&quot;,
                            passed=False,
                            error=f&quot;Should reject invalid input: {invalid_input}&quot;
                        ))

                results.append(TestResult(
                    test_name=f&quot;{metric_name}_functional_test&quot;,
                    passed=True
                ))

            except Exception as e:
                results.append(TestResult(
                    test_name=f&quot;{metric_name}_functional_test&quot;,
                    passed=False,
                    error=str(e)
                ))

        return TestResult.aggregate(results)
</code></pre>
<h3 id="peer-review-process">Peer Review Process</h3>
<p><strong>Academic Review Workflow</strong></p>
<pre><code class="language-python">class AcademicReviewProcess:
    &quot;&quot;&quot;Framework for academic peer review of framework packages&quot;&quot;&quot;

    def __init__(self):
        self.review_criteria = [
            &quot;theoretical_foundation&quot;,
            &quot;methodological_rigor&quot;, 
            &quot;empirical_validation&quot;,
            &quot;reproducibility&quot;,
            &quot;academic_citations&quot;,
            &quot;ethical_considerations&quot;
        ]

    def initiate_review(self, framework_package: Path, reviewers: List[str]) -&gt; str:
        &quot;&quot;&quot;Start academic review process&quot;&quot;&quot;
        review_id = self._generate_review_id()

        # Package framework for review
        review_package = self._create_review_package(framework_package)

        # Send to reviewers
        for reviewer_email in reviewers:
            self._send_review_request(reviewer_email, review_package, review_id)

        # Create review tracking
        self._create_review_tracking(review_id, framework_package, reviewers)

        return review_id

    def submit_review(self, review_id: str, reviewer_id: str, review_data: Dict) -&gt; bool:
        &quot;&quot;&quot;Submit individual review&quot;&quot;&quot;

        # Validate review completeness
        if not self._validate_review_completeness(review_data):
            return False

        # Store review
        self._store_review(review_id, reviewer_id, review_data)

        # Check if all reviews submitted
        if self._all_reviews_submitted(review_id):
            self._compile_final_review(review_id)

        return True

    def _validate_review_completeness(self, review_data: Dict) -&gt; bool:
        &quot;&quot;&quot;Ensure review covers all required criteria&quot;&quot;&quot;
        required_sections = [
            &quot;theoretical_assessment&quot;,
            &quot;methodological_evaluation&quot;, 
            &quot;technical_implementation_review&quot;,
            &quot;reproducibility_check&quot;,
            &quot;ethical_considerations&quot;,
            &quot;overall_recommendation&quot;
        ]

        return all(section in review_data for section in required_sections)
</code></pre>
<h2 id="future-extensions">Future Extensions</h2>
<h3 id="advanced-plugin-capabilities">Advanced Plugin Capabilities</h3>
<p><strong>Machine Learning Integration</strong></p>
<pre><code class="language-python">class MLEnhancedMetricCalculator(MetricCalculator):
    &quot;&quot;&quot;Base class for ML-enhanced metrics&quot;&quot;&quot;

    def __init__(self, model_path: Optional[Path] = None):
        self.model = self._load_model(model_path) if model_path else None

    def calculate_with_ml_enhancement(self,
                                      well_scores: Dict[str, float],
                                      narrative_text: str,
                                      context: Optional[Dict] = None) -&gt; float:
        &quot;&quot;&quot;Calculate metric using both rule-based and ML approaches&quot;&quot;&quot;

        # Traditional calculation
        base_score = self.calculate(well_scores, context)

        # ML enhancement
        if self.model and narrative_text:
            ml_features = self._extract_ml_features(narrative_text, well_scores, context)
            ml_adjustment = self.model.predict(ml_features)

            # Combine base score with ML adjustment
            enhanced_score = self._combine_scores(base_score, ml_adjustment)
            return enhanced_score

        return base_score
</code></pre>
<p><strong>Real-time Analysis Capabilities</strong></p>
<pre><code class="language-python">class StreamingAnalysisPlugin(FrameworkPlugin):
    &quot;&quot;&quot;Plugin supporting real-time narrative analysis&quot;&quot;&quot;

    def register_streaming_components(self) -&gt; Dict[str, Any]:
        return {
            &quot;stream_processors&quot;: {
                &quot;social_media_stream&quot;: SocialMediaStreamProcessor,
                &quot;news_feed_stream&quot;: NewsFeedStreamProcessor
            },
            &quot;real_time_metrics&quot;: {
                &quot;trending_narratives&quot;: TrendingNarrativesCalculator,
                &quot;narrative_velocity&quot;: NarrativeVelocityCalculator
            }
        }

    def create_stream_analyzer(self, stream_config: Dict) -&gt; 'StreamAnalyzer':
        &quot;&quot;&quot;Create real-time stream analyzer&quot;&quot;&quot;
        return StreamAnalyzer(
            framework=self,
            stream_config=stream_config,
            buffer_size=stream_config.get(&quot;buffer_size&quot;, 1000),
            analysis_interval=stream_config.get(&quot;interval&quot;, 60)
        )
</code></pre>
<p><strong>Cross-Framework Comparison Tools</strong></p>
<pre><code class="language-python">class FrameworkComparator:
    &quot;&quot;&quot;Advanced tools for comparing frameworks and their outputs&quot;&quot;&quot;

    def compare_framework_outputs(self,
                                  narrative: str,
                                  frameworks: List[str],
                                  comparison_metrics: List[str]) -&gt; 'ComparisonResult':
        &quot;&quot;&quot;Compare how different frameworks analyze the same narrative&quot;&quot;&quot;

        results = {}

        for framework_name in frameworks:
            analyzer = NarrativeGravityAnalyzer(framework_name)
            results[framework_name] = analyzer.analyze(narrative)

        # Calculate cross-framework correlations
        correlations = self._calculate_cross_framework_correlations(results, comparison_metrics)

        # Identify framework agreement/disagreement
        consensus_analysis = self._analyze_framework_consensus(results)

        # Generate comparative visualization
        comparison_viz = self._create_comparison_visualization(results)

        return ComparisonResult(
            framework_results=results,
            correlations=correlations,
            consensus_analysis=consensus_analysis,
            visualization=comparison_viz
        )
</code></pre>
<h3 id="ecosystem-development">Ecosystem Development</h3>
<p><strong>Framework Marketplace</strong></p>
<pre><code class="language-python">class FrameworkMarketplace:
    &quot;&quot;&quot;Central repository for community-contributed frameworks&quot;&quot;&quot;

    def __init__(self, registry_url: str):
        self.registry_url = registry_url
        self.local_cache = FrameworkCache()

    def search_frameworks(self, 
                          query: str,
                          filters: Optional[Dict] = None) -&gt; List['FrameworkListing']:
        &quot;&quot;&quot;Search available frameworks by topic, author, or capability&quot;&quot;&quot;

        search_params = {
            &quot;query&quot;: query,
            &quot;filters&quot;: filters or {},
            &quot;sort_by&quot;: &quot;popularity&quot;,
            &quot;limit&quot;: 50
        }

        response = requests.get(f&quot;{self.registry_url}/search&quot;, params=search_params)
        return [FrameworkListing.from_dict(item) for item in response.json()]

    def install_framework(self, framework_id: str, version: str = &quot;latest&quot;) -&gt; bool:
        &quot;&quot;&quot;Install framework from marketplace&quot;&quot;&quot;

        # Download framework package
        package_url = f&quot;{self.registry_url}/packages/{framework_id}/{version}&quot;
        package_data = requests.get(package_url).content

        # Validate package security
        if not self._validate_package_security(package_data):
            logger.error(f&quot;Security validation failed for {framework_id}&quot;)
            return False

        # Install to local frameworks directory
        framework_path = Path(f&quot;frameworks/{framework_id}&quot;)
        self._extract_package(package_data, framework_path)

        # Validate installation
        validator = FrameworkValidator()
        validation_result = validator.validate_framework_package(framework_path)

        if not validation_result.is_valid:
            logger.error(f&quot;Framework validation failed: {validation_result.error}&quot;)
            shutil.rmtree(framework_path)
            return False

        # Update local registry
        self.local_cache.register_framework(framework_id, version, framework_path)

        return True
</code></pre>
<p><strong>Community Contribution Tools</strong></p>
<pre><code class="language-python">class FrameworkContributor:
    &quot;&quot;&quot;Tools for contributing frameworks to the community&quot;&quot;&quot;

    def package_framework(self, framework_path: Path) -&gt; Path:
        &quot;&quot;&quot;Package framework for distribution&quot;&quot;&quot;

        # Validate framework completeness
        validator = FrameworkValidator()
        validation_result = validator.validate_framework_package(framework_path)

        if not validation_result.is_valid:
            raise ValueError(f&quot;Framework validation failed: {validation_result.error}&quot;)

        # Create distribution package
        package_path = self._create_distribution_package(framework_path)

        # Generate package metadata
        metadata = self._generate_package_metadata(framework_path)

        # Sign package for authenticity
        signature = self._sign_package(package_path)

        return package_path

    def submit_framework(self, 
                         package_path: Path,
                         submission_metadata: Dict) -&gt; str:
        &quot;&quot;&quot;Submit framework to community marketplace&quot;&quot;&quot;

        # Upload package
        upload_response = self._upload_package(package_path)

        # Submit for review
        review_request = {
            &quot;package_id&quot;: upload_response[&quot;package_id&quot;],
            &quot;metadata&quot;: submission_metadata,
            &quot;author_info&quot;: self._get_author_info(),
            &quot;review_level&quot;: &quot;community&quot;  # or &quot;academic&quot; for academic review
        }

        review_response = requests.post(
            f&quot;{self.marketplace_url}/submit&quot;,
            json=review_request
        )

        return review_response.json()[&quot;submission_id&quot;]
</code></pre>
<h2 id="resource-requirements">Resource Requirements</h2>
<h3 id="development-resources">Development Resources</h3>
<p><strong>Personnel Requirements</strong></p>
<ul>
<li><strong>Senior Software Engineer</strong>: 0.8 FTE for 12 weeks (plugin architecture, security)</li>
<li><strong>Research Software Engineer</strong>: 0.6 FTE for 8 weeks (visualization system, integration)</li>
<li><strong>Academic Researcher</strong>: 0.3 FTE for 16 weeks (validation, documentation)</li>
<li><strong>QA Engineer</strong>: 0.4 FTE for 6 weeks (testing, validation pipeline)</li>
</ul>
<p><strong>Total Estimated Effort</strong>: ~40 person-weeks</p>
<h3 id="infrastructure-requirements">Infrastructure Requirements</h3>
<p><strong>Development Environment</strong></p>
<ul>
<li>Enhanced CI/CD pipeline with plugin validation</li>
<li>Expanded test infrastructure for cross-framework validation</li>
<li>Security scanning and analysis tools</li>
<li>Performance monitoring and benchmarking systems</li>
</ul>
<p><strong>Storage and Compute</strong></p>
<ul>
<li>Additional 50GB storage for framework packages and caches</li>
<li>Increased memory allocation for parallel framework testing</li>
<li>Sandbox environments for plugin security validation</li>
</ul>
<h3 id="budget-estimation">Budget Estimation</h3>
<p><strong>Development Phase</strong> (12 weeks)</p>
<ul>
<li>Personnel: \$180,000 (blended rates)</li>
<li>Infrastructure: \$5,000 (enhanced CI/CD, security tools)</li>
<li>External Security Audit: \$15,000</li>
<li>Academic Review Process: \$8,000</li>
</ul>
<p><strong>Total Estimated Cost</strong>: \$208,000</p>
<p><strong>Post-Launch Maintenance</strong> (Annual)</p>
<ul>
<li>Framework review and validation: \$25,000</li>
<li>Community support and marketplace maintenance: \$15,000</li>
<li>Security updates and monitoring: \$10,000</li>
</ul>
<p><strong>Annual Maintenance Cost</strong>: \$50,000</p>
<hr />
<h2 id="conclusion">Conclusion</h2>
<p>The Plugin Architecture Enhancement represents a transformative evolution of the Narrative Gravity Wells system, enabling unlimited innovation in political narrative analysis while maintaining the academic rigor and reliability that distinguishes the platform. By implementing this architecture after successful validation studies, the project can evolve from a specific analytical tool into a platform for building analytical tools—creating lasting value for the academic community and establishing a foundation for continued innovation in computational political communication research.</p>
<p>The comprehensive specification provided here ensures that when the time comes for implementation, the development team will have a clear roadmap for creating a secure, efficient, and academically rigorous plugin system that respects both the technical constraints of software development and the methodological requirements of academic research.</p>
<p><strong>Implementation Recommendation</strong>: Proceed with current validation studies using existing architecture, then implement this plugin enhancement as a post-publication priority to maximize both academic impact and long-term system sustainability.</p>
<div style="text-align: center">⁂</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>