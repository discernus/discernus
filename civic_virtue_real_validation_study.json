{
  "experiment_meta": {
    "name": "Civic_Virtue_Real_Validation_Study",
    "description": "End-to-end validation of comprehensive experiment orchestrator with real LLM analysis using civic virtue framework. Tests complete pipeline from corpus management through academic audit trails.",
    "version": "v1.0.0",
    "created": "2025-06-17T00:20:00Z",
    "hypotheses": [
      "H1: Comprehensive experiment orchestrator produces consistent civic virtue analysis across multiple runs with real LLM integration",
      "H2: Academic audit trails capture complete research metadata suitable for institutional publication requirements",
      "H3: Quality assurance system effectively validates real LLM outputs and detects analytical inconsistencies",
      "H4: Context propagation maintains research integrity throughout the analysis pipeline with actual API calls",
      "H5: Corpus integrity validation and auto-registration work correctly with real filesystem-database synchronization"
    ],
    "research_context": "Validation study to demonstrate production readiness of the comprehensive experiment orchestrator system. Tests integration of all five phases: component validation, auto-registration, corpus management, context propagation, and comprehensive logging with real LLM analysis.",
    "success_criteria": [
      "All 6 conservative dignity texts successfully processed with real GPT-4o analysis",
      "Civic virtue scores generated within expected ranges (0.0-1.0) with meaningful variance",
      "Academic audit trail meets institutional compliance requirements with complete metadata",
      "Quality assurance system flags any analytical anomalies or API failures",
      "Context propagation preserves experiment metadata throughout analysis pipeline",
      "Corpus integrity validation passes with SHA-256 hash verification",
      "Cost controls prevent API spending above $5.00 total for complete study",
      "Reproducibility package generated with complete replication materials"
    ],
    "tags": ["validation", "civic_virtue", "real_llm", "orchestrator", "phase_6"],
    "principal_investigator": "Research Validation Team",
    "institution": "Narrative Gravity Research Initiative",
    "ethical_clearance": "IRB-2025-VALIDATION-001",
    "funding_source": "Platform Development Grant #NGR-2025-VALIDATION",
    "data_classification": "unclassified",
    "publication_intent": true
  },
  "components": {
    "frameworks": [
      {
        "id": "civic_virtue",
        "version": "v2025.06.14",
        "file_path": "frameworks/civic_virtue/framework_consolidated.json",
        "validation_required": true
      }
    ],
    "prompt_templates": [
      {
        "id": "hierarchical_analysis",
        "version": "v2.1",
        "description": "Hierarchical analysis template for multi-tier civic virtue evaluation"
      }
    ],
    "weighting_schemes": [
      {
        "id": "winner_take_most",
        "version": "v2.1",
        "description": "Winner-take-most weighting with amplification factor 1.5"
      }
    ],
    "models": [
      {
        "id": "gpt-4o",
        "provider": "openai",
        "cost_limit_per_request": 0.50,
        "total_cost_limit": 5.00,
        "retry_attempts": 3,
        "timeout_seconds": 60
      }
    ],
    "corpus": [
      {
        "id": "conservative_dignity_validation",
        "file_path": "corpus/validation_set/conservative_dignity",
        "pattern": "*.txt",
        "description": "Conservative dignity validation corpus with 6 curated texts",
        "integrity_validation": true,
        "auto_registration": true
      }
    ]
  },
  "execution": {
    "description": "Comprehensive validation study with multiple runs for consistency testing",
    "cost_controls": {
      "max_total_cost": 5.00,
      "cost_per_analysis_limit": 0.50,
      "cost_tracking": true,
      "fail_on_limit_exceeded": true
    },
    "quality_assurance": {
      "enable_qa_validation": true,
      "qa_confidence_threshold": 70.0,
      "qa_validation_layers": ["schema", "content", "scoring", "positioning", "consistency", "metadata"],
      "fail_on_qa_errors": false,
      "log_qa_warnings": true
    },
    "academic_compliance": {
      "require_ethical_clearance": true,
      "require_pi_authorization": true,
      "generate_reproducibility_package": true,
      "track_institutional_metadata": true
    },
    "matrix": [
      {
        "run_id": "conservative_dignity_run_1",
        "framework": "civic_virtue",
        "prompt_template": "hierarchical_analysis",
        "weighting_scheme": "winner_take_most",
        "model": "gpt-4o",
        "corpus": "conservative_dignity_validation",
        "description": "Primary validation run testing all conservative dignity texts",
        "context_enrichment": true,
        "hypothesis_tracking": true
      },
      {
        "run_id": "conservative_dignity_run_2",
        "framework": "civic_virtue",
        "prompt_template": "hierarchical_analysis", 
        "weighting_scheme": "winner_take_most",
        "model": "gpt-4o",
        "corpus": "conservative_dignity_validation",
        "description": "Consistency validation run for reliability testing",
        "context_enrichment": true,
        "hypothesis_tracking": true
      },
      {
        "run_id": "conservative_dignity_run_3",
        "framework": "civic_virtue",
        "prompt_template": "hierarchical_analysis",
        "weighting_scheme": "winner_take_most", 
        "model": "gpt-4o",
        "corpus": "conservative_dignity_validation",
        "description": "Final validation run for triangulation",
        "context_enrichment": true,
        "hypothesis_tracking": true
      }
    ],
    "validation_parameters": {
      "minimum_successful_analyses": 15,
      "maximum_allowed_failures": 3,
      "consistency_tolerance": 0.15,
      "expected_dignity_score_range": [0.4, 0.9],
      "expected_tribalism_score_range": [0.1, 0.6],
      "narrative_positioning_validation": true
    }
  },
  "expected_outputs": {
    "analysis_results": {
      "total_analyses": 18,
      "format": "structured_json",
      "include_qa_metadata": true,
      "include_academic_metadata": true
    },
    "academic_exports": {
      "r_analysis_script": true,
      "stata_data_file": true,
      "csv_export": true,
      "data_dictionary": true,
      "reproducibility_package": true
    },
    "validation_reports": {
      "hypothesis_validation_report": true,
      "consistency_analysis": true,
      "quality_assurance_summary": true,
      "academic_compliance_report": true,
      "cost_analysis": true
    },
    "logging_outputs": {
      "structured_experiment_log": "logs/civic_virtue_validation_experiment.log",
      "academic_audit_trail": true,
      "reproducibility_metadata": true,
      "institutional_compliance_package": true
    }
  },
  "success_validation": {
    "required_completions": {
      "successful_analyses": 15,
      "qa_validations_passed": 15,
      "corpus_integrity_checks": 6,
      "academic_compliance_checks": 3
    },
    "quality_thresholds": {
      "minimum_qa_confidence": 70.0,
      "maximum_cost_variance": 0.20,
      "consistency_score_minimum": 0.85,
      "narrative_positioning_accuracy": 0.90
    },
    "academic_requirements": {
      "complete_audit_trail": true,
      "institutional_metadata": true,
      "reproducibility_package": true,
      "ethical_compliance_documented": true
    }
  },
  "metadata": {
    "orchestrator_version": "v1.0.0",
    "experiment_schema_version": "v2.0.0",
    "created_by": "comprehensive_experiment_orchestrator",
    "validation_study": true,
    "real_llm_integration": true,
    "estimated_duration_minutes": 15,
    "estimated_cost_usd": 3.50
  }
} 