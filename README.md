# Discernus: Computational Text Analysis Platform

**Philosophy**: "Thick LLM + Thin Software = Epistemic Trust"

## 📚 Documentation

tbd

## 🚀 Quick Start

tbd

## 🏗️ THIN Architecture Principles

### ✅ **THIN Patterns (Do This)**
- **LLM Intelligence**: Analysis, reasoning, and content generation in prompts
- **Software Infrastructure**: Simple routing, storage, and execution
- **Natural Language Flow**: LLM-to-LLM communication without parsing
- **Centralized Prompts**: Prompts are engineered as part of the agent that consumes them, not hardcoded.

### ❌ **THICK Anti-Patterns (Don't Do This)**
- Complex JSON parsing from LLM responses
- Hardcoded prompts in orchestrator code
- Mathematical operations in software (use hybrid intelligence pattern)
- Domain-specific assumptions in core platform

## 🎯 Three Foundational Commitments

1. **Structured Data, Not Code**: LLMs are prompted to return structured, verifiable data (e.g., JSON with scores) rather than executable code for analysis, which simplifies the pipeline and improves reliability.
2. **Cost Transparency**: Upfront estimation, budget controls, predictable pricing
3. **Complete Reproducibility**: Zero mystery, full audit trails, deterministic results

## 📋 Commands

tbd

## 🛠️ Development Tools

tbd


## 🔗 Key Resources

tbd
---

