# THIN Architecture Rules - Cursor AI must follow these STRICTLY

## ðŸš¨ CRITICAL: ENVIRONMENT MANAGEMENT RULES
- **ALWAYS use `source venv/bin/activate` before ANY Python command**
- **NEVER run `pip install` without venv activated**  
- **NEVER run `python` - ALWAYS use `python3`**
- **NEVER modify venv directly - only through pip install/uninstall**
- **If imports fail, install missing packages, do NOT recreate venv**
- **Check `which python3` shows venv path before running code**

## âœ… REQUIRED ENVIRONMENT PATTERNS:
```bash
# ALWAYS start Python commands this way:
source venv/bin/activate && python3 your_script.py

# ALWAYS install packages this way:
source venv/bin/activate && pip install package_name

# ALWAYS check environment this way:
which python3  # Should show: /path/to/project/venv/bin/python3
```

## ðŸš« FORBIDDEN ENVIRONMENT PATTERNS:
- python (use python3)
- pip install without activating venv
- Recreating venv unless explicitly requested
- Running system python for project code
- Modifying venv files directly

## ðŸš¨ FORBIDDEN PATTERNS - NEVER write these:
- import re, regex, bs4, xml.etree (use LLM for parsing instead)
- def parse_*, extract_*, validate_*, analyze_* (use LLM calls instead)
- More than 3 if/elif statements in a function (use LLM logic instead)
- String manipulation like .split(), .replace(), .strip() (use LLM formatting instead)
- Complex try/except blocks with multiple handlers (use LLM error recovery)
- Regex patterns, string parsing, content validation (use LLM processing)

## âœ… REQUIRED PATTERNS - ALWAYS write these:
- Read file â†’ pass to LLM â†’ store result (simple orchestration)
- Route message â†’ call LLM â†’ store response (no processing)
- Maximum 50 lines per function/class (complexity limit)
- Use llm_client.call_llm() for ANY content processing
- Simple file operations, Redis pub-sub, basic routing only
- Store raw LLM responses, don't parse or validate them

## ðŸ¤” BEFORE WRITING ANY CODE, ASK:
1. Could an LLM solve this problem better?
2. Am I building intelligence into software? (Should be NO)
3. Is this simple orchestration/routing? (Should be YES)
4. Am I parsing or validating content? (Should be NO)
5. Could I explain this to a non-programmer? (Should be YES)

## ðŸŽ¯ THIN SUCCESS PATTERNS:
```python
# GOOD - THIN pattern
def load_framework(path):
    content = Path(path).read_text()
    validation = llm_client.call_llm(f"Validate this framework: {content}")
    return {'content': content, 'validation': validation}

# BAD - THICK pattern  
def load_framework(path):
    content = Path(path).read_text()
    if not re.search(r'dimensions?:', content):
        raise ValueError("Missing dimensions")
    # ... complex parsing logic
```

## ðŸ›‘ IF YOU START WRITING PARSING/VALIDATION LOGIC, STOP!
Use LLM calls instead. The software orchestrates, the LLM provides intelligence.

## ðŸš€ SOAR 2.0 SPECIFIC:
- Use Redis pub-sub for agent coordination
- Framework specifications pass to LLM agents as-is
- Store ensemble results without processing
- Let LLMs handle framework application and validation 