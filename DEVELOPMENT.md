# Development Guide

## ğŸš¨ **START HERE: MANDATORY AI ASSISTANT RULES**

**â— If you are an AI assistant working on this project, you MUST follow these rules:**

```bash
# BEFORE suggesting ANY development work:
python3 scripts/applications/check_existing_systems.py "what you want to build"
```

**ğŸ“š REQUIRED READING:**
- `.ai_assistant_rules.md` - **MANDATORY** rules for AI assistants
- `docs/EXISTING_SYSTEMS_INVENTORY.md` - What already exists
- `docs/CODE_ORGANIZATION_STANDARDS.md` - Where things belong

---

## ğŸ—ï¸ **Development Environment**

### **ğŸ–¥ï¸ Recommended: Local Development (Active Development Phase)**

**Why Local Development Now:**
- âš¡ Faster iteration cycles during refactoring
- ğŸ” Easier debugging and IDE integration
- ğŸ“ Direct file system access (no sync issues)
- ğŸ§ª Simplified testing workflow

**Setup:**
```bash
# 1. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set up local environment
cp env.example .env
# Edit .env with local database settings

# 4. Run tests
python3 -m pytest tests/unit/ -v
```

### **ğŸ³ Docker (CI/CD and Final Validation)**

**When to Use Docker:**
- âœ… Final integration testing before commits
- âœ… Production deployment simulation
- âœ… CI/CD pipeline (GitHub Actions)
- âœ… Environment consistency validation

**Quick Docker Validation:**
```bash
# Validate your changes work in Docker before committing
docker-compose up -d
docker-compose run --rm app python3 -m pytest tests/unit/ -v
docker-compose down
```

---

## ğŸ”„ **Development Workflow**

### **For AI Assistants:**
1. **Search First**: `python3 scripts/applications/check_existing_systems.py "functionality"`
2. **Enhance Don't Replace**: Use existing production systems when possible
3. **Build in Experimental**: New code goes in `experimental/` first
4. **Test Locally**: `python3 -m pytest tests/unit/ -v`
5. **Validate in Docker**: Quick Docker validation before commits

### **For Human Developers:**
1. **Search First**: Check existing systems before building
2. **Follow Guided Workflow**: `python3 scripts/production/new_development_workflow.py`
3. **Build in Experimental**: Prototype in `experimental/` first
4. **Test Locally**: Fast local testing during development
5. **Docker Validation**: Final validation in containerized environment

---

## ğŸ—ï¸ **Development Architecture**

### **âœ… Production Code (Use These)**
- `src/narrative_gravity/` - Core production systems
- `scripts/production/` - Production-ready scripts
- `docs/specifications/` - Production documentation

### **ğŸ§ª Experimental Code (Build Here First)**
- `experimental/prototypes/` - New development starts here
- `sandbox/` - Personal experimental space

### **ğŸ—‘ï¸ Deprecated Code (Never Use)**
- `deprecated/` - Obsolete systems (**DO NOT USE**)
- Any file with `# DEPRECATED` comments

---

## ğŸ›¡ï¸ **Quality Assurance**

### **Existing Production QA Systems (USE THESE):**
- `LLMQualityAssuranceSystem` - 6-layer mathematical validation
- `ComponentQualityValidator` - 15+ quality checks  
- `QAEnhancedDataExporter` - Academic export with QA

### **âŒ Deprecated QA Systems (NEVER USE):**
- "AI Academic Advisor" - Just file existence checks (moved to deprecated/)

---

## ğŸ“Š **Key Production Systems**

### **Experiment Execution:**
- `scripts/production/execute_experiment_definition.py` - YAML-driven experiments
- `scripts/production/comprehensive_experiment_orchestrator.py` - Multi-phase orchestration

### **Data & Analysis:**
- `src/narrative_gravity/academic/data_export.py` - Academic data export
- `src/narrative_gravity/cli/academic_analysis_pipeline.py` - Complete workflow

### **Framework Management:**
- `src/narrative_gravity/framework_manager.py` - Framework loading/management

---

## ğŸ—„ï¸ **Database Configuration**

### **Local Development:**
```bash
# Option 1: Local PostgreSQL
brew install postgresql  # macOS
sudo apt-get install postgresql  # Ubuntu
# Update .env: DATABASE_URL=postgresql://postgres:password@localhost:5432/discernus

# Option 2: SQLite (for simple testing)
# Update .env: DATABASE_URL=sqlite:///discernus.db
```

### **Docker (Final Validation):**
```bash
# Uses Docker Compose managed PostgreSQL
docker-compose up -d db  # Start just the database
# App connects to Docker-managed database
```

---

## ğŸš¨ **Common AI Assistant Violations**

**âŒ VIOLATION**: "Let's build a new QA system"
**âœ… CORRECT**: "Let's enhance the existing LLMQualityAssuranceSystem"

**âŒ VIOLATION**: Using "AI Academic Advisor" 
**âœ… CORRECT**: Using LLMQualityAssuranceSystem (production 6-layer validation)

**âŒ VIOLATION**: Creating files directly in `src/`
**âœ… CORRECT**: Prototyping in `experimental/` first

**âŒ VIOLATION**: Building without searching for existing systems
**âœ… CORRECT**: Always search production systems first

---

## ğŸ¯ **Success Metrics**

A successful development session:
- âœ… Searched production systems before building
- âœ… Enhanced existing systems when possible  
- âœ… Built new development in experimental/ first
- âœ… Fast local testing during development
- âœ… Docker validation before commits
- âœ… Followed clean code organization standards
- âœ… Never referenced deprecated code

---

## ğŸ”„ **Path to Full Containerization**

**This hybrid approach maintains containerization readiness:**
- ğŸ“‹ All dependencies tracked in `requirements.txt`
- ğŸ”§ Docker files maintained and tested
- ğŸ§ª Regular Docker validation prevents drift
- ğŸ“¦ Easy transition back to Docker-first when stability increases

**ğŸ›¡ï¸ These rules exist because this project has repeatedly wasted time rebuilding inferior versions of existing sophisticated systems. Following these rules prevents that waste.** 