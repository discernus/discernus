#!/usr/bin/env python3
"""
Unit Tests for Enhanced Framework Validator
==========================================

Tests each component of the enhanced framework validator in isolation
to ensure proper functionality before running full integration.
"""

import unittest
import sys
import json
import tempfile
from pathlib import Path
from typing import Dict, List, Any
from unittest.mock import patch, MagicMock, mock_open

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Add framework_researcher to path
sys.path.insert(0, str(Path(__file__).parent))

from enhanced_framework_validator import EnhancedFrameworkValidator

class TestEnhancedFrameworkValidator(unittest.TestCase):
    """Test cases for the Enhanced Framework Validator."""

    def setUp(self):
        """Set up test fixtures."""
        self.validator = EnhancedFrameworkValidator()
        self.test_framework_path = "test_framework.md"
        
        # Mock framework content
        self.mock_framework_content = """# Test Framework
---
title: Test Framework
version: 1.0.0
description: A test framework for validation
---

## Analysis Prompt
Test analysis prompt content.

## Output Schema
- dimension1: float
- dimension2: float
"""

    def test_initialization(self):
        """Test that the enhanced validator initializes correctly."""
        self.assertIsNotNone(self.validator.original_validator)
        self.assertIsNotNone(self.validator.llm_gateway)
        self.assertEqual(self.validator.academic_model, "vertex_ai/gemini-2.5-pro")

    @patch('enhanced_framework_validator.FrameworkValidator')
    def test_validate_structure_with_original_validator(self, mock_framework_validator):
        """Test that structural validation uses the original FrameworkValidator."""
        # Mock the original validator
        mock_validator_instance = MagicMock()
        mock_framework_validator.return_value = mock_validator_instance
        
        # Mock validation result
        mock_result = MagicMock()
        mock_result.success = True
        mock_result.framework_name = "Test Framework"
        mock_result.framework_version = "1.0.0"
        mock_result.issues = []
        mock_validator_instance.validate_framework.return_value = mock_result
        
        # Replace the validator's original_validator with our mock
        self.validator.original_validator = mock_validator_instance
        
        # Test structural validation
        result = self.validator._validate_structure(self.test_framework_path, verbose=False)
        
        # Verify original validator was called
        mock_validator_instance.validate_framework.assert_called_once()
        
        # Verify result structure
        self.assertEqual(result['status'], 'PASSED')
        self.assertEqual(result['structural_score'], 10.0)
        self.assertEqual(result['summary'], 'Framework validation passed')

    @patch('enhanced_framework_validator.FrameworkValidator')
    def test_validate_structure_with_issues(self, mock_framework_validator):
        """Test structural validation when issues are found."""
        # Mock the original validator
        mock_validator_instance = MagicMock()
        mock_framework_validator.return_value = mock_validator_instance
        
        # Mock validation result with issues
        mock_result = MagicMock()
        mock_result.success = False  # This sets initial score to 0.0
        mock_result.framework_name = "Test Framework"
        mock_result.framework_version = "1.0.0"
        
        # Create mock issues
        mock_issue1 = MagicMock()
        mock_issue1.priority = 'BLOCKING'
        mock_issue1.description = 'Critical issue'
        mock_issue1.impact = 'Blocks execution'
        mock_issue1.fix = 'Fix required'
        
        mock_issue2 = MagicMock()
        mock_issue2.priority = 'QUALITY'
        mock_issue2.description = 'Quality issue'
        mock_issue2.impact = 'Reduces quality'
        mock_issue2.fix = 'Improve quality'
        
        mock_result.issues = [mock_issue1, mock_issue2]
        mock_validator_instance.validate_framework.return_value = mock_result
        
        # Replace the validator's original_validator with our mock
        self.validator.original_validator = mock_validator_instance
        
        # Test structural validation
        result = self.validator._validate_structure(self.test_framework_path, verbose=False)
        
        # Debug output
        print(f"DEBUG: Result status: {result['status']}")
        print(f"DEBUG: Result score: {result['structural_score']}")
        print(f"DEBUG: Result issues: {result['issues']}")
        
        # Verify result structure
        self.assertEqual(result['status'], 'FAILED')
        # When success=False, initial score is 0.0, BLOCKING issue keeps it at 0.0
        # But QUALITY issue might adjust it: max(5.0, 0.0 - 2.0) = max(5.0, -2.0) = 5.0
        self.assertEqual(result['structural_score'], 5.0)  # Adjusted for QUALITY issue
        self.assertEqual(len(result['issues']), 2)
        self.assertEqual(result['issues'][0]['type'], 'BLOCKING')
        self.assertEqual(result['issues'][1]['type'], 'QUALITY')

    def test_extract_theoretical_content(self):
        """Test extraction of theoretical content from framework."""
        with patch('builtins.open', mock_open(read_data=self.mock_framework_content)):
            content = self.validator._extract_theoretical_content(self.test_framework_path)
            self.assertIn("Test Framework", content)
            self.assertIn("test framework for validation", content)

    def test_integrate_validation_results(self):
        """Test integration of structural and academic validation results."""
        structural_results = {
            'status': 'PASSED',
            'structural_score': 8.0,
            'issues': []
        }
        
        academic_results = {
            'academic_credibility_score': 7.0,
            'confidence_level': 'MEDIUM'
        }
        
        integrated = self.validator._integrate_validation_results(structural_results, academic_results)
        
        # Verify integration
        self.assertEqual(integrated['overall_score'], 7.6)  # (8.0 * 0.6) + (7.0 * 0.4)
        self.assertEqual(integrated['overall_status'], 'GOOD')
        self.assertEqual(integrated['structural_weight'], 0.6)
        self.assertEqual(integrated['academic_weight'], 0.4)

    def test_integrate_validation_results_no_academic(self):
        """Test integration when academic validation is skipped."""
        structural_results = {
            'status': 'PASSED',
            'structural_score': 8.0,
            'issues': []
        }
        
        integrated = self.validator._integrate_validation_results(structural_results, None)
        
        # Verify integration with no academic results
        self.assertEqual(integrated['overall_score'], 4.8)  # (8.0 * 0.6) + (0 * 0.4)
        self.assertEqual(integrated['overall_status'], 'FAIR')
        self.assertEqual(integrated['confidence_level'], 'UNKNOWN')

    def test_generate_integrated_recommendations(self):
        """Test generation of integrated recommendations."""
        structural_results = {
            'issues': [
                {'fix': 'Fix structural issue'},
                {'fix': 'Improve quality'}
            ]
        }
        
        academic_results = {
            'recommendations': 'Strengthen academic foundations'
        }
        
        recommendations = self.validator._generate_integrated_recommendations(
            structural_results, academic_results
        )
        
        self.assertIn('Fix structural issue', recommendations)
        self.assertIn('Improve quality', recommendations)
        self.assertIn('Strengthen academic foundations', recommendations)

    def test_generate_integrated_recommendations_no_issues(self):
        """Test recommendations when no issues are found."""
        structural_results = {'issues': []}
        academic_results = None
        
        recommendations = self.validator._generate_integrated_recommendations(
            structural_results, academic_results
        )
        
        self.assertIn('Complete academic validation', recommendations)

    def test_get_timestamp(self):
        """Test timestamp generation."""
        timestamp = self.validator._get_timestamp()
        self.assertIsInstance(timestamp, str)
        self.assertGreater(len(timestamp), 0)

    def test_generate_enhanced_report_with_research(self):
        """Test that enhanced report generation includes research synthesis and librarian research"""
        # Mock data
        framework_path = "test_framework.md"
        structural_results = {
            'status': 'PASSED',
            'structural_score': 8.0,
            'summary': 'Framework validation passed',
            'issues': []
        }
        academic_results = {
            'academic_credibility_score': 7,
            'confidence_level': 'HIGH',
            'theoretical_validation': 'Strong theoretical foundations',
            'literature_coverage': 'Good coverage',
            'research_gaps': 'Minor gaps identified',
            'methodological_validation': 'Methodologically sound',
            'recommendations': ['Improve citations', 'Expand examples']
        }
        integrated_results = {
            'overall_score': 7.5,
            'overall_status': 'GOOD',
            'confidence_level': 'HIGH',
            'recommendations': 'Framework is well-structured and academically sound'
        }
        research_directions = {
            'research_questions': [
                {
                    'priority': 1,
                    'question': 'Test research question 1',
                    'rationale': 'Test rationale 1',
                    'expected_outcomes': 'Test outcomes 1',
                    'methodology_suggestions': 'Test methodology 1'
                }
            ],
            'overall_research_strategy': 'Test research strategy',
            'academic_impact': 'Test academic impact'
        }
        librarian_research = {
            'framework_path': 'test_framework.md',
            'total_questions': 1,
            'research_file_path': 'test_research.md',
            'research_results': [
                {
                    'priority': 1,
                    'question': 'Test research question 1',
                    'status': 'COMPLETED',
                    'summary': 'Test research summary',
                    'findings': 'Test research findings',
                    'detailed_report_path': 'test_detailed_report.md'
                }
            ],
            'synthesis': {
                'theoretical_insights': 'Test theoretical insights',
                'literature_alignment': 'Test literature alignment',
                'theoretical_gaps': 'Test theoretical gaps',
                'improvement_recommendations': 'Test improvement recommendations',
                'research_gaps': 'Test research gaps'
            }
        }
        
        # Generate report
        report = self.validator._generate_enhanced_report(
            framework_path, structural_results, academic_results, 
            integrated_results, False, research_directions, librarian_research
        )
        
        # Verify report contains all expected sections
        self.assertIn('## ðŸ“‹ Phase 1: Structural Validation', report)
        self.assertIn('## ðŸ“š Phase 2: Academic Validation', report)
        self.assertIn('## ðŸŽ¯ Phase 3: Integrated Assessment', report)
        self.assertIn('## ðŸ”¬ Phase 4: Research Directions & Librarian Research', report)
        self.assertIn('## ðŸ“Š Validation Summary', report)
        
        # Verify research directions are included
        self.assertIn('Test research question 1', report)
        self.assertIn('Test research strategy', report)
        self.assertIn('Test academic impact', report)
        
        # Verify librarian research is included
        self.assertIn('## ðŸ”¬ Librarian Research Executed', report)
        self.assertIn('Test research summary', report)
        self.assertIn('Test research findings', report)
        self.assertIn('Test theoretical insights', report)
        self.assertIn('Test literature alignment', report)
        self.assertIn('Test improvement recommendations', report)
        
        # Verify overall structure
        self.assertIn('Enhanced validation with structural + academic assessment + research synthesis', report)

if __name__ == '__main__':
    unittest.main()
