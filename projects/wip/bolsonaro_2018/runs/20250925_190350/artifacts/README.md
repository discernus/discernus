# README: Discernus Experiment - `bolsonaro_2018`

This document serves as a comprehensive guide and record for the Discernus research experiment titled `bolsonaro_2018`. It provides an overview of the experiment, details its structure, inventories its generated artifacts, and offers instructions for researchers and auditors seeking to understand, reproduce, or extend this work.

---

## Table of Contents

1.  [Experiment Overview](#1-experiment-overview)
2.  [Experiment Details](#2-experiment-details)
3.  [Directory Structure](#3-directory-structure)
4.  [Artifact Inventory and Descriptions](#4-artifact-inventory-and-descriptions)
    *   [Core Experiment Definitions](#41-core-experiment-definitions)
    *   [Corpus Management](#42-corpus-management)
    *   [Analysis Outputs](#43-analysis-outputs)
    *   [Reporting and Validation](#44-reporting-and-validation)
    *   [Run Context](#45-run-context)
5.  [Provenance Information](#5-provenance-information)
6.  [Usage Instructions for Researchers and Auditors](#6-usage-instructions-for-researchers-and-auditors)
7.  [Discoverability and Auditability](#7-discoverability-and-auditability)

---

## 1. Experiment Overview

This Discernus experiment, `bolsonaro_2018`, was conducted to analyze a specific corpus of documents related to the 2018 Bolsonaro campaign/period. The experiment leverages the Discernus framework to perform structured analysis, evidence extraction, and scoring, culminating in a final synthesis report and statistical analysis. This README aims to make the experiment's outputs transparent, accessible, and fully auditable.

---

## 2. Experiment Details

The following provides key metadata for this specific experiment run:

*   **Experiment Name**: `bolsonaro_2018`
*   **Framework Used**: `unknown_framework` (Specific version/configuration details may be found in `framework` and `run_context` artifacts)
*   **Corpus Name**: `unknown_corpus` (Specific details may be found in `corpus_manifest` artifact)
*   **Documents Processed**: 12 (Based on `corpus_document` artifact count. The `Documents: 0` in the initial overview may refer to an initial state or a generic placeholder.)
*   **Run ID**: `bolsonaro_2018_20250925_150351`
*   **Completion Date**: `2025-09-25T19:03:51.019037+00:00`
*   **Experiment Directory**: `/Volumes/code/discernus/projects/wip/bolsonaro_2018`

---

## 3. Directory Structure

The experiment's output is organized within the designated directory to ensure logical grouping and ease of navigation. The structure generally follows the Discernus artifact types.

```
/Volumes/code/discernus/projects/wip/bolsonaro_2018/
├── experiment_spec/              # Defines the experiment's parameters and methodology
├── framework/                    # Details about the Discernus framework configuration
├── corpus_manifest/              # Manifest of all documents in the corpus
├── corpus_document/              # Individual documents from the corpus
├── composite_analysis/           # Aggregated analytical outputs
├── evidence_extraction/          # Extracted evidence from documents
├── score_extraction/             # Scores assigned based on evidence
├── marked_up_document/           # Documents with annotations/markup
├── statistical_analysis/         # Quantitative analysis results
├── final_synthesis_report/       # Comprehensive report of findings
├── validation_report/            # Report on validation procedures and results
└── run_context/                  # Environmental and system context of the run
```

---

## 4. Artifact Inventory and Descriptions

This section details each type of artifact generated by the `bolsonaro_2018` experiment, explaining its purpose and content.

### 4.1. Core Experiment Definitions

*   **`experiment_spec`** (1 artifact)
    *   **Description**: This artifact contains the formal specification of the experiment. It outlines the research questions, hypotheses, analytical methodology, and any specific parameters or configurations used to guide the Discernus framework's execution. It serves as the blueprint for the entire experiment.
    *   **Purpose**: To provide a clear, machine-readable and human-readable definition of *what* the experiment intended to achieve and *how* it was designed.

*   **`framework`** (1 artifact)
    *   **Description**: This artifact captures details about the specific version, configuration, and any custom modules or extensions of the Discernus framework utilized for this experiment run. It ensures reproducibility by documenting the exact analytical engine.
    *   **Purpose**: To document the software environment and configuration of the Discernus framework itself, critical for reproducibility and understanding potential system-level influences.

### 4.2. Corpus Management

*   **`corpus_manifest`** (1 artifact)
    *   **Description**: This artifact is a comprehensive manifest or index of all documents included in the `unknown_corpus` for this experiment. It typically lists document IDs, file paths, and potentially relevant metadata (e.g., source, date, author).
    *   **Purpose**: To provide a complete and auditable list of all source materials processed by the experiment.

*   **`corpus_document`** (12 artifacts)
    *   **Description**: These artifacts represent the individual documents from the corpus that were subjected to analysis. Each artifact corresponds to one document, typically in its raw or pre-processed text format, ready for Discernus's analytical pipeline.
    *   **Purpose**: To provide direct access to the primary source material upon which all subsequent analyses are based.

### 4.3. Analysis Outputs

*   **`evidence_extraction`** (12 artifacts)
    *   **Description**: For each `corpus_document`, this artifact details the specific pieces of information, phrases, sentences, or data points identified and extracted as relevant evidence according to the `experiment_spec`. It typically includes the extracted text, its location within the document, and the criteria for its extraction.
    *   **Purpose**: To document the raw evidence identified by the Discernus system, forming the basis for scoring and further analysis.

*   **`score_extraction`** (12 artifacts)
    *   **Description**: Following evidence extraction, these artifacts contain the quantitative or qualitative scores assigned to each document or specific aspects within them, based on the extracted evidence and the scoring rules defined in the `experiment_spec`.
    *   **Purpose**: To present the direct output of the Discernus scoring mechanism for each document, reflecting the system's interpretation of the evidence.

*   **`composite_analysis`** (12 artifacts)
    *   **Description**: These artifacts represent aggregated or intermediate analytical outputs that combine information from various stages or sources for each document. This might include synthesized findings, cross-referenced data, or preliminary conclusions derived from the evidence and scores.
    *   **Purpose**: To provide a more holistic, document-specific analytical view, potentially bridging raw evidence/scores with higher-level interpretations.

*   **`marked_up_document`** (12 artifacts)
    *   **Description**: These artifacts are versions of the original `corpus_document` with annotations, highlights, or tags directly embedded within the text. They visually indicate the extracted evidence, assigned scores, or other analytical insights, making the analysis transparent and easy to review.
    *   **Purpose**: To offer a human-readable, visual representation of the Discernus system's interaction with the source text, aiding in validation and understanding.

### 4.4. Reporting and Validation

*   **`statistical_analysis`** (1 artifact)
    *   **Description**: This artifact contains the results of quantitative analysis performed on the collected scores and other data across all documents. It may include summary statistics, correlations, trend analyses, and other statistical inferences.
    *   **Purpose**: To provide a high-level, data-driven summary of the experiment's findings, identifying patterns and significant observations.

*   **`final_synthesis_report`** (1 artifact)
    *   **Description**: This is the primary output report of the experiment. It synthesizes all findings, discusses the methodology, presents the key results, interprets their implications, and draws conclusions based on the `statistical_analysis` and `composite_analysis`.
    *   **Purpose**: To present the complete narrative and conclusions of the research experiment in a formal report format.

*   **`validation_report`** (1 artifact)
    *   **Description**: This artifact documents the procedures, criteria, and outcomes of any validation steps performed on the experiment's results. This could include manual review, comparison with ground truth, or cross-validation checks.
    *   **Purpose**: To demonstrate the reliability and accuracy of the experiment's findings and the Discernus system's performance.

### 4.5. Run Context

*   **`run_context`** (1 artifact)
    *   **Description**: This artifact captures the complete environmental context in which the experiment was executed. This includes system specifications (OS, CPU, RAM), software dependencies and their versions, environment variables, and any other configuration details relevant to the execution.
    *   **Purpose**: Crucial for ensuring the reproducibility of the experiment by documenting the exact computational environment.

---

## 5. Provenance Information

The Discernus framework is designed with provenance in mind. Each artifact's directory structure and naming conventions (where applicable) are intended to link it directly to this specific experiment run (`bolsonaro_2018_20250925_150351`).

*   **Run ID**: The unique `Run ID` (`bolsonaro_2018_20250925_150351`) serves as the primary identifier for this entire set of artifacts. All artifacts within this directory are products of this specific execution.
*   **Completion Date**: The `Completion Date` provides a precise timestamp for when the experiment concluded, aiding in chronological tracking.
*   **Directory Structure**: The hierarchical organization within `/Volumes/code/discernus/projects/wip/bolsonaro_2018/` ensures that all artifacts are logically grouped under the experiment's scope.
*   **`experiment_spec` and `run_context`**: These two artifacts are particularly important for provenance, detailing *what* was intended to be done and *how* it was executed, respectively.

For deeper provenance, individual artifact files may contain internal metadata (e.g., timestamps, generating script versions) depending on the Discernus framework's implementation.

---

## 6. Usage Instructions for Researchers and Auditors

This section provides guidance on how to navigate and utilize the contents of this experiment directory.

1.  **Start with the README**: This document is your primary entry point.
2.  **Review Experiment Details**: Consult Section 2 for a quick overview of the experiment's scope and identifiers.
3.  **Understand the Methodology**: Examine the `experiment_spec` artifact to grasp the research questions, hypotheses, and analytical approach.
    *   `./experiment_spec/`
4.  **Inspect the Corpus**:
    *   Review the `corpus_manifest` to see the list of all documents included.
        *   `./corpus_manifest/`
    *   Access individual `corpus_document` files to review the raw source material.
        *   `./corpus_document/`
5.  **Trace the Analysis Pipeline**:
    *   Examine `evidence_extraction` artifacts to see what specific data points were identified in each document.
        *   `./evidence_extraction/`
    *   Review `score_extraction` artifacts to understand how evidence translated into quantitative/qualitative scores.
        *   `./score_extraction/`
    *   Consult `composite_analysis` for intermediate, document-specific analytical outputs.
        *   `./composite_analysis/`
    *   Utilize `marked_up_document` files for a visual, annotated view of the analysis on the original text.
        *   `./marked_up_document/`
6.  **Review Overall Findings**:
    *   Analyze the `statistical_analysis` artifact for quantitative summaries and patterns across the corpus.
        *   `./statistical_analysis/`
    *   Read the `final_synthesis_report` for the comprehensive narrative, conclusions, and implications of the experiment.
        *   `./final_synthesis_report/`
7.  **Assess Reliability**: Consult the `validation_report` to understand the quality assurance measures and their outcomes.
    *   `./validation_report/`
8.  **Reproduce the Experiment**: Refer to the `framework` and `run_context` artifacts for details on the software and environment configuration necessary to replicate this experiment.
    *   `./framework/`
    *   `./run_context/`

**Accessing Artifacts**: Artifacts are typically stored in formats suitable for their content (e.g., JSON, CSV, TXT, PDF). Standard tools for viewing these formats should be sufficient.

---

## 7. Discoverability and Auditability

This README, along with the structured directory and detailed artifact descriptions, is designed to maximize the discoverability and auditability of the `bolsonaro_2018` experiment.

*   **Discoverability**: Researchers can quickly ascertain the experiment's purpose, scope, and key findings by reviewing this document. The clear table of contents and detailed descriptions facilitate rapid understanding of the experiment's components.
*   **Auditability**: Auditors can trace the entire analytical process from the initial `experiment_spec` and `corpus_document` to the `final_synthesis_report`. Every step, from `evidence_extraction` to `score_extraction` and `statistical_analysis`, is documented with corresponding artifacts, allowing for thorough verification and validation of the results. The `run_context` and `framework` artifacts provide the necessary environmental details for full reproducibility checks.

This comprehensive documentation ensures that the `bolsonaro_2018` experiment is a self-contained, transparent, and verifiable research output.