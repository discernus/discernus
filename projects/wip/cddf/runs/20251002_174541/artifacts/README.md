# README: Discernus Experiment Run `cddf_20251002_114541`

This README provides a comprehensive overview and guide to the Discernus research experiment identified by the name `cddf` and run ID `cddf_20251002_114541`. It is designed to facilitate understanding, navigation, and auditing of the experiment's outputs and methodology.

## Table of Contents

1.  [Experiment Overview](#1-experiment-overview)
    *   [Basic Information](#basic-information)
    *   [Framework and Corpus](#framework-and-corpus)
    *   [Processed Documents](#processed-documents)
2.  [Directory Structure](#2-directory-structure)
3.  [Artifact Inventory & Descriptions](#3-artifact-inventory--descriptions)
    *   [experiment_spec](#experimentspec)
    *   [framework](#framework)
    *   [corpus_manifest](#corpus_manifest)
    *   [corpus_document](#corpus_document)
    *   [composite_analysis](#composite_analysis)
    *   [evidence_extraction](#evidence_extraction)
    *   [score_extraction](#score_extraction)
    *   [marked_up_document](#marked_up_document)
    *   [statistical_analysis](#statistical_analysis)
    *   [final_synthesis_report](#final_synthesis_report)
    *   [validation_report](#validation_report)
    *   [run_context](#run_context)
4.  [Usage Instructions for Researchers and Auditors](#4-usage-instructions-for-researchers-and-auditors)
5.  [Provenance and Reproducibility](#5-provenance-and-reproducibility)
6.  [Contact Information](#6-contact-information)
7.  [License](#7-license)

---

## 1. Experiment Overview

This section provides high-level information about the `cddf` experiment run.

### Basic Information

*   **Experiment Name:** `cddf`
*   **Run ID:** `cddf_20251002_114541`
*   **Completion Date:** `2025-10-02T17:45:41.980161+00:00`
*   **Experiment Directory:** `/Volumes/code/discernus/projects/wip/cddf`

### Framework and Corpus

*   **Discernus Framework Version/Configuration:** `unknown_framework` (Details may be found in `framework` artifacts.)
*   **Corpus Name:** `unknown_corpus` (Details may be found in `corpus_manifest` artifacts.)

### Processed Documents

*   **Number of Documents Processed:** 42
    *(Note: While the initial `Documents: 0` might indicate a starting state, the presence of 42 document-specific artifacts confirms that 42 documents were successfully processed during this run.)*

---

## 2. Directory Structure

The experiment's output is organized within the root directory `/Volumes/code/discernus/projects/wip/cddf`. It is structured into subdirectories, with each subdirectory typically corresponding to an artifact type. This organization ensures clarity and ease of navigation.

```
/Volumes/code/discernus/projects/wip/cddf/
├── experiment_spec/
│   └── experiment_spec_artifact_1.json  (example)
├── framework/
│   └── framework_config_1.yaml          (example)
├── corpus_manifest/
│   └── corpus_manifest_1.json           (example)
├── corpus_document/
│   ├── doc_001.txt                      (example)
│   ├── doc_002.txt
│   └── ... (42 documents)
├── composite_analysis/
│   ├── doc_001_composite_analysis.json  (example)
│   ├── doc_002_composite_analysis.json
│   └── ... (42 analyses)
├── evidence_extraction/
│   ├── doc_001_evidence.json            (example)
│   ├── doc_002_evidence.json
│   └── ... (42 extractions)
├── score_extraction/
│   ├── doc_001_scores.json              (example)
│   ├── doc_002_scores.json
│   └── ... (42 scores)
├── marked_up_document/
│   ├── doc_001_marked_up.html           (example)
│   ├── doc_002_marked_up.html
│   └── ... (42 marked-up documents)
├── statistical_analysis/
│   └── statistical_results_1.json       (example)
├── final_synthesis_report/
│   └── synthesis_report_1.pdf           (example)
├── validation_report/
│   └── validation_report_1.json         (example)
└── run_context/
    ├── run_log_1.txt                    (example)
    ├── environment_vars.json
    └── ... (5 artifacts)
```

---

## 3. Artifact Inventory & Descriptions

This section details each type of artifact generated by the experiment, explaining its purpose and content.

### `experiment_spec`
*   **Count:** 1 artifact
*   **Description:** This artifact contains the formal specification of the experiment. It outlines the research questions, objectives, methodology, parameters, and any specific configurations used to define the experiment's scope and execution. It is crucial for understanding the *intent* behind the experiment.
*   **Expected Content:** Typically a JSON or YAML file detailing experiment configuration.

### `framework`
*   **Count:** 1 artifact
*   **Description:** This artifact provides details about the Discernus framework version, configuration, or specific modules utilized during the experiment run. It is essential for ensuring reproducibility and understanding the computational environment.
*   **Expected Content:** Configuration files, version manifests, or environment descriptions.

### `corpus_manifest`
*   **Count:** 1 artifact
*   **Description:** This artifact serves as an index or manifest for the entire corpus used in the experiment. It lists all processed documents, often including metadata such as document IDs, original sources, and any pre-processing steps applied.
*   **Expected Content:** A JSON or CSV file listing document metadata.

### `corpus_document`
*   **Count:** 42 artifacts
*   **Description:** These artifacts represent the raw or pre-processed textual content of each individual document from the corpus. These are the primary inputs that the Discernus framework analyzed.
*   **Expected Content:** Text files (`.txt`), XML, or other document formats.

### `composite_analysis`
*   **Count:** 42 artifacts
*   **Description:** For each document, this artifact aggregates the results of various analytical steps. It might combine different types of scores, extracted entities, structural analyses, or other intermediate findings into a single, comprehensive representation of the document's analysis.
*   **Expected Content:** JSON or XML files containing structured analytical data per document.

### `evidence_extraction`
*   **Count:** 42 artifacts
*   **Description:** These artifacts contain specific snippets or sections of text identified within each document that serve as "evidence" for particular claims, research questions, or analytical categories. Each extraction typically includes the text, its location (e.g., page, paragraph, character offset), and the associated claim/category.
*   **Expected Content:** JSON files detailing extracted evidence, often with contextual information.

### `score_extraction`
*   **Count:** 42 artifacts
*   **Description:** These artifacts provide numerical or categorical scores derived from the analysis of each individual document. These scores quantify specific aspects, criteria, or hypotheses relevant to the experiment's objectives.
*   **Expected Content:** JSON or CSV files containing scores and their associated criteria per document.

### `marked_up_document`
*   **Count:** 42 artifacts
*   **Description:** These are versions of the original documents that have been annotated or "marked up" to visually highlight extracted evidence, scores, or other analytical findings. They are invaluable for human review and understanding how the system interpreted the text.
*   **Expected Content:** HTML, PDF with annotations, or other visually marked-up document formats.

### `statistical_analysis`
*   **Count:** 1 artifact
*   **Description:** This artifact presents the results of statistical tests, aggregations, or modeling performed across the entire set of processed documents. It provides a quantitative summary of the experiment's findings at a corpus level.
*   **Expected Content:** Statistical reports (e.g., JSON, CSV, R Markdown output, or PDF).

### `final_synthesis_report`
*   **Count:** 1 artifact
*   **Description:** This is the primary human-readable output report of the experiment. It synthesizes the objectives, methodology, key findings, and conclusions drawn from the entire analysis. It often includes summaries of the statistical analysis and examples from the marked-up documents.
*   **Expected Content:** A comprehensive report, typically in PDF or a similar document format.

### `validation_report`
*   **Count:** 1 artifact
*   **Description:** This artifact documents any validation procedures undertaken to assess the reliability, accuracy, or robustness of the experiment's outputs. This might include comparisons against ground truth, expert reviews, or internal consistency checks.
*   **Expected Content:** A report detailing validation methodology, results, and confidence metrics.

### `run_context`
*   **Count:** 5 artifacts
*   **Description:** These artifacts capture various contextual details about the specific execution environment and process of this experiment run. This can include system logs, environment variables, configuration files, and timestamps, all critical for debugging, auditing, and ensuring reproducibility.
*   **Expected Content:** Log files, environment variable dumps, configuration files, system information.

---

## 4. Usage Instructions for Researchers and Auditors

To effectively navigate and understand this experiment's outputs:

1.  **Start with the `final_synthesis_report`:** This document provides the high-level summary and conclusions.
2.  **Review the `experiment_spec`:** To understand the experiment's original goals and design.
3.  **Examine `corpus_manifest` and `corpus_document`:** To understand the input data.
4.  **Dive into `marked_up_document`:** For a visual understanding of how the system processed individual documents and identified key information. This is often the most intuitive way to grasp the document-level analysis.
5.  **Consult `evidence_extraction` and `score_extraction`:** For detailed, structured data on what was extracted and scored from each document.
6.  **Analyze `composite_analysis`:** For a consolidated view of all analytical outputs for a specific document.
7.  **Review `statistical_analysis`:** To understand the aggregate quantitative findings across the corpus.
8.  **Check `validation_report`:** To assess the confidence and reliability of the experiment's results.
9.  **Utilize `framework` and `run_context`:** For deep dives into the technical environment and execution details, especially for reproducibility or debugging.

The directory structure is designed to be intuitive, with each artifact type residing in its own subdirectory. Document-specific artifacts (e.g., `corpus_document`, `evidence_extraction`, `marked_up_document`) are typically named or indexed to correspond to the document IDs found in the `corpus_manifest`.

---

## 5. Provenance and Reproducibility

This experiment run, `cddf_20251002_114541`, is a self-contained record of a Discernus analysis. The combination of the `experiment_spec`, `framework` details, `corpus_manifest`, and the `run_context` artifacts provides a robust foundation for understanding the experiment's provenance and for potential future reproduction. Researchers and auditors are encouraged to review these artifacts to verify the experimental setup and execution.

---

## 6. Contact Information

For questions or further information regarding this experiment, please contact:

[Insert Contact Name/Email/Department Here]

---

## 7. License

[Insert License Information Here, e.g., MIT, Apache 2.0, or proprietary statement]