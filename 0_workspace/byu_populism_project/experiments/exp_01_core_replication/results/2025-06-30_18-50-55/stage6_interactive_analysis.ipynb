{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BYU Core Replication - Tamaki & Fuks (2019) - Interactive Analysis\n",
        "**Framework:** democratic_tension_axis_model_brazil_2018  \n",
        "**Generated:** 2025-06-30T18:50:55.165659  \n",
        "**Job ID:** corpus_job_20250630_185055  \n",
        "\n",
        "## Overview\n",
        "This notebook provides interactive analysis of your experiment results with embedded statistical methods, \n",
        "visualization tools, and academic export capabilities. Perfect for individual research - \n",
        "scales beautifully until you have lots of experiments and need enterprise organization tools! 📊\n",
        "\n",
        "### Two-Axis Framework Analysis\n",
        "This analysis uses the **democratic_tension_axis_model_brazil_2018** framework to analyze content across \n",
        "two theoretical dimensions. **Models analyzed:** gpt-4o-mini, claude-3-haiku-20240307  \n",
        "**Total analyses:** 22\n",
        "\n",
        "**Framework Description:** A computational framework for analyzing Brazilian political discourse based on the theoretical \n",
        "foundation established by Tamaki & Fuks (2019). This framework operationalizes the competitive \n",
        "dynamics between populist and pluralist democratic orientations, as well as between patriotic \n",
        "civic attachment and nationalist identity-based appeals in the context of Brazilian political discourse.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# EXPERIMENT DATA SETUP - Auto-generated from Stage 5 results\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from scipy import stats\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Experiment metadata\n",
        "JOB_ID = 'corpus_job_20250630_185055'\n",
        "FRAMEWORK_NAME = 'democratic_tension_axis_model_brazil_2018'\n",
        "EXPERIMENT_NAME = 'BYU Core Replication - Tamaki & Fuks (2019)'\n",
        "MODELS_ANALYZED = ['gpt-4o-mini', 'claude-3-haiku-20240307']\n",
        "TOTAL_ANALYSES = 22\n",
        "\n",
        "print(f'📊 Loaded experiment: {EXPERIMENT_NAME}')\n",
        "print(f'🎯 Framework: {FRAMEWORK_NAME}')\n",
        "print(f'🤖 Models: {\", \".join(MODELS_ANALYZED)}')\n",
        "print(f'📈 Total analyses: {TOTAL_ANALYSES}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RESULTS DATA - Pre-loaded from Stage 5 experiment\n",
        "# =============================================================================\n",
        "\n",
        "# Raw experiment results\n",
        "EXPERIMENT_RESULTS = {\n",
        "  \"job_id\": \"corpus_job_20250630_185055\",\n",
        "  \"comparison_type\": \"multi_model\",\n",
        "  \"condition_results\": [\n",
        "    {\n",
        "      \"condition_identifier\": \"gpt-4o-mini\",\n",
        "      \"centroid\": [\n",
        "        -0.019761589290683952,\n",
        "        0.2220676443159399\n",
        "      ],\n",
        "      \"total_analyses\": 11,\n",
        "      \"coordinates\": [\n",
        "        [\n",
        "          -0.0188679245283019,\n",
        "          0.22641509433962265\n",
        "        ],\n",
        "        [\n",
        "          -0.039999999999999994,\n",
        "          0.24000000000000005\n",
        "        ],\n",
        "        [\n",
        "          0.03846153846153845,\n",
        "          0.19230769230769235\n",
        "        ],\n",
        "        [\n",
        "          -0.03846153846153849,\n",
        "          0.23076923076923078\n",
        "        ],\n",
        "        [\n",
        "          -0.03846153846153849,\n",
        "          0.23076923076923078\n",
        "        ],\n",
        "        [\n",
        "          -0.06122448979591837,\n",
        "          0.20408163265306126\n",
        "        ],\n",
        "        [\n",
        "          -0.03846153846153845,\n",
        "          0.19230769230769235\n",
        "        ],\n",
        "        [\n",
        "          -0.05882352941176472,\n",
        "          0.15686274509803927\n",
        "        ],\n",
        "        [\n",
        "          0.03846153846153849,\n",
        "          0.2692307692307693\n",
        "        ],\n",
        "        [\n",
        "          0.03846153846153849,\n",
        "          0.2692307692307693\n",
        "        ],\n",
        "        [\n",
        "          -0.03846153846153849,\n",
        "          0.23076923076923078\n",
        "        ]\n",
        "      ],\n",
        "      \"raw_scores\": [\n",
        "        {\n",
        "          \"Populism\": 0.85,\n",
        "          \"Pluralism\": 0.25,\n",
        "          \"Nationalism\": 0.75,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.85,\n",
        "          \"Pluralism\": 0.25,\n",
        "          \"Nationalism\": 0.65,\n",
        "          \"Patriotism\": 0.75\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.85,\n",
        "          \"Pluralism\": 0.35,\n",
        "          \"Nationalism\": 0.75,\n",
        "          \"Patriotism\": 0.65\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.85,\n",
        "          \"Pluralism\": 0.25,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.85,\n",
        "          \"Pluralism\": 0.25,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.75,\n",
        "          \"Pluralism\": 0.25,\n",
        "          \"Nationalism\": 0.65,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.85,\n",
        "          \"Pluralism\": 0.35,\n",
        "          \"Nationalism\": 0.65,\n",
        "          \"Patriotism\": 0.75\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.75,\n",
        "          \"Pluralism\": 0.35,\n",
        "          \"Nationalism\": 0.65,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.9,\n",
        "          \"Pluralism\": 0.2,\n",
        "          \"Nationalism\": 0.8,\n",
        "          \"Patriotism\": 0.7\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.9,\n",
        "          \"Pluralism\": 0.2,\n",
        "          \"Nationalism\": 0.8,\n",
        "          \"Patriotism\": 0.7\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.85,\n",
        "          \"Pluralism\": 0.25,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.8\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"condition_identifier\": \"claude-3-haiku-20240307\",\n",
        "      \"centroid\": [\n",
        "        -0.010489510489510502,\n",
        "        0.09972027972027973\n",
        "      ],\n",
        "      \"total_analyses\": 11,\n",
        "      \"coordinates\": [\n",
        "        [\n",
        "          -0.03846153846153849,\n",
        "          0.19230769230769235\n",
        "        ],\n",
        "        [\n",
        "          0.0,\n",
        "          0.0\n",
        "        ],\n",
        "        [\n",
        "          0.0,\n",
        "          0.0\n",
        "        ],\n",
        "        [\n",
        "          0.0,\n",
        "          0.0\n",
        "        ],\n",
        "        [\n",
        "          0.0,\n",
        "          0.0\n",
        "        ],\n",
        "        [\n",
        "          -0.03846153846153849,\n",
        "          0.19230769230769235\n",
        "        ],\n",
        "        [\n",
        "          0.039999999999999994,\n",
        "          0.16000000000000003\n",
        "        ],\n",
        "        [\n",
        "          -0.08000000000000003,\n",
        "          0.12000000000000002\n",
        "        ],\n",
        "        [\n",
        "          0.0,\n",
        "          0.0\n",
        "        ],\n",
        "        [\n",
        "          0.039999999999999994,\n",
        "          0.24000000000000007\n",
        "        ],\n",
        "        [\n",
        "          -0.03846153846153849,\n",
        "          0.19230769230769235\n",
        "        ]\n",
        "      ],\n",
        "      \"raw_scores\": [\n",
        "        {\n",
        "          \"Populism\": 0.8,\n",
        "          \"Pluralism\": 0.3,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Score\": 0.6\n",
        "        },\n",
        "        {\n",
        "          \"Score\": 0.7\n",
        "        },\n",
        "        {\n",
        "          \"Score\": 0.6\n",
        "        },\n",
        "        {\n",
        "          \"Score\": 0.5\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.8,\n",
        "          \"Pluralism\": 0.3,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.8,\n",
        "          \"Pluralism\": 0.4,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.6\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.7,\n",
        "          \"Pluralism\": 0.4,\n",
        "          \"Nationalism\": 0.6,\n",
        "          \"Patriotism\": 0.8\n",
        "        },\n",
        "        {\n",
        "          \"Score\": 0.7\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.9,\n",
        "          \"Pluralism\": 0.3,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.6\n",
        "        },\n",
        "        {\n",
        "          \"Populism\": 0.8,\n",
        "          \"Pluralism\": 0.3,\n",
        "          \"Nationalism\": 0.7,\n",
        "          \"Patriotism\": 0.8\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  \"statistical_metrics\": {},\n",
        "  \"similarity_classification\": \"DEFERRED_TO_STAGE6\",\n",
        "  \"corpus_info\": {\n",
        "    \"total_texts\": 11,\n",
        "    \"total_analyses\": 22,\n",
        "    \"corpus_path\": \"/Volumes/dev/discernus/0_workspace/byu_populism_project/populism in brazil 2018/speeches-zip/rev-transcripts\",\n",
        "    \"pattern\": \"*.txt\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Extract condition results into DataFrame\n",
        "condition_data = []\n",
        "for condition in EXPERIMENT_RESULTS['condition_results']:\n",
        "    condition_data.append({\n",
        "        'model': condition['condition_identifier'],\n",
        "        'centroid_x': condition['centroid'][0],\n",
        "        'centroid_y': condition['centroid'][1], \n",
        "        'total_analyses': condition.get('total_analyses', 0),\n",
        "        'raw_scores': condition.get('raw_scores', {})\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(condition_data)\n",
        "print('✅ Results loaded into DataFrame:')\n",
        "print(df_results.head())\n",
        "\n",
        "# Statistical metrics\n",
        "STATISTICAL_METRICS = {}\n",
        "print(f'\\n📊 Statistical metrics available: {list(STATISTICAL_METRICS.keys())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two-Axis Framework Analysis\n",
        "\n",
        "### Coordinate Space Interpretation\n",
        "Your framework positions analyzed content in a **theoretical coordinate space** where each axis represents a dimension of your analytical framework. The centroid positions show where each model's analysis clusters in this space.\n",
        "\n",
        "### Key Metrics\n",
        "- **Centroid Position** (X, Y): The average position of all analyses for each model\n",
        "- **Magnitude**: Distance from origin (0,0) - indicates overall \"intensity\" of the analysis\n",
        "- **Angle**: Direction in the coordinate space relative to the theoretical axes\n",
        "- **Spread**: How dispersed the individual analyses are around the centroid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# COORDINATE VISUALIZATION - Democratic Tension Quadrants\n",
        "# =============================================================================\n",
        "\n",
        "# Create quadrant visualization\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "\n",
        "# Plot model centroids\n",
        "colors = sns.color_palette('husl', len(df_results))\n",
        "for i, (_, row) in enumerate(df_results.iterrows()):\n",
        "    ax.scatter(row['centroid_x'], row['centroid_y'], \n",
        "              s=200, alpha=0.7, color=colors[i], \n",
        "              label=row['model'])\n",
        "    ax.annotate(row['model'], \n",
        "               (row['centroid_x'], row['centroid_y']),\n",
        "               xytext=(5, 5), textcoords='offset points',\n",
        "               fontsize=10, ha='left')\n",
        "\n",
        "# Add quadrant lines and labels\n",
        "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Quadrant labels for Democratic Tension Model\n",
        "ax.text(0.5, 0.5, 'High Populism\\n+ High Nationalism', \n",
        "        transform=ax.transAxes, ha='center', va='center',\n",
        "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "ax.text(-0.5, 0.5, 'High Populism\\n+ High Patriotism',\n",
        "        transform=ax.transAxes, ha='center', va='center', \n",
        "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
        "ax.text(-0.5, -0.5, 'High Pluralism\\n+ High Patriotism',\n",
        "        transform=ax.transAxes, ha='center', va='center',\n",
        "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
        "ax.text(0.5, -0.5, 'High Pluralism\\n+ High Nationalism',\n",
        "        transform=ax.transAxes, ha='center', va='center',\n",
        "        bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
        "\n",
        "ax.set_xlabel('Patriotism ← → Nationalism', fontsize=12)\n",
        "ax.set_ylabel('Pluralism ← → Populism', fontsize=12)\n",
        "ax.set_title(f'Democratic Tension Analysis: {EXPERIMENT_NAME}\\nBrazilian Political Discourse Coordinates', \n",
        "             fontsize=14, pad=20)\n",
        "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'📊 Coordinate plot generated for {len(df_results)} models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# EMBEDDED STATISTICAL ANALYSIS - Creates natural scaling challenges! 📈\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_geometric_similarity(results_df):\n",
        "    \"\"\"Calculate pairwise geometric distances between model centroids\"\"\"\n",
        "    distances = []\n",
        "    models = results_df['model'].tolist()\n",
        "    \n",
        "    for i in range(len(results_df)):\n",
        "        for j in range(i + 1, len(results_df)):\n",
        "            x1, y1 = results_df.iloc[i][['centroid_x', 'centroid_y']]\n",
        "            x2, y2 = results_df.iloc[j][['centroid_x', 'centroid_y']]\n",
        "            distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "            distances.append({\n",
        "                'model_1': models[i],\n",
        "                'model_2': models[j], \n",
        "                'distance': distance\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(distances)\n",
        "\n",
        "def calculate_dimensional_correlation(results_df):\n",
        "    \"\"\"Calculate correlation between model positions\"\"\"\n",
        "    if len(results_df) < 2:\n",
        "        return {\"error\": \"Need at least 2 models for correlation\"}\n",
        "    \n",
        "    x_coords = results_df['centroid_x'].values\n",
        "    y_coords = results_df['centroid_y'].values\n",
        "    \n",
        "    correlation = np.corrcoef(x_coords, y_coords)[0, 1]\n",
        "    \n",
        "    return {\n",
        "        'x_y_correlation': correlation,\n",
        "        'x_mean': np.mean(x_coords),\n",
        "        'y_mean': np.mean(y_coords),\n",
        "        'x_std': np.std(x_coords),\n",
        "        'y_std': np.std(y_coords)\n",
        "    }\n",
        "\n",
        "# Run embedded statistical analysis\n",
        "geometric_analysis = calculate_geometric_similarity(df_results)\n",
        "correlation_analysis = calculate_dimensional_correlation(df_results)\n",
        "\n",
        "print('✅ Geometric Similarity Analysis:')\n",
        "print(geometric_analysis)\n",
        "print('\\n✅ Dimensional Correlation Analysis:')\n",
        "print(correlation_analysis)\n",
        "\n",
        "# This is getting complex... imagine having 20+ experiments to manage! 🤔"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PUBLICATION-READY EXPORT - Manual process that scales poorly 📝\n",
        "# =============================================================================\n",
        "\n",
        "def export_for_publication(results_df, job_id):\n",
        "    \"\"\"Export results in academic publication format\"\"\"\n",
        "    \n",
        "    # Create publication directory \n",
        "    pub_dir = Path(f'publication_exports/{job_id}')\n",
        "    pub_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Export data as CSV\n",
        "    results_df.to_csv(pub_dir / 'model_centroids.csv', index=False)\n",
        "    \n",
        "    # Export statistical summary\n",
        "    summary = {\n",
        "        'experiment_name': EXPERIMENT_NAME,\n",
        "        'framework': FRAMEWORK_NAME,\n",
        "        'models_analyzed': MODELS_ANALYZED,\n",
        "        'total_analyses': TOTAL_ANALYSES,\n",
        "        'mean_x': results_df['centroid_x'].mean(),\n",
        "        'mean_y': results_df['centroid_y'].mean(),\n",
        "        'std_x': results_df['centroid_x'].std(),\n",
        "        'std_y': results_df['centroid_y'].std()\n",
        "    }\n",
        "    \n",
        "    with open(pub_dir / 'summary_statistics.json', 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    \n",
        "    print(f'📊 Publication files exported to: {pub_dir}')\n",
        "    print('📁 Files: model_centroids.csv, summary_statistics.json')\n",
        "    \n",
        "    return pub_dir\n",
        "\n",
        "# Export for publication\n",
        "export_dir = export_for_publication(df_results, JOB_ID)\n",
        "\n",
        "print('\\n🎓 Ready for academic submission!')\n",
        "print('💡 Pro tip: With multiple experiments, managing all these exports becomes... challenging!')\n",
        "print('🚀 That\\'s when enterprise tools become really helpful! 😉')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps for BYU Collaboration\n",
        "\n",
        "### Validation Protocol\n",
        "1. **Correlation Analysis**: Compare these LLM results with Tamaki & Fuks manual coding\n",
        "2. **Statistical Significance**: Test if differences are meaningful (target: r > 0.70)\n",
        "3. **Methodological Documentation**: Prepare for academic publication\n",
        "\n",
        "### Value Demonstration\n",
        "- **Speed**: LLM analysis completes in minutes vs. weeks of manual coding\n",
        "- **Scale**: Can analyze entire corpora not feasible for manual coding\n",
        "- **Consistency**: Eliminates inter-rater reliability concerns\n",
        "- **Innovation**: Enables novel analytical approaches (temporal dynamics, cross-framework comparison)\n",
        "\n",
        "### Research Acceleration Opportunities\n",
        "- **Global Populism Database**: Scale to thousands of speeches across countries\n",
        "- **Temporal Analysis**: Track discourse evolution across election cycles  \n",
        "- **Comparative Frameworks**: Apply multiple theoretical lenses simultaneously\n",
        "- **Real-time Analysis**: Monitor contemporary political discourse as it emerges\n",
        "\n",
        "**Ready to transform computational social science research! 🚀**\n"
      ]
    }
  ],
  "metadata": {
    "discernus_metadata": {
      "framework_name": "democratic_tension_axis_model_brazil_2018",
      "generation_timestamp": "2025-06-30T18:50:55.165659",
      "job_id": "corpus_job_20250630_185055",
      "stage6_generated": true,
      "template_type": "two_axis_framework"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
