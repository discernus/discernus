# Research Questions: BYU Populism Project (Strategic Edition)

This document organizes our research inquiries into two primary sections: foundational studies to validate our tools, and strategic research programs designed to generate novel academic contributions by targeting "white space" and "competitive zones" in the field.

---

# Part I: Foundational & Validation Studies

These questions focus on establishing the validity, reliability, and technical performance of the Discernus system and the `democratic_tension_axis_model`.

## 1. Core Replication & Framework Validity

-   **1.1 (Core Replication):** How well do scores generated by our system using the `democratic_tension_axis_model_brazil_2018` framework correlate with the original manual scores from Tamaki & Fuks (2019)?
-   **1.2 (Orthogonality):** Does the orthogonal design of the framework hold empirically? Is the correlation between the Populism↔Pluralism and Patriotism↔Nationalism axes statistically close to zero?
-   **1.3 (Alternative Architecture):** How would findings from our bipolar axis model compare to those from an anchor-set framework where Populism, Pluralism, Nationalism, and Patriotism are four independent concepts?
-   **1.4 (Framework Fit):** How complete is our two-axis framework at capturing the entirety of political discourse? What is its "territorial coverage"?
-   **1.5 (Cue Set Robustness):** How sensitive are the final scores to the inclusion/exclusion of specific `language_cues` in the framework definition?
-   **1.6 (Theoretical Weighting):** How do final scores and validity change if we assign higher weights to core `language_cues` (e.g., "anti-elite") than to secondary ones?

## 2. Methodological & Technical Inquiry

-   **2.1 (Human vs. LLM):** Is there a statistically significant difference between scores from expert human raters, generalist LLMs, and specialized Portuguese LLMs?
-   **2.2 (Model Comparison):** How do different LLMs (GPT-4o, Claude, Perplexity, local models) compare in scoring accuracy, reliability, cost, and qualitative justification?
-   **2.3 (Scoring Strategy):** Which LLM prompting strategy—sequential single-axis or parallel multi-axis—produces more reliable and valid scores? Does parallel prompting increase "axis cross-talk"?
-   **2.4 (Local Model Performance):** Do specialized Portuguese-native models provide measurable improvement over general-purpose ones? How does quantization affect analytical nuance?
-   **2.5 (Human Rater "Halo Effect"):** Can we quantify the "halo effect" in human raters by comparing their sequential vs. parallel scoring performance?

## 3. Platform & Workflow Validation

-   **3.1 (Communicative Value):** Do the system's visualizations provide immediate, intuitive insights that are easily communicable to academic and non-academic audiences?
-   **3.2 (Workflow Efficiency):** Does the integrated, YAML-to-Jupyter workflow measurably reduce the time and cognitive load required to produce publishable results?
-   **3.3 (Reproducibility):** How effectively does the system's provenance tracking support transparent and computationally reproducible research?

---

# Part II: Strategic Research Programs (Landscape Analysis)

These programs target the key opportunities identified in our academic landscape analysis.

## Program 1: Advanced Ideological Analysis (Competitive Zone)

*Leverages our nuanced, multi-dimensional approach to outperform blunt, single-dimension ideological classifiers.*

-   **1.1 (Substantive Analysis):** What were the dominant rhetorical quadrants for Bolsonaro's 2018 campaign discourse? How did this compare to his competitors?
-   **1.2 (Competitive Dynamics):** Does the presence of strong nationalist rhetoric systematically *amplify* or *dilute* the populist elements within the same speech?
-   **1.3 (Novel Insights):** Does our independent measurement of the two axes reveal competitive or complementary dynamics between populism and nationalism that were previously difficult to observe?

## Program 2: Temporal & Dynamic Analysis (White Space)

*Moves beyond static snapshots to analyze the velocity and acceleration of rhetorical change over time.*

-   **2.1 (Discourse Evolution):** How did Jair Bolsonaro's discourse on the two primary axes evolve over the course of the 2018 campaign?
-   **2.2 (Event Impact):** Can we map the *velocity* and *acceleration* of Bolsonaro's rhetorical shifts following critical events, such as the assassination attempt? Did his rhetoric change direction, or just intensify along its existing trajectory?
-   **2.3 (Formality and Stakes):** How does the rhetorical signature change based on the formality or stakes of a communication event (e.g., a concession speech vs. a campaign tweet)?

## Program 3: Relational Discourse Analysis (White Space)

*Focuses on the novel Enmity↔Amity axis to quantify the relational orientation of discourse.*

-   **3.1 (A New Axis):** Can we reliably code texts along an independent Enmity↔Amity axis?
-   **3.2 (Correlation with Ideology):** How strongly does "enmity framing" correlate with high scores in populism and nationalism? Is it a core component of that rhetorical quadrant or an independent strategy?
-   **3.3 (Target of Enmity):** Who are the most common "enemies" identified in the discourse, and does the choice of enemy change by medium or campaign stage?
-   **3.4 (Predictive Power):** Is the Enmity↔Amity score a more powerful predictor of social media engagement than the populism score alone?

## Program 4: Integrated Affective Analysis (Competitive Zone)

*Combines emotional analysis with ideological content to provide deeper insight than generic sentiment analysis.*

-   **4.1 (Emotion & Ideology):** What is the relationship between the primary emotional valence (e.g., anger, fear, hope) of a text and its position in the four-quadrant ideological model?
-   **4.2 (Intensity & Granularity):** Beyond simple valence, what is the *intensity* of the emotion used? Do specific quadrants map to specific granular emotions?
-   **4.3 (Engagement Driver):** Is the *intensity* of emotional language a stronger predictor of social media engagement (especially retweets) than simple valence or ideological content?

## Program 5: Interaction Effects Analysis (White Space)

*Examines the complex interplay between content, style, medium, and engagement.*

-   **5.1 (Style vs. Substance):** Which is a better predictor of social media engagement: the ideological content (quadrant score) or the rhetorical style (e.g., high emotional valence, simple language)?
-   **5.2 (Medium-Specific Rhetoric):** Does a political actor's rhetorical signature systematically change across different communication mediums (e.g., formal speeches vs. Twitter)?
-   **5.3 (Social Media Dynamics):** How does the function of a tweet (e.g., policy announcement, attack) moderate the relationship between its rhetorical signature and user engagement?
-   **5.4 (Framework on Social Media):** How effectively can our framework be applied to short-form text? Are the `language_cues` equally effective in fragmented, informal language?