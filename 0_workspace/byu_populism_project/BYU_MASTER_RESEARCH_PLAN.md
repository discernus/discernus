# BYU Master Research Plan: From Strategy to Execution

**Purpose**: This document provides a single, reconciled view of the BYU collaboration research program. It integrates the high-level strategy from the `prioritized_research_plan.md`, the detailed experiments from `BYU_EXPERIMENT_REQUIREMENTS_SCRATCHPAD.md`, and the core methodology from `experiment_design_considerations.md` into one cohesive and actionable plan.

---

## Overall Research Strategy & Phasing

The research is organized into a multi-phase program designed to build credibility, deliver breakthrough insights, and demonstrate the unique power of the Discernus platform.

-   **Phase 0: Foundational Credibility & Partnership:** Prove that the platform can reliably replicate and meaningfully extend established, peer-reviewed research from Tamaki & Fuks (2019).
-   **Phase 1: The Breakthrough Study:** Introduce a novel, powerful concept to capture attention and establish thought leadership.
-   **Phase 2: The Momentum Engine:** Showcase the platform's unique methodological power.
-   **Phase 3: The Dynamic Frontier:** Demonstrate next-generation dynamic analysis capabilities.
-   **Phase 4: Ecosystem Expansion & Commercialization:** Prove universal applicability in new domains.

---

## Phase 0: Foundational Credibility & Partnership

**Goal:** Prove that the Discernus platform can reliably replicate and meaningfully extend the Tamaki & Fuks (2019) study of Brazilian populist discourse.

### 1. Core Replication & Framework Validity

#### **RQ 1.1: Core Replication**
*Strategic Question:* How well do scores generated by our system correlate with the original manual scores from Tamaki & Fuks (2019)?

*Experiment to Answer:*
-   **Experiment 1: Tamaki & Fuks Methodology Replication**
    -   **Purpose**: Validate our framework against the original BYU Team Populism manual coding results.
    -   **Core Falsifiable Question**: Can our computational analysis achieve r > 0.80 correlation with manual human coding of Bolsonaro's populism scores?
    -   **Success Criteria**: Correlation coefficient r > 0.80 with manual scores; p < 0.05.

#### **RQ 1.2: Axis Orthogonality**
*Strategic Question:* Does the orthogonal design of the `democratic_tension_axis_model_brazil_2018` framework hold empirically? Is the correlation between the Populism↔Pluralism and Patriotism↔Nationalism axes statistically close to zero?

*Experiment to Answer:*
-   **Experiment 2: Axis Independence Validation**
    -   **Purpose**: To empirically test the theoretical orthogonality of the framework's two axes.
    -   **Core Falsifiable Question**: Is the correlation coefficient between the Populism↔Pluralism and Patriotism↔Nationalism scores statistically indistinguishable from zero?
    -   **Method**: Analyze the scores generated across all documents in Experiment 1.
    -   **Success Criteria**: Correlation coefficient r ≈ 0; p > 0.05.

#### **RQ 1.3: Alternative Architecture Comparison**
*Strategic Question:* How would findings from our bipolar axis model compare to those from an anchor-set framework?

*Experiment to Answer:*
-   **Experiment 3: Framework Architecture Comparison (Formerly Exp. 8)**
    -   **Purpose**: Validate that our framework properly implements Framework Specification v3.2 and compare its output to a pure anchor-set design.
    -   **Core Falsifiable Question**: Does the anchor-set implementation produce theoretically consistent results compared to the axis-based model?
    -   **Method**: Re-run analysis on the same corpus using an axis-based framework vs. a pure anchor-set framework (where Populism, Pluralism, Nationalism, and Patriotism are four independent concepts).
    -   **Success Criteria**: Assess theoretical coherence, interpretability, and compliance.

#### **RQ 1.4 & 1.5: Framework Robustness**
*Strategic Questions:* How sensitive are the final scores to the inclusion/exclusion of specific `language_cues`? How do final scores change if we assign higher weights to core cues?

*Experiment to Answer:*
-   **Experiment 4: Cue Set & Weighting Sensitivity Analysis (New)**
    -   **Purpose**: To measure the robustness of the framework by testing its sensitivity to cue and weight variations.
    -   **Core Falsifiable Question**: Do final scores change by more than 15% when removing secondary cues or applying a 2x weight to primary cues?
    -   **Method**:
        -   **A/B Test 1 (Cue Removal)**: Run analysis with full cue set vs. a set with the 3 least-central cues removed.
        -   **A/B Test 2 (Weighting)**: Run analysis with uniform weights vs. a 2x weight multiplier on the 3 most-central cues (e.g., "anti-elite").
    -   **Success Criteria**: Quantify the score variance to understand framework stability.

---

### 2. Methodological & Technical Inquiry

#### **RQ 2.1 & 2.3: Optimal Scoring Strategy (Human vs. LLM)**
*Strategic Questions:* Is there a significant difference between scores from human raters and LLMs? Which LLM prompting strategy—sequential single-axis or parallel multi-axis—produces more reliable and valid scores?

*Experiment to Answer:*
-   **Experiment 5: Human vs. LLM Optimal Scoring Protocol (New, integrating `experiment_design_considerations.md`)**
    -   **Purpose**: To establish the most reliable and valid scoring protocol for both humans and LLMs, and to quantify the performance difference.
    -   **Core Falsifiable Question**: Does a parallel multi-axis LLM prompt produce scores with >0.90 correlation to a sequential single-axis prompt, while reducing cost/time by >40%?
    -   **Method**:
        -   **Human Protocol**: Raters score each axis independently in **sequential passes** to minimize halo effects, per Krippendorff (2018).
        -   **LLM Protocol**: The same corpus is analyzed using two distinct prompts:
            1.  **Sequential Single-Axis**: One prompt per axis.
            2.  **Parallel Multi-Axis**: One prompt scoring both axes, with separate reasoning for each.
    -   **Success Criteria**: Compare LLM approaches on reliability (correlation between methods), validity (correlation against human ground truth), and cost-efficiency.

#### **RQ 2.2 & 2.4: Cross-Model & Local Model Reliability**
*Strategic Questions:* How do different LLMs (GPT-4o, Claude, etc.) compare in scoring accuracy and reliability? Do specialized Portuguese-native models offer measurable improvement?

*Experiment to Answer:*
-   **Experiment 6: Cross-LLM Reliability Assessment (Formerly Exp. 7)**
    -   **Purpose**: Test consistency of populism analysis across different LLM systems.
    -   **Core Falsifiable Question**: Do different LLM systems produce consistent populism scores (inter-LLM reliability r > 0.70) using the identical optimal framework and prompt from Experiment 5?
    -   **Method**: Execute analysis using GPT-4o, Claude 3 Opus, Gemini 1.5 Pro, and a local Portuguese-native model.
    -   **Success Criteria**: Inter-rater reliability coefficient > 0.70; systematic vs. random error analysis.

#### **RQ 2.5: Context & Isolation Effects**
*Strategic Questions:* How does context affect scoring? Does pre-isolating speaker utterances produce different results than instructing the LLM to perform the isolation?

*Experiments to Answer:*
-   **Experiment 7: Context Effects Analysis (Formerly Exp. 2)**
    -   **Purpose**: Quantify the difference between isolated speaker analysis vs. full rally context.
    -   **Hypothesis**: Isolated speaker analysis will show higher populism scores.
-   **Experiment 8: Corpus Isolation A/B Test (Formerly Exp. 3)**
    -   **Purpose**: Compare manually pre-isolated corpus vs. LLM-guided isolation instructions.
    -   **Hypothesis**: Pre-isolated corpus will show more consistent results with lower variance.

---

### 3. Dynamic & Advanced Analysis

#### **RQ 3.1: Discourse Evolution Over Time**
*Strategic Question:* How did Jair Bolsonaro's discourse on the two primary axes evolve over the course of the 2018 campaign?

*Experiment to Answer:*
-   **Experiment 9: Temporal Evolution Analysis (Formerly Exp. 6)**
    -   **Purpose**: Track changes in Bolsonaro's populist rhetoric across the 2018 campaign timeline.
    -   **Core Falsifiable Question**: Can computational analysis detect the same temporal progression that manual coders observed (0.5→0.9 increase)?
    -   **Success Criteria**: Temporal progression pattern match; detection of October 7 turning point.

#### **RQ 3.4: Competitive Ideology Dynamics**
*Strategic Question:* Does the presence of strong nationalist rhetoric systematically *amplify* or *dilute* the populist elements within the same speech?

*Experiment to Answer:*
-   **Experiment 10: Competitive Ideology Dynamics (Formerly Exp. 5)**
    -   **Purpose**: Validate the Tamaki & Fuks insight that patriotism and nationalism compete with populism.
    -   **Core Falsifiable Question**: Do speeches with higher patriotism/nationalism scores show systematically lower populism scores?
    -   **Success Criteria**: Negative correlation between populism and competing ideologies.

---

### Phase 0 Success Gates & Validation

-   **Gate 1 (Core Replication)**: Experiment 1 achieves r > 0.70 correlation with T&F scores.
-   **Gate 2 (Methodology)**: Experiment 5 establishes a reliable and cost-effective LLM scoring protocol.
-   **Gate 3 (Dynamics)**: Experiment 10 demonstrates measurable competitive ideology dynamics.
-   **Gate 4 (Credibility)**: Experiments 6, 7, and 9 show systematic, interpretable patterns that align with the original study's observations.

**Next Steps**: Execute Phase 0 experiments, starting with Experiment 1 and 5, as they provide the foundation for all subsequent work. 