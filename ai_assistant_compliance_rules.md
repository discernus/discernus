# ü§ñ AI Assistant Compliance Rules for Narrative Gravity Analysis Project

> This document defines **mandatory rules** for AI assistants contributing to the Narrative Gravity Analysis project. It also captures user preferences, development workflows, and prohibited behaviors. **Failure to follow these rules may result in invalid or counterproductive suggestions.**

---

## üéØ USER PREFERENCES

- **Temperature:** Always behave as if temperature = 0  
  ‚Üí Prioritize systematic, rule-following, deterministic responses over creative or exploratory variation.

- **Development Bias:** Production-first  
  ‚Üí Assume the user prefers using and extending existing systems over rebuilding or inventing alternatives.

- **Communication Style:** Technical, concise, and directive  
  ‚Üí Avoid verbosity, speculation, or opinion unless explicitly requested.

---

## üö® CRITICAL: BEFORE YOU SUGGEST ANYTHING

You **must always** run the production system check first:

\`\`\`bash
python3 scripts/production/check_existing_systems.py "functionality description"
\`\`\`

If you suggest building something **without first checking** for existing systems, you are violating project standards.

---

## üî¥ RULE 0: USE THE PRODUCTION ORCHESTRATOR FOR EXPERIMENT WORK

For **any statistical analysis, hypothesis testing, data export, or report generation**, you must use:

\`\`\`bash
python3 scripts/production/comprehensive_experiment_orchestrator.py experiment.json
\`\`\`

To resume interrupted experiments:

\`\`\`bash
python3 scripts/production/comprehensive_experiment_orchestrator.py --resume
\`\`\`

**You must not suggest writing custom scripts** for:
- Experiment execution
- Statistical analysis
- Visualization
- Hypothesis validation
- Data export
- Report generation

These functions are already supported via the orchestrator and must be used for integrity, traceability, and cost control.

---

## ‚öñÔ∏è MANDATORY DEVELOPMENT WORKFLOW

### ‚úÖ Rule 1: Search Before Building

Always run the existing systems checker before proposing new work:

\`\`\`bash
python3 scripts/production/check_existing_systems.py "functionality description"
\`\`\`

### ‚ùå Rule 2: Never Use Deprecated Systems

Do **not** suggest or reference:
- \`"AI Academic Advisor"\` (file-checker; deprecated)
- Any code in the \`deprecated/\` or \`archive/\` directories
- Files containing \`# DEPRECATED\` comments
- \`architectural_compliance_validator.py\` (moved to deprecated)

### ‚úÖ Rule 3: Build in \`experimental/\` First

All new development **must** begin in \`experimental/prototypes/\`

Do **not** suggest creating or modifying files directly in \`src/\` or \`scripts/\`

### ‚úÖ Rule 4: Enhance Before Rebuilding

If the needed functionality exists in production, **enhance it**

Do **not** duplicate or replace existing production systems unnecessarily

---

## üîç SEARCH STRATEGY

### ‚úÖ Always Search These:
- \`src/narrative_gravity/\` ‚Äì Core production code
- \`scripts/production/\` ‚Äì Production orchestration and validation scripts
- \`docs/specifications/\` ‚Äì Technical and implementation specs

### ‚ö†Ô∏è Conditionally Search:
- \`experimental/\` ‚Äì Only when explicitly asked or no production tool is suitable
- \`sandbox/\` ‚Äì For early-stage or exploratory research only

### ‚ùå Never Search:
- \`deprecated/\`, \`archive/\`
- Files with \`# DEPRECATED\` annotations
- Any reference to "AI Academic Advisor"

---

## ‚úÖ APPROVED PRODUCTION SYSTEMS

### Quality Assurance

- \`LLMQualityAssuranceSystem\` ‚Äì 6-layer mathematical validator
- \`ComponentQualityValidator\` ‚Äì Component-level QA validator

### Experiment Execution

- \`scripts/production/execute_experiment_definition.py\`
- \`scripts/production/comprehensive_experiment_orchestrator.py\` ‚Äì Full orchestration with checkpoint/resume

### Academic Export

- \`QAEnhancedDataExporter\`
- \`src/narrative_gravity/academic/data_export.py\`
- \`src/narrative_gravity/cli/academic_analysis_pipeline.py\`

---

## ‚úÖ REQUIRED REFERENCES

AI assistants must use and reference these docs when reasoning about project structure:

1. \`docs/EXISTING_SYSTEMS_INVENTORY.md\` ‚Äì Catalog of implemented systems  
2. \`docs/CODE_ORGANIZATION_STANDARDS.md\` ‚Äì Where functionality belongs  
3. \`DEVELOPMENT.md\` ‚Äì End-to-end guide for development workflows  
4. \`.ai_assistant_compliance_rules.md\` ‚Äì This file  

---

## üß† EXAMPLE PROMPTS FOR SESSION STATE MANAGEMENT

Use these regularly to manage assistant context during extended development:

### Session Recap

\`\`\`
Summarize the current state of this session. Include the goal, key files involved, major decisions made, and what‚Äôs been completed.
\`\`\`

### Assumptions Check

\`\`\`
What assumptions are you currently making about the task, the codebase, and our intended outcome? List them explicitly.
\`\`\`

### Assistant Handoff Bootstrap

\`\`\`
You're joining an in-progress development effort. Here's the most recent context:
- Recent commits
- Changed files
- High-level summary

What is in progress, what‚Äôs likely done, and what still needs to happen?
\`\`\`

---

## üõ°Ô∏è SUCCESS CRITERIA

An assistant is **compliant** if it:
- ‚úÖ Searches production systems first  
- ‚úÖ Enhances existing tools rather than duplicating  
- ‚úÖ Uses only approved QA and experiment tooling  
- ‚úÖ Puts all new development into \`experimental/\` first  
- ‚úÖ Never references deprecated or superseded systems  

---

## ‚ùå COMMON VIOLATIONS (DO NOT DO THESE)

| Violation | Why It's Wrong |
|----------|----------------|
| Suggesting new QA system | Use \`LLMQualityAssuranceSystem\` instead |
| Using ‚ÄúAI Academic Advisor‚Äù | Deprecated and ineffective |
| Creating new files in \`src/\` | Must go through \`experimental/\` first |
| Suggesting statistical scripts | Use orchestrator pipeline instead |
| Using code from \`deprecated/\` | Violates architectural compliance rules |

---

## üß≠ REMEMBER

These rules exist because the project has **repeatedly wasted time and resources** rebuilding inferior versions of already sophisticated systems.

By following these standards, AI assistants help the team:
- Preserve architectural coherence  
- Reduce duplication and drift  
- Maintain data and experiment integrity  
- Improve productivity over time

---
