"""Add v2.1 Experiment and Run models for hierarchical analysis

Revision ID: f6587a1dad12
Revises: 95c3a8503833
Create Date: 2025-06-09 20:47:16.635758

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'f6587a1dad12'
down_revision: Union[str, None] = '95c3a8503833'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('experiment',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('creator_id', sa.Integer(), nullable=True),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('hypothesis', sa.Text(), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('research_context', sa.Text(), nullable=True),
    sa.Column('prompt_template_id', sa.String(length=100), nullable=False),
    sa.Column('framework_config_id', sa.String(length=100), nullable=False),
    sa.Column('scoring_algorithm_id', sa.String(length=100), nullable=False),
    sa.Column('analysis_mode', sa.String(length=50), nullable=True),
    sa.Column('selected_models', sa.JSON(), nullable=False),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('total_runs', sa.Integer(), nullable=True),
    sa.Column('successful_runs', sa.Integer(), nullable=True),
    sa.Column('research_notes', sa.Text(), nullable=True),
    sa.Column('publication_status', sa.String(length=50), nullable=True),
    sa.Column('tags', sa.JSON(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['creator_id'], ['user.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_experiment_id'), 'experiment', ['id'], unique=False)
    op.create_table('run',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('experiment_id', sa.Integer(), nullable=False),
    sa.Column('run_number', sa.Integer(), nullable=False),
    sa.Column('text_id', sa.String(length=255), nullable=True),
    sa.Column('text_content', sa.Text(), nullable=False),
    sa.Column('input_length', sa.Integer(), nullable=False),
    sa.Column('llm_model', sa.String(length=100), nullable=False),
    sa.Column('llm_version', sa.String(length=50), nullable=True),
    sa.Column('prompt_template_version', sa.String(length=20), nullable=False),
    sa.Column('framework_version', sa.String(length=20), nullable=False),
    sa.Column('raw_scores', sa.JSON(), nullable=False),
    sa.Column('hierarchical_ranking', sa.JSON(), nullable=True),
    sa.Column('framework_fit_score', sa.Float(), nullable=True),
    sa.Column('well_justifications', sa.JSON(), nullable=True),
    sa.Column('narrative_elevation', sa.Float(), nullable=True),
    sa.Column('polarity', sa.Float(), nullable=True),
    sa.Column('coherence', sa.Float(), nullable=True),
    sa.Column('directional_purity', sa.Float(), nullable=True),
    sa.Column('narrative_position_x', sa.Float(), nullable=True),
    sa.Column('narrative_position_y', sa.Float(), nullable=True),
    sa.Column('execution_time', sa.DateTime(), nullable=True),
    sa.Column('duration_seconds', sa.Float(), nullable=True),
    sa.Column('api_cost', sa.Float(), nullable=True),
    sa.Column('raw_prompt', sa.Text(), nullable=True),
    sa.Column('raw_response', sa.Text(), nullable=True),
    sa.Column('model_parameters', sa.JSON(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('success', sa.Boolean(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('complete_provenance', sa.JSON(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['experiment_id'], ['experiment.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_run_id'), 'run', ['id'], unique=False)
    op.drop_table('performance_metrics')
    op.drop_index(op.f('idx_jobs_model_name'), table_name='jobs')
    op.drop_index(op.f('idx_jobs_speaker'), table_name='jobs')
    op.drop_table('jobs')
    op.drop_table('variance_statistics')
    op.drop_table('variance_stats')
    op.drop_index(op.f('idx_runs_job_id'), table_name='runs')
    op.drop_index(op.f('idx_runs_model_name'), table_name='runs')
    op.drop_index(op.f('idx_runs_timestamp'), table_name='runs')
    op.drop_table('runs')
    op.alter_column('chunk', 'framework_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.alter_column('document', 'document_metadata',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.add_column('job', sa.Column('experiment_id', sa.Integer(), nullable=True))
    op.add_column('job', sa.Column('prompt_template_config', sa.JSON(), nullable=True))
    op.add_column('job', sa.Column('scoring_algorithm', sa.String(length=50), nullable=True))
    op.add_column('job', sa.Column('analysis_mode', sa.String(length=50), nullable=True))
    op.alter_column('job', 'text_ids',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.alter_column('job', 'frameworks',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.alter_column('job', 'models',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.alter_column('job', 'job_config',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.create_foreign_key(None, 'job', 'experiment', ['experiment_id'], ['id'])
    op.add_column('task', sa.Column('hierarchical_result', sa.JSON(), nullable=True))
    op.add_column('task', sa.Column('justifications', sa.JSON(), nullable=True))
    op.alter_column('task', 'result_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('task', 'result_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.drop_column('task', 'justifications')
    op.drop_column('task', 'hierarchical_result')
    op.drop_constraint(None, 'job', type_='foreignkey')
    op.alter_column('job', 'job_config',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('job', 'models',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('job', 'frameworks',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('job', 'text_ids',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.drop_column('job', 'analysis_mode')
    op.drop_column('job', 'scoring_algorithm')
    op.drop_column('job', 'prompt_template_config')
    op.drop_column('job', 'experiment_id')
    op.alter_column('document', 'document_metadata',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('chunk', 'framework_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.create_table('runs',
    sa.Column('run_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('job_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('run_number', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('well_scores', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('narrative_position', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('analysis_text', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('model_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('framework', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=False),
    sa.Column('cost', sa.NUMERIC(precision=8, scale=4), autoincrement=False, nullable=False),
    sa.Column('duration_seconds', sa.NUMERIC(precision=6, scale=2), autoincrement=False, nullable=False),
    sa.Column('success', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('raw_prompt', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('raw_response', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('input_text', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('model_parameters', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('api_metadata', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.job_id'], name=op.f('runs_job_id_fkey')),
    sa.PrimaryKeyConstraint('run_id', name=op.f('runs_pkey'))
    )
    op.create_index(op.f('idx_runs_timestamp'), 'runs', ['timestamp'], unique=False)
    op.create_index(op.f('idx_runs_model_name'), 'runs', ['model_name'], unique=False)
    op.create_index(op.f('idx_runs_job_id'), 'runs', ['job_id'], unique=False)
    op.create_table('variance_stats',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('job_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('well_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('mean_score', sa.NUMERIC(precision=6, scale=4), autoincrement=False, nullable=False),
    sa.Column('std_deviation', sa.NUMERIC(precision=6, scale=4), autoincrement=False, nullable=False),
    sa.Column('variance', sa.NUMERIC(precision=8, scale=6), autoincrement=False, nullable=False),
    sa.Column('score_category', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('well_type', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.job_id'], name=op.f('variance_stats_job_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('variance_stats_pkey'))
    )
    op.create_table('variance_statistics',
    sa.Column('job_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('well_statistics', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('narrative_statistics', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('framework_info', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('job_id', name=op.f('variance_statistics_pkey'))
    )
    op.create_table('jobs',
    sa.Column('job_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('speaker', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('speech_type', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('text_length', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('framework', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('model_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('total_runs', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('successful_runs', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('total_cost', sa.NUMERIC(precision=10, scale=4), autoincrement=False, nullable=False),
    sa.Column('total_duration_seconds', sa.NUMERIC(precision=8, scale=2), autoincrement=False, nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=False),
    sa.Column('mean_scores', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('variance_stats', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('threshold_category', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('job_id', name='jobs_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('idx_jobs_speaker'), 'jobs', ['speaker'], unique=False)
    op.create_index(op.f('idx_jobs_model_name'), 'jobs', ['model_name'], unique=False)
    op.create_table('performance_metrics',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('job_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('model_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('framework', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('success_rate', sa.NUMERIC(precision=5, scale=4), autoincrement=False, nullable=False),
    sa.Column('avg_cost_per_run', sa.NUMERIC(precision=8, scale=4), autoincrement=False, nullable=False),
    sa.Column('avg_duration_per_run', sa.NUMERIC(precision=6, scale=2), autoincrement=False, nullable=False),
    sa.Column('total_variance_sum', sa.NUMERIC(precision=8, scale=6), autoincrement=False, nullable=False),
    sa.Column('max_individual_variance', sa.NUMERIC(precision=8, scale=6), autoincrement=False, nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.job_id'], name=op.f('performance_metrics_job_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('performance_metrics_pkey'))
    )
    op.drop_index(op.f('ix_run_id'), table_name='run')
    op.drop_table('run')
    op.drop_index(op.f('ix_experiment_id'), table_name='experiment')
    op.drop_table('experiment')
    # ### end Alembic commands ###
