# Discernus v8.1: Architectural Recovery and Test-Driven Implementation Plan

**Date**: 2025-08-18  
**Status**: Approved Strategic Plan
**Lead**: Senior Architect

---

## 1. Executive Summary

The Discernus v8.0 architecture has suffered from systemic integration failures, resulting in a non-functional research pipeline. A comprehensive audit has revealed that while core components for analysis and code generation are fundamentally sound, the system is crippled by a critical "execution gap": it generates essential computational assets but never executes them. Further, the intellectual rigor of core specifications has been degraded, depriving the system of the necessary guidance to produce high-quality academic output.

This document outlines a recovery plan to evolve the system to **v8.1**. The strategy is rooted in a **test-first, component-driven methodology**. We will abandon the fragile end-to-end integration approach and instead build, test, and validate each component in isolation before integration.

The plan involves resurrecting a proven, production-ready `SecureCodeExecutor` from git history, implementing a series of deterministic `Assembler` utilities to manage prompt engineering, and restoring the intellectual depth of our frameworks and experiments. This will produce a simpler, more robust, and more intelligent platform capable of fulfilling its mission.

---

## 2. Strategic Context: Key Audit Findings

Our path forward is informed by the following critical findings from the [Comprehensive System Audit](system_audit_and_unit_testing_strategy.md):

*   **Analysis Stage is Solid**: The `EnhancedAnalysisAgent` is highly reliable and produces consistent, high-quality structured data. The system's foundation is strong.
*   **Code Generation is a Solved Problem**: LLMs can reliably generate correct, executable Python code for derived metrics and statistical analysis in a single shot.
*   **The "Execution Gap" is the Core Failure**: The central problem is that the system generates code (for metrics, statistics) but never executes it, causing a total breakdown of the data pipeline.
*   **Key Infrastructure was Discarded**: A robust, production-ready `SecureCodeExecutor` and its dependencies were previously built, proven, and then deleted from the codebase.
*   **Specifications Lack Rigor**: The intellectual guidance in frameworks and experiments has been "simplified" to the point of being inadequate, preventing the system from producing credible academic work.
*   **Synthesis is Over-Engineered**: The current three-agent synthesis model is an unnecessary complication based on obsolete token limit concerns.

---

## 3. Core Methodology: Test-Driven, Component-First Development

To break the cycle of integration failures, all v8.1 development will adhere to the following pattern:

1.  **Define the Contract**: For any new or restored component, first define its precise inputs, outputs, and expected behaviors.
2.  **Write the Unit Test**: Create a comprehensive unit test suite that validates the component's contract. This includes testing for success cases, failure cases, and edge cases. The test must fail initially.
3.  **Implement the Component**: Write the minimum amount of code required to make the unit test pass.
4.  **Refactor and Harden**: Improve the implementation while ensuring all tests continue to pass.
5.  **Integrate**: Only once a component is fully validated in isolation will it be integrated into the broader pipeline.

This methodology applies to all new and restored components outlined below.

---

## 4. Implementation Plan: Path to v8.1

The recovery will proceed by implementing a series of well-defined, testable components.

### Phase 1: Foundational Infrastructure [STATUS: COMPLETED]

#### **Component 1: Secure Code Execution (`CodeExecutor`)**
*   **Action**: Resurrect the `SecureCodeExecutor`, `LLMCodeSanitizer`, and `CapabilityRegistry` from git history.
*   **Test Plan**:
    *   Verify that the `CodeExecutor` can securely run Python code in a sandboxed environment.
    *   Test resource limits (CPU, memory).
    *   Validate that the `LLMCodeSanitizer` correctly fixes common LLM code errors.
    *   Confirm that the `CapabilityRegistry` correctly manages library permissions.
*   **Definition of Done**: A fully tested `CodeExecutor` service is available for use by the orchestrator.

### Phase 2: Code Generation and Execution Pipeline [STATUS: COMPLETED]

**Major Breakthrough**: This phase has been successfully completed using a **THIN prompting approach** that abandons structured output constraints in favor of precise natural language instructions. Key architectural decisions:

**Structured Output Abandonment**: Through extensive prompt engineering testing, we discovered that **natural prompting produces superior, more reliable code** than structured output constraints. LLMs generate cleaner, more executable code when not forced into artificial JSON schemas.

**Model Selection**: `vertex_ai/gemini-2.5-flash` was selected as the standard for code generation after testing both Flash and Flash Lite. While Flash Lite offers 60% cost savings, it has behavioral inconsistencies (ignoring format instructions) that would require brittle workarounds. Flash provides reliable, consistent behavior that aligns with THIN principles.

**Security Model Integration**: The `CapabilityRegistry` with preset configurations successfully enables controlled file operations while maintaining security. The `data_aggregation` preset allows necessary operations (`open`, `json`, `pandas`) while blocking dangerous ones.

**End-to-End Validation**: The complete pipeline now successfully processes experiments from analysis → code generation → secure execution → data aggregation, producing structured DataFrames ready for statistical analysis.

#### **Component 2: Analysis Data Aggregation** [STATUS: COMPLETED]
*   **Architectural Achievement**: Successfully implemented the "LLM-as-Code-Generator" pattern where the LLM generates deterministic aggregation scripts rather than performing high-volume data processing directly. This maintains scalability, determinism, and full provenance while keeping the orchestrator THIN and framework-agnostic.
*   **Security Model**: The `CapabilityRegistry` `data_aggregation` preset successfully enables controlled file operations (`open`, `json`, `pandas`, `os.path`, `glob`) while blocking dangerous operations.
*   **Sub-Component 2a: `DataAggregationPromptAssembler`** [COMPLETED]
    *   **Implementation**: Created with THIN prompting approach - precise natural language instructions that consistently produce clean, executable Python code.
    *   **Validation**: Tested and confirmed reliable prompt assembly from framework output schema and analysis file samples.
*   **Sub-Component 2b: Pipeline Integration** [COMPLETED]
    *   **Implementation**: Fully integrated into `ExperimentOrchestrator` using natural prompting (no structured output) with markdown code extraction fallback.
    *   **Validation**: Successfully processes experiments end-to-end, producing correctly structured DataFrames with 4 rows of dimensional scores from 4 documents.

#### **Component 3: Derived Metrics Generation and Execution** [STATUS: COMPLETED]
*   **Major Achievement**: Successfully integrated derived metrics calculation using the proven THIN approach, generating 6 new derived metric columns from framework specifications.
*   **Sub-Component 3a: `DerivedMetricsPromptAssembler`** [COMPLETED]
    *   **Implementation**: Enhanced with explicit security constraints (no eval/exec) and nested data structure support.
    *   **Validation**: Successfully generates code that implements mathematical formulas explicitly without dynamic execution.
*   **Sub-Component 3b: Pipeline Integration** [COMPLETED]
    *   **Implementation**: Fully integrated into `ExperimentOrchestrator` with v10.0 specification compliance.
    *   **Validation**: Successfully calculates complex derived metrics including tension calculations and composite indices.

#### **Component 4: Statistical Analysis Pipeline** [STATUS: COMPLETED]
*   **Breakthrough Implementation**: Created `StatisticalAnalysisPromptAssembler` and integrated comprehensive statistical analysis generation using THIN prompting approach.
*   **Results**: Successfully generates and executes statistical analysis code producing 8 result categories including descriptive statistics, correlations, and significance tests.
*   **Security Validation**: Maintains security model while enabling legitimate statistical computations using pandas, numpy, scipy, and statistics libraries.

### Phase 3: Synthesis and Final Reporting

#### **Component 4: Synthesis Pipeline**
*   **Sub-Component 4a: `SynthesisPromptAssembler`**
    *   **Action**: Create a utility that assembles the final synthesis prompt, incorporating statistical results and integrating with the `txtai` RAG index to retrieve supporting evidence.
    *   **Test Plan**:
        *   Verify the assembler correctly queries `txtai`.
        *   Confirm the final prompt contains all necessary context (stats, evidence, framework).
*   **Sub-Component 4b: Unified Synthesis Agent**
    *   **Action**: Replace the three narrative agents with a single agent that takes the assembled prompt and generates the final, complete research report in Markdown format.
    *   **Test Plan**: Validate that the generated report is coherent, correctly interprets the statistical findings, and properly cites the provided evidence.

### Phase 4: Intellectual Rigor Restoration [STATUS: COMPLETED]

**Architectural Mandate for Code Generation**: All code-generating agents in the v8.1 architecture standardize on Google's Gemini-series models via Vertex AI. However, **structured output has been abandoned for code generation** after extensive testing revealed that **natural prompting produces superior, more reliable code** than JSON schema constraints. 

**Revised Code Generation Strategy**:
- **For Code Generation**: Use precise natural language instructions with `vertex_ai/gemini-2.5-flash`
- **For Data Extraction**: Continue using structured output where appropriate (validation responses, data parsing)
- **Format Handling**: Simple regex extraction for markdown code blocks when needed, avoiding complex parsing pipelines

#### **Component 5: Specification and Reference Experiment Overhaul** [STATUS: COMPLETED]
*   **Major Achievement**: Successfully upgraded all specifications to v10.0 standard with comprehensive intellectual rigor.
*   **Sub-Component 5a: Enhanced Specifications** [COMPLETED]
    *   **Implementation**: Created `FRAMEWORK_SPECIFICATION_V10.0.md` and `EXPERIMENT_SPECIFICATION_V10.0.md` with scholarly depth, clear guidance, and machine-readable appendices.
    *   **Validation**: Specifications include conceptual onboarding, term definitions, academic citations, and practical authoring guidance.
*   **Sub-Component 5b: Reference Frameworks** [COMPLETED]
    *   **Implementation**: Created `cff_v10.md` (Cohesive Flourishing Framework) compliant with v10.0 specification, synthesizing best elements from historical versions.
    *   **Validation**: Framework includes robust theoretical foundations, empirical grounding, and comprehensive analytical methodology.
*   **Sub-Component 5c: Validation Architecture** [COMPLETED]
    *   **Implementation**: Elevated `ExperimentCoherenceAgent` as primary validator using v10.0 specifications, successfully identifying and resolving specification inconsistencies.
    *   **Validation**: Agent provides intelligent, actionable feedback for experiment setup coherence.

---

## 5. Current Status and Next Steps

### **Architectural Recovery Status: ~95% Complete**

**✅ COMPLETED PHASES:**
- **Phase 1**: Foundational Infrastructure - `SecureCodeExecutor`, `LLMCodeSanitizer`, `CapabilityRegistry` restored and enhanced
- **Phase 2**: Code Generation Pipeline - Complete analytical pipeline functional with THIN prompting approach
- **Phase 4**: Intellectual Rigor - v10.0 specifications, reference frameworks, and validation architecture

**✅ COMPLETED COMPONENTS:**
- **Analysis Data Aggregation**: 4 documents → structured DataFrame
- **Derived Metrics Calculation**: 6 derived metrics generated from framework formulas
- **Statistical Analysis**: 8 result categories with comprehensive statistical computations
- **Framework Specification Compliance**: Enhanced definitions successfully guide Pro model behavior

**🔄 REMAINING FOR COMPLETION:**
- **Phase 3**: Synthesis and Final Reporting - RAG integration and unified synthesis agent

### **Key Architectural Breakthroughs**

1. **THIN Prompting Superiority**: Natural language instructions produce more reliable code than structured output constraints
2. **LLM-as-Code-Generator Pattern**: Scalable, deterministic approach for data processing while maintaining provenance
3. **Security Model Success**: `CapabilityRegistry` presets enable controlled operations without compromising security
4. **Component-First Methodology Validated**: Test-driven approach prevented integration failures and enabled rapid debugging
5. **Model Selection Optimization**: Gemini 2.5 Pro for analysis provides superior framework specification compliance
6. **Framework Definition Enhancement**: Precise conceptual definitions (compersion vs compassion) successfully guide LLM behavior

### **Critical Lessons Learned**

1. **Framework Integrity**: Frameworks are intellectual artifacts that cannot be arbitrarily modified to accommodate implementation issues - the system must conform to the framework specification, not vice versa.
2. **Specification Compliance**: Enhanced conceptual definitions in frameworks are essential for guiding LLM behavior and preventing conceptual substitutions.
3. **Model Capability Matching**: Pro model's superior instruction-following is crucial for complex framework specifications requiring precise terminology.

### **Final Completion Steps**

1. **Synthesis Pipeline Integration**: Implement `txtai` RAG integration for evidence retrieval
2. **Unified Synthesis Agent**: Create final report generation using proven THIN approach
3. **End-to-End Validation**: Complete research pipeline from analysis through publication-ready reports

**Status**: The core analytical pipeline is fully functional. Discernus can now process experiments from raw text through comprehensive statistical analysis with full provenance and security. Only synthesis and final reporting remain for complete platform restoration.