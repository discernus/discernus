# Discernus v8.1: Architectural Recovery and Test-Driven Implementation Plan

**Date**: 2025-08-18  
**Status**: Approved Strategic Plan
**Lead**: Senior Architect

---

## 1. Executive Summary

The Discernus v8.0 architecture has suffered from systemic integration failures, resulting in a non-functional research pipeline. A comprehensive audit has revealed that while core components for analysis and code generation are fundamentally sound, the system is crippled by a critical "execution gap": it generates essential computational assets but never executes them. Further, the intellectual rigor of core specifications has been degraded, depriving the system of the necessary guidance to produce high-quality academic output.

This document outlines a recovery plan to evolve the system to **v8.1**. The strategy is rooted in a **test-first, component-driven methodology**. We will abandon the fragile end-to-end integration approach and instead build, test, and validate each component in isolation before integration.

The plan involves resurrecting a proven, production-ready `SecureCodeExecutor` from git history, implementing a series of deterministic `Assembler` utilities to manage prompt engineering, and restoring the intellectual depth of our frameworks and experiments. This will produce a simpler, more robust, and more intelligent platform capable of fulfilling its mission.

---

## 2. Strategic Context: Key Audit Findings

Our path forward is informed by the following critical findings from the [Comprehensive System Audit](system_audit_and_unit_testing_strategy.md):

*   **Analysis Stage is Solid**: The `EnhancedAnalysisAgent` is highly reliable and produces consistent, high-quality structured data. The system's foundation is strong.
*   **Code Generation is a Solved Problem**: LLMs can reliably generate correct, executable Python code for derived metrics and statistical analysis in a single shot.
*   **The "Execution Gap" is the Core Failure**: The central problem is that the system generates code (for metrics, statistics) but never executes it, causing a total breakdown of the data pipeline.
*   **Key Infrastructure was Discarded**: A robust, production-ready `SecureCodeExecutor` and its dependencies were previously built, proven, and then deleted from the codebase.
*   **Specifications Lack Rigor**: The intellectual guidance in frameworks and experiments has been "simplified" to the point of being inadequate, preventing the system from producing credible academic work.
*   **Synthesis is Over-Engineered**: The current three-agent synthesis model is an unnecessary complication based on obsolete token limit concerns.

---

## 3. Core Methodology: Test-Driven, Component-First Development

To break the cycle of integration failures, all v8.1 development will adhere to the following pattern:

1.  **Define the Contract**: For any new or restored component, first define its precise inputs, outputs, and expected behaviors.
2.  **Write the Unit Test**: Create a comprehensive unit test suite that validates the component's contract. This includes testing for success cases, failure cases, and edge cases. The test must fail initially.
3.  **Implement the Component**: Write the minimum amount of code required to make the unit test pass.
4.  **Refactor and Harden**: Improve the implementation while ensuring all tests continue to pass.
5.  **Integrate**: Only once a component is fully validated in isolation will it be integrated into the broader pipeline.

This methodology applies to all new and restored components outlined below.

---

## 4. Implementation Plan: Path to v8.1

The recovery will proceed by implementing a series of well-defined, testable components.

### Phase 1: Foundational Infrastructure [STATUS: COMPLETED]

#### **Component 1: Secure Code Execution (`CodeExecutor`)**
*   **Action**: Resurrect the `SecureCodeExecutor`, `LLMCodeSanitizer`, and `CapabilityRegistry` from git history.
*   **Test Plan**:
    *   Verify that the `CodeExecutor` can securely run Python code in a sandboxed environment.
    *   Test resource limits (CPU, memory).
    *   Validate that the `LLMCodeSanitizer` correctly fixes common LLM code errors.
    *   Confirm that the `CapabilityRegistry` correctly manages library permissions.
*   **Definition of Done**: A fully tested `CodeExecutor` service is available for use by the orchestrator.

### Phase 2: Code Generation and Execution Pipeline [STATUS: COMPLETED]

**Major Breakthrough**: This phase has been successfully completed using a **THIN prompting approach** that abandons structured output constraints in favor of precise natural language instructions. Key architectural decisions:

**Structured Output Abandonment**: Through extensive prompt engineering testing, we discovered that **natural prompting produces superior, more reliable code** than structured output constraints. LLMs generate cleaner, more executable code when not forced into artificial JSON schemas.

**Model Selection**: `vertex_ai/gemini-2.5-flash` was selected as the standard for code generation after testing both Flash and Flash Lite. While Flash Lite offers 60% cost savings, it has behavioral inconsistencies (ignoring format instructions) that would require brittle workarounds. Flash provides reliable, consistent behavior that aligns with THIN principles.

**Security Model Integration**: The `CapabilityRegistry` with preset configurations successfully enables controlled file operations while maintaining security. The `data_aggregation` preset allows necessary operations (`open`, `json`, `pandas`) while blocking dangerous ones.

**End-to-End Validation**: The complete pipeline now successfully processes experiments from analysis â†’ code generation â†’ secure execution â†’ data aggregation, producing structured DataFrames ready for statistical analysis.

#### **Component 2: Analysis Data Aggregation** [STATUS: COMPLETED]
*   **Architectural Achievement**: Successfully implemented the "LLM-as-Code-Generator" pattern where the LLM generates deterministic aggregation scripts rather than performing high-volume data processing directly. This maintains scalability, determinism, and full provenance while keeping the orchestrator THIN and framework-agnostic.
*   **Security Model**: The `CapabilityRegistry` `data_aggregation` preset successfully enables controlled file operations (`open`, `json`, `pandas`, `os.path`, `glob`) while blocking dangerous operations.
*   **Sub-Component 2a: `DataAggregationPromptAssembler`** [COMPLETED]
    *   **Implementation**: Created with THIN prompting approach - precise natural language instructions that consistently produce clean, executable Python code.
    *   **Validation**: Tested and confirmed reliable prompt assembly from framework output schema and analysis file samples.
*   **Sub-Component 2b: Pipeline Integration** [COMPLETED]
    *   **Implementation**: Fully integrated into `ExperimentOrchestrator` using natural prompting (no structured output) with markdown code extraction fallback.
    *   **Validation**: Successfully processes experiments end-to-end, producing correctly structured DataFrames with 4 rows of dimensional scores from 4 documents.

#### **Component 3: Derived Metrics Generation and Execution** [STATUS: READY]
*   **Foundation**: With data aggregation complete, the derived metrics pipeline can now be implemented using the same proven THIN approach.
*   **Sub-Component 3a: `DerivedMetricsPromptAssembler`** [IMPLEMENTED]
    *   **Status**: Basic implementation exists and tested, ready for integration.
*   **Sub-Component 3b: Pipeline Integration** [PENDING]
    *   **Action**: Integrate derived metrics generation into the main orchestrator using the proven natural prompting approach.
    *   **Test Plan**: Validate that LLM-generated code correctly calculates derived metrics as specified in framework definitions.

### Phase 3: Synthesis and Final Reporting

#### **Component 4: Synthesis Pipeline**
*   **Sub-Component 4a: `SynthesisPromptAssembler`**
    *   **Action**: Create a utility that assembles the final synthesis prompt, incorporating statistical results and integrating with the `txtai` RAG index to retrieve supporting evidence.
    *   **Test Plan**:
        *   Verify the assembler correctly queries `txtai`.
        *   Confirm the final prompt contains all necessary context (stats, evidence, framework).
*   **Sub-Component 4b: Unified Synthesis Agent**
    *   **Action**: Replace the three narrative agents with a single agent that takes the assembled prompt and generates the final, complete research report in Markdown format.
    *   **Test Plan**: Validate that the generated report is coherent, correctly interprets the statistical findings, and properly cites the provided evidence.

### Phase 4: Intellectual Rigor Restoration [STATUS: COMPLETED]

**Architectural Mandate for Code Generation**: All code-generating agents in the v8.1 architecture standardize on Google's Gemini-series models via Vertex AI. However, **structured output has been abandoned for code generation** after extensive testing revealed that **natural prompting produces superior, more reliable code** than JSON schema constraints. 

**Revised Code Generation Strategy**:
- **For Code Generation**: Use precise natural language instructions with `vertex_ai/gemini-2.5-flash`
- **For Data Extraction**: Continue using structured output where appropriate (validation responses, data parsing)
- **Format Handling**: Simple regex extraction for markdown code blocks when needed, avoiding complex parsing pipelines

#### **Component 5: Specification and Reference Experiment Overhaul** [STATUS: COMPLETED]
*   **Major Achievement**: Successfully upgraded all specifications to v10.0 standard with comprehensive intellectual rigor.
*   **Sub-Component 5a: Enhanced Specifications** [COMPLETED]
    *   **Implementation**: Created `FRAMEWORK_SPECIFICATION_V10.0.md` and `EXPERIMENT_SPECIFICATION_V10.0.md` with scholarly depth, clear guidance, and machine-readable appendices.
    *   **Validation**: Specifications include conceptual onboarding, term definitions, academic citations, and practical authoring guidance.
*   **Sub-Component 5b: Reference Frameworks** [COMPLETED]
    *   **Implementation**: Created `cff_v10.md` (Cohesive Flourishing Framework) compliant with v10.0 specification, synthesizing best elements from historical versions.
    *   **Validation**: Framework includes robust theoretical foundations, empirical grounding, and comprehensive analytical methodology.
*   **Sub-Component 5c: Validation Architecture** [COMPLETED]
    *   **Implementation**: Elevated `ExperimentCoherenceAgent` as primary validator using v10.0 specifications, successfully identifying and resolving specification inconsistencies.
    *   **Validation**: Agent provides intelligent, actionable feedback for experiment setup coherence.

---

## 5. Current Status and Next Steps

### **Architectural Recovery Status: ~85% Complete**

**âœ… COMPLETED PHASES:**
- **Phase 1**: Foundational Infrastructure - `SecureCodeExecutor`, `LLMCodeSanitizer`, `CapabilityRegistry` restored and enhanced
- **Phase 2**: Code Generation Pipeline - Data aggregation fully functional with THIN prompting approach
- **Phase 4**: Intellectual Rigor - v10.0 specifications, reference frameworks, and validation architecture

**ðŸ”„ READY FOR COMPLETION:**
- **Phase 3**: Synthesis and Final Reporting - Foundation exists, needs integration
- **Component 3**: Derived Metrics Pipeline - Components implemented, needs orchestrator integration

### **Key Architectural Breakthroughs**

1. **THIN Prompting Superiority**: Natural language instructions produce more reliable code than structured output constraints
2. **LLM-as-Code-Generator Pattern**: Scalable, deterministic approach for data processing while maintaining provenance
3. **Security Model Success**: `CapabilityRegistry` presets enable controlled operations without compromising security
4. **Component-First Methodology Validated**: Test-driven approach prevented integration failures and enabled rapid debugging

### **Immediate Next Steps**

1. **Complete Derived Metrics Integration**: Apply proven THIN approach to integrate derived metrics calculation
2. **Implement Statistical Analysis Pipeline**: Use same natural prompting approach for statistical code generation
3. **Finalize Synthesis Pipeline**: Integrate `txtai` RAG with unified synthesis agent
4. **End-to-End Validation**: Execute complete research pipeline from analysis through final report

The architectural recovery has successfully restored core functionality and established a robust, maintainable foundation for completing the Discernus research platform.