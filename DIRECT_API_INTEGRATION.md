# Direct API Integration for Flagship LLMs

## ðŸŽ¯ **The Right Solution for Academic Research**

For your narrative gravity analysis to have academic credibility, you need **direct access to flagship models**:
- **OpenAI GPT-4** (ChatGPT)
- **Anthropic Claude-3** 
- **Mistral Large**

## ðŸ“‹ **Setup Guide**

### **1. Get API Keys**
```bash
# Get API keys from:
# OpenAI: https://platform.openai.com/api-keys
# Anthropic: https://console.anthropic.com/
# Mistral: https://console.mistral.ai/
```

### **2. Install Libraries**
```bash
pip install openai anthropic mistralai python-dotenv
```

### **3. Environment Setup**
```bash
# Create .env file
echo "OPENAI_API_KEY=your_openai_key" >> .env
echo "ANTHROPIC_API_KEY=your_anthropic_key" >> .env  
echo "MISTRAL_API_KEY=your_mistral_key" >> .env
```

## ðŸ”§ **Integration with Your Framework**

### **Update HuggingFace Client for Direct APIs**

```python
import openai
import anthropic
from mistralai.client import MistralClient
import os
from dotenv import load_dotenv

load_dotenv()

class DirectAPIClient:
    """Direct API client for flagship LLMs"""
    
    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.anthropic_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        self.mistral_client = MistralClient(api_key=os.getenv("MISTRAL_API_KEY"))
    
    def analyze_with_gpt4(self, prompt: str) -> tuple[dict, float]:
        """Analyze text with GPT-4"""
        response = self.openai_client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        # Calculate cost (approximate)
        input_tokens = len(prompt.split()) * 1.3  # rough estimate
        output_tokens = len(response.choices[0].message.content.split()) * 1.3
        cost = (input_tokens * 0.00003) + (output_tokens * 0.00006)  # GPT-4 pricing
        
        return self.parse_response(response.choices[0].message.content), cost
    
    def analyze_with_claude(self, prompt: str) -> tuple[dict, float]:
        """Analyze text with Claude-3"""
        response = self.anthropic_client.messages.create(
            model="claude-3-sonnet-20240229",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        # Calculate cost
        input_tokens = response.usage.input_tokens
        output_tokens = response.usage.output_tokens
        cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)  # Claude pricing
        
        return self.parse_response(response.content[0].text), cost
    
    def analyze_with_mistral(self, prompt: str) -> tuple[dict, float]:
        """Analyze text with Mistral Large"""
        response = self.mistral_client.chat(
            model="mistral-large-latest",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        # Calculate cost (approximate)
        input_tokens = len(prompt.split()) * 1.3
        output_tokens = len(response.choices[0].message.content.split()) * 1.3
        cost = (input_tokens * 0.000002) + (output_tokens * 0.000008)  # Mistral pricing
        
        return self.parse_response(response.choices[0].message.content), cost
    
    def parse_response(self, content: str) -> dict:
        """Parse LLM response into structured format"""
        try:
            # Try to parse as JSON first
            import json
            return json.loads(content)
        except:
            # Fallback parsing logic
            return {"raw_response": content, "parsed": False}
```

### **Update Your Test Script**

```python
# Replace HuggingFace client with direct API client
from direct_api_client import DirectAPIClient

class DirectAPITester:
    """Test narrative gravity with direct flagship APIs"""
    
    def __init__(self, framework: str):
        self.framework = framework
        self.client = DirectAPIClient()
        
    def test_all_models(self, text: str) -> dict:
        """Test with all flagship models"""
        results = {}
        
        # Get framework prompt
        prompt = self.generate_prompt(text, self.framework)
        
        # Test with each model
        print("ðŸ¤– Testing with GPT-4...")
        gpt4_result, gpt4_cost = self.client.analyze_with_gpt4(prompt)
        results["gpt4"] = {"result": gpt4_result, "cost": gpt4_cost}
        
        print("ðŸ¤– Testing with Claude-3...")
        claude_result, claude_cost = self.client.analyze_with_claude(prompt)
        results["claude"] = {"result": claude_result, "cost": claude_cost}
        
        print("ðŸ¤– Testing with Mistral...")
        mistral_result, mistral_cost = self.client.analyze_with_mistral(prompt)
        results["mistral"] = {"result": mistral_result, "cost": mistral_cost}
        
        total_cost = gpt4_cost + claude_cost + mistral_cost
        print(f"âœ… Total cost: ${total_cost:.4f}")
        
        return results
```

## ðŸ’° **Cost Estimates (Much Cheaper!)**

### **Per Analysis (1000 words)**:
- **GPT-4**: ~$0.05-0.10
- **Claude-3**: ~$0.02-0.05  
- **Mistral**: ~$0.01-0.03
- **Total per test**: ~$0.08-0.18

### **Academic Research Budget**:
- **100 test cases**: ~$8-18 total
- **1000 test cases**: ~$80-180 total
- **No infrastructure costs**
- **No management overhead**

## ðŸŽ“ **Academic Benefits**

### **Research Credibility**:
- âœ… **"We tested with GPT-4, Claude-3, and Mistral"**
- âœ… **Reproducible results** with exact model versions
- âœ… **Direct comparison** of flagship models
- âœ… **No confounding variables** from alternative models

### **Paper Submission**:
- âœ… **Reviewers recognize** flagship model names
- âœ… **Standard benchmarks** in academic literature
- âœ… **Clear methodology** for replication

## ðŸš€ **Quick Start**

1. **Get API keys** from OpenAI, Anthropic, Mistral
2. **Update your existing prompt generation** system
3. **Replace HuggingFace calls** with direct API calls
4. **Run comprehensive tests** with all three models
5. **Generate comparison analysis** for your paper

## ðŸŽ¯ **Bottom Line**

**Direct APIs are:**
- âœ… **10x simpler** than HuggingFace Endpoints
- âœ… **10x cheaper** for research use cases
- âœ… **100% academic credible** 
- âœ… **Zero infrastructure management**
- âœ… **Actual flagship models** you need

Your existing prompt generation and analysis framework is perfect - you just need to swap out the model access layer! 