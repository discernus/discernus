# THIN Architecture Compliance Audit Report
Generated: 2025-08-10 07:35:52

## Executive Summary
- **Total Violations**: 230
- **Critical Violations**: 0
- **High Priority Violations**: 156
- **Agents Audited**: 14
- **Non-Compliant Agents**: 12

## Violation Breakdown

- **INLINE_PROMPTS**: 149 violations
- **EXCESSIVE_PARSING**: 72 violations
- **MISSING_YAML**: 7 violations
- **COMPLEX_PARSING_METHODS**: 2 violations

## Detailed Agent Analysis

### EnhancedAnalysisAgent
**Violations**: 43

ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.local_artifact_storage import LocalArtifactStorage
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/analysis_cache.py:15
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.audit_logger import AuditLogger
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/analysis_cache.py:16
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: THIN Principle: Pure software caching infrastructure.
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/analysis_cache.py:31
âš ï¸ **INLINE_PROMPTS**: F-string prompts: batch_content = f'{framework_content}{doc_content_hash}{model}'...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/analysis_cache.py:59
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: cached_result = json.loads(cached_content.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/analysis_cache.py:87
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"âš ï¸ Cache hit but failed to load content: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/analysis_cache.py:101
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"ğŸ” No cache hit for {batch_id} - will perform analysis...")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/analysis_cache.py:106
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.local_artifact_storage import LocalArtifactStorage
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/document_processor.py:15
âš ï¸ **INLINE_PROMPTS**: F-string prompts: content_for_analysis = f"[Binary content, base64 encoded: {len(doc_content)} chars]"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/document_processor.py:57
âš ï¸ **INLINE_PROMPTS**: F-string prompts: formatted_docs.append(f"Document {i+1} ({doc.filename}):\n{doc.content}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/document_processor.py:102
âš ï¸ **INLINE_PROMPTS**: F-string prompts: formatted_docs.append(f"Document {i+1} ({doc.filename}):\n{doc.content}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/llm_analyzer.py:95
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.security_boundary import ExperimentSecurityBoundary, SecurityError
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:27
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.audit_logger import AuditLogger
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:28
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.local_artifact_storage import LocalArtifactStorage
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:29
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"ğŸ§  {self.agent_name} initialized with mathematical validation")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:69
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: json_match = re.search(json_pattern, result_content, re.DOTALL)
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:154
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: analysis_data = json.loads(json_match.group(1).strip())
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:160
âš ï¸ **INLINE_PROMPTS**: F-string prompts: # session_base_content = f'{framework_content}{doc_content_hash}{model}'...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:240
âš ï¸ **INLINE_PROMPTS**: F-string prompts: # session_id = f"ensemble_session_{hashlib.sha256(session_base_content.encode()).hexdigest()[:12]}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:241
âš ï¸ **INLINE_PROMPTS**: F-string prompts: #     batch_id = f"batch_{hashlib.sha256(f'{session_base_content}{ensemble_run}'.encode()).hexdigest...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:245
âš ï¸ **INLINE_PROMPTS**: F-string prompts: #     batch_id = f"batch_{hashlib.sha256(session_base_content.encode()).hexdigest()[:12]}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:247
âš ï¸ **INLINE_PROMPTS**: F-string prompts: batch_id = f"batch_{hashlib.sha256(f'{framework_content}{doc_content_hash}{model}'.encode()).hexdige...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:250
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: cached_result = json.loads(cached_content.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:275
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"ğŸ” No cache hit for {batch_id} - performing analysis...")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:307
âš ï¸ **INLINE_PROMPTS**: F-string prompts: "original_filename": doc.get('filename', f'doc_{i+1}'),...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:325
âš ï¸ **INLINE_PROMPTS**: F-string prompts: "original_filename": doc.get('filename', f'doc_{i+1}'),...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:333
âš ï¸ **INLINE_PROMPTS**: F-string prompts: frameworks=f"=== FRAMEWORK 1 (base64 encoded) ===\n{framework_b64}\n",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:354
âš ï¸ **INLINE_PROMPTS**: F-string prompts: #     print(f"    ğŸ”„ Using session-based caching: {session_id} (run {ensemble_run}/{total_ensemble_ru...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:387
âš ï¸ **INLINE_PROMPTS**: F-string prompts: #             print(f"    ğŸ’¾ Vertex AI cache hit: {cached_tokens} tokens reused")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:408
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"ğŸ’° Document analysis cost: ${response_cost:.6f} ({total_tokens:,} tokens)")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:457
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"âš ï¸ Error extracting cost information: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:460
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: "tokens_input": len(prompt_text.split()),
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:486
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: "tokens_output": len(result_content.split())
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:487
ğŸ”¸ **EXCESSIVE_PARSING**: Content parsing: "tokens_output": len(result_content.split())
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:487
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"âœ… Enhanced analysis complete: {batch_id} ({duration:.1f}s)")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:548
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise EnhancedAnalysisAgentError(f"Enhanced analysis failed: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:569
âš ï¸ **INLINE_PROMPTS**: F-string prompts: f"=== DOCUMENT {document['index']} (base64 encoded) ===\n"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:584
âš ï¸ **INLINE_PROMPTS**: F-string prompts: f"Filename: {document.get('filename', 'unknown')}\n"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/main.py:585
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: json_match = re.search(json_pattern, framework_content, re.DOTALL)
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/framework_parser.py:46
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: framework_config = json.loads(json_match.group(1))
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/framework_parser.py:51
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise ValueError(f"Invalid JSON in framework appendix: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/framework_parser.py:53
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"Warning: Dimension group '{group_name}' is not a list, skipping")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/framework_parser.py:64
ğŸ”¸ **COMPLEX_PARSING_METHODS**: Contains parse_* or extract_* methods
   ğŸ“ /Volumes/code/discernus/discernus/agents/EnhancedAnalysisAgent/framework_parser.py

### classification_agent
**Violations**: 3

âš ï¸ **MISSING_YAML**: No YAML prompt files found
   ğŸ“ /Volumes/code/discernus/discernus/agents/classification_agent
âš ï¸ **INLINE_PROMPTS**: F-string prompts: classifications[f"{metric_name}_classification"] = category...
   ğŸ“ /Volumes/code/discernus/discernus/agents/classification_agent/agent.py:44
âš ï¸ **INLINE_PROMPTS**: F-string prompts: classifications[f"{metric_name}_classification"] = "Unclassified"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/classification_agent/agent.py:48

### comprehensive_knowledge_curator
**Violations**: 24

âš ï¸ **MISSING_YAML**: No YAML prompt files found
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.local_artifact_storage import LocalArtifactStorage
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:41
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"ğŸ“š Loaded cached comprehensive knowledge index: {index_hash[:12]}...")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:166
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"âœ… Built comprehensive knowledge graph: {len(documents)} items across {len(request...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:233
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Comprehensive indexing failed: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:244
âš ï¸ **INLINE_PROMPTS**: F-string prompts: types_str = ", ".join(f"'{t}'" for t in query.content_types)...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:272
âš ï¸ **INLINE_PROMPTS**: F-string prompts: where_clauses.append(f"content_type IN ({types_str})")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:273
âš ï¸ **INLINE_PROMPTS**: F-string prompts: where_clauses.append(f"speaker = '{query.speaker_filter}'")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:275
âš ï¸ **INLINE_PROMPTS**: F-string prompts: where_clauses.append(f"document_id = '{query.document_filter}'")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:277
âš ï¸ **INLINE_PROMPTS**: F-string prompts: search_results = self.embeddings.search(f"select id, text, score, content_type, source_artifact, spe...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:282
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"ğŸ” Knowledge query '{query.semantic_query}' with filter '{where_sql}' â†’ {len(knowl...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:316
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Knowledge query failed: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:320
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: evidence_json = json.loads(evidence_data.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:327
âš ï¸ **INLINE_PROMPTS**: F-string prompts: searchable_text = f"Evidence from {doc_name} for {dimension}: {quote_text}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:337
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Failed to process evidence data: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:358
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: scores_json = json.loads(scores_data.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:364
âš ï¸ **INLINE_PROMPTS**: F-string prompts: searchable_text = f"Score for {dimension} in {document_name} by {speaker}: {value}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:381
âš ï¸ **INLINE_PROMPTS**: F-string prompts: 'confidence': record.get(f'{dimension}_confidence', 1.0),...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:393
âš ï¸ **INLINE_PROMPTS**: F-string prompts: 'salience': record.get(f'{dimension}_salience', 1.0)...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:394
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Failed to process scores data: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:402
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: metrics_json = json.loads(metrics_data.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:408
âš ï¸ **INLINE_PROMPTS**: F-string prompts: description = metric_data.get('description', f'Calculated metric: {metric_name}')...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:417
âš ï¸ **INLINE_PROMPTS**: F-string prompts: searchable_text = f"Calculated metric {metric_name}: {description} = {value}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:419
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Failed to process calculated metrics data: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/comprehensive_knowledge_curator/agent.py:438

### csv_export_agent
**Violations**: 17

âš ï¸ **MISSING_YAML**: No YAML prompt files found
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: framework's output structure.
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:8
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.audit_logger import AuditLogger
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:33
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: return json.loads(artifact_content.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:222
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise FileNotFoundError(f"Artifact not found: {artifact_hash}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:228
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: return json.loads(artifact_content.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:233
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise CSVExportError(f"Failed to load artifact {artifact_hash}: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:235
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"Generated {filename} with {len(document_analyses)} records")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:290
âš ï¸ **INLINE_PROMPTS**: F-string prompts: reasoning = f"Confidence: {confidence}, Context: {context_type}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:323
âš ï¸ **INLINE_PROMPTS**: F-string prompts: reasoning = f"Analysis reasoning for {dimension} score: {score}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:346
âš ï¸ **INLINE_PROMPTS**: F-string prompts: hash_content = f"{document_id}:{json.dumps(analysis_scores, sort_keys=True)}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:429
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Could not load statistical results: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:521
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Could not load curated evidence: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:527
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Final synthesis CSV export failed: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:585
âš ï¸ **INLINE_PROMPTS**: F-string prompts: f"Structure: {list(results.keys()) if isinstance(results, dict) else type(results)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:640
âš ï¸ **INLINE_PROMPTS**: F-string prompts: f"{test_name}_{var1}_{var2}", test_type, 'correlation_coefficient',...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:705
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"Generated statistical_results.csv with {len(results)} test results")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/csv_export_agent/agent.py:732

### evidence_indexer_agent
**Violations**: 7

âš ï¸ **MISSING_YAML**: No YAML prompt files found
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_indexer_agent
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: evidence_json = json.loads(request.evidence_data.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_indexer_agent/agent.py:38
âš ï¸ **INLINE_PROMPTS**: F-string prompts: "id": f"evd_{hashlib.sha1(str(evidence_item).encode()).hexdigest()[:10]}",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_indexer_agent/agent.py:50
âš ï¸ **INLINE_PROMPTS**: F-string prompts: "original_quote_hash": f"sha256:{hashlib.sha256(evidence_item.get('quote_text', '').encode()).hexdig...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_indexer_agent/agent.py:55
âš ï¸ **INLINE_PROMPTS**: F-string prompts: quotes_section += f"\nQuote {i+1}: \"{quote_text}\"\n"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_indexer_agent/agent.py:86
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: response_array = json.loads(response_content)
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_indexer_agent/agent.py:108
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Batch processing failed: {e}. Using fallback.")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_indexer_agent/agent.py:128

### evidence_quality_measurement
**Violations**: 28

âš ï¸ **MISSING_YAML**: No YAML prompt files found
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Evidence quality measurement failed: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:209
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: queries = [q.strip() for q in response.split('\n') if q.strip()]
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:239
ğŸ”¸ **EXCESSIVE_PARSING**: Response parsing: queries = [q.strip() for q in response.split('\n') if q.strip()]
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:239
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"LLM query generation failed: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:242
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Query failed for '{query}': {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:288
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Failed to get total evidence count: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:304
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: matches = re.findall(ref_pattern, synthesis_report)
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:322
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Claim query failed for '{result_key}': {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:370
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Synthesis claim query failed for '{claim}': {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:394
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: query_terms.extend(result_key.split('_'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:414
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: query_terms.extend(value.split()[:5])  # First 5 words
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:420
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: claims = [c.strip() for c in response.split('\n') if c.strip()]
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:448
ğŸ”¸ **EXCESSIVE_PARSING**: Response parsing: claims = [c.strip() for c in response.split('\n') if c.strip()]
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:448
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"LLM claim extraction failed: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:451
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: match = re.search(r'0\.\d+|1\.0', response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:482
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"LLM alignment assessment failed: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:487
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Alignment query failed for '{query}': {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:542
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Relevance query failed for '{query}': {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:611
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Quality query failed for '{query}': {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:674
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: if evidence_quote and any(word in claim_text for word in evidence_quote.split()[:5]):
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:711
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Evidence is not a list: {type(evidence)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:731
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Invalid evidence object {i}: {type(ev)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:744
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: citations = re.findall(citation_pattern, synthesis_report)
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:1012
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: has_evidence_section = bool(re.search(evidence_section_pattern, synthesis_report))
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:1014
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: inline_citations = re.findall(r'\[(\d+)\]', synthesis_report)
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:1062
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: evidence_section_match = re.search(r'## Evidence References\s*\n(.*?)(?=\n##|\Z)', synthesis_report, re.DOTALL)
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:1066
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: references = re.findall(r'\[(\d+)\]', evidence_section)
   ğŸ“ /Volumes/code/discernus/discernus/agents/evidence_quality_measurement/agent.py:1074

### experiment_coherence_agent
**Violations**: 19

ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.audit_logger import AuditLogger
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:21
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise FileNotFoundError(f"Prompt file not found: {prompt_path}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:96
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise ValueError(f"Prompt file missing 'template' key: {prompt_path}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:104
âš ï¸ **INLINE_PROMPTS**: F-string prompts: description=f"Failed to load experiment artifacts: {str(e)}",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:232
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise FileNotFoundError(f"experiment.md not found in {experiment_path}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:243
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: parts = content.split('---', 2)
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:250
ğŸ”¸ **EXCESSIVE_PARSING**: Content parsing: parts = content.split('---', 2)
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:250
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise FileNotFoundError(f"Framework file not found: {framework_file}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:262
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise FileNotFoundError(f"corpus.md not found in {corpus_path}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:273
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: return json.loads(json_content)
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:284
âš ï¸ **INLINE_PROMPTS**: F-string prompts: description=f"Insufficient corpus size: {corpus_size} documents",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:311
âš ï¸ **INLINE_PROMPTS**: F-string prompts: fix=f"Add {3 - corpus_size} more documents to corpus directory",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:313
âš ï¸ **INLINE_PROMPTS**: F-string prompts: description=f"Minimal corpus size: {corpus_size} documents",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:320
âš ï¸ **INLINE_PROMPTS**: F-string prompts: description=f"Complex framework ({dimension_count} dimension indicators) with small corpus ({corpus_...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:342
âš ï¸ **INLINE_PROMPTS**: F-string prompts: description=f"Could not analyze framework complexity: {str(e)}",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:351
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: data = json.loads(json_content)
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:380
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: data = json.loads(response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:382
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: data = json.loads(response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:384
âš ï¸ **INLINE_PROMPTS**: F-string prompts: description=f"Failed to parse validation response: {str(e)}",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/experiment_coherence_agent/agent.py:410

### intelligent_extractor_agent
**Violations**: 18

ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.audit_logger import AuditLogger
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:32
âš ï¸ **INLINE_PROMPTS**: F-string prompts: error_message=f"Unsupported gasket_schema version: {gasket_schema.get('version')}. Supported version...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:160
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Extraction attempt {attempt} failed: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:236
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: Load external YAML prompt template following THIN architecture.
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:269
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise FileNotFoundError(f"Prompt file not found: {prompt_path}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:279
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise ValueError(f"Prompt file missing 'template' key: {prompt_path}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:287
âš ï¸ **INLINE_PROMPTS**: F-string prompts: keys_text = "\n".join(f"- {key}" for key in target_keys)...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:310
âš ï¸ **INLINE_PROMPTS**: F-string prompts: pattern_hints.append(f"- {key}: Look for patterns like '{patterns[0]}'")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:317
âš ï¸ **INLINE_PROMPTS**: F-string prompts: example_json_content = ",\n      ".join(f'"{k}": {v}' for k, v in example_mapping.items())...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:324
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: parsed_data = json.loads(cleaned_response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:360
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Invalid score for {key} in {document_name}: {value} (must be {min_score}-{max_...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:393
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Invalid score type for {key} in {document_name}: {value} (must be numeric)")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:395
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Failed to parse extraction response as JSON: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:405
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Response was: {response[:200]}...")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:406
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise IntelligentExtractorError(f"Invalid JSON response from LLM: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:407
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Unexpected error parsing extraction response: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:410
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise IntelligentExtractorError(f"Failed to parse extraction response: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py:411
ğŸ”¸ **COMPLEX_PARSING_METHODS**: Contains parse_* or extract_* methods
   ğŸ“ /Volumes/code/discernus/discernus/agents/intelligent_extractor_agent/agent.py

### reliability_analysis_agent
**Violations**: 15

ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.audit_logger import AuditLogger
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:21
âš ï¸ **INLINE_PROMPTS**: F-string prompts: print(f"Warning: Failed to load prompts for {self.agent_name}: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:101
âš ï¸ **INLINE_PROMPTS**: F-string prompts: error_msg = f"Framework dimension validation failed: {str(e)}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:179
âš ï¸ **INLINE_PROMPTS**: F-string prompts: error_msg = f"Statistical health validation failed: {str(e)}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:266
âš ï¸ **INLINE_PROMPTS**: F-string prompts: error_msg = f"Pipeline health assessment failed: {str(e)}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:359
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: json_match = re.search(r'\{.*\}', response, re.DOTALL)
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:381
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: result_data = json.loads(json_match.group(0))
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:383
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: result_data = json.loads(response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:385
âš ï¸ **INLINE_PROMPTS**: F-string prompts: impact_assessment=f"Failed to parse validation response: {str(e)}",...
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:403
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: json_match = re.search(r'\{.*\}', response, re.DOTALL)
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:413
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: result_data = json.loads(json_match.group(0))
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:415
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: result_data = json.loads(response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:417
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: json_match = re.search(r'\{.*\}', response, re.DOTALL)
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:445
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: result_data = json.loads(json_match.group(0))
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:447
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: result_data = json.loads(response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/reliability_analysis_agent/agent.py:449

### score_grounding
**Violations**: 18

ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: Provides automatic grounding evidence generation for every numerical score.
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/__init__.py:5
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.audit_logger import AuditLogger
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:29
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: from discernus.core.evidence_confidence_calibrator import EvidenceConfidenceCalibrator, ConfidenceCalibrationRequest
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:30
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise ValueError(f"Prompt file missing 'template' key: {prompt_path}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:127
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"LLM returned empty response for grounding evidence. Reason: {reason}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:203
âš ï¸ **INLINE_PROMPTS**: F-string prompts: raise ValueError(f"LLM returned empty response. Reason: {reason}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:204
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: grounding_data = json.loads(json_content)
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:271
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: grounding_data = json.loads(response_content)
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:273
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: grounding_data = json.loads(response_content)
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:275
âš ï¸ **INLINE_PROMPTS**: F-string prompts: logging.error(f"Failed to parse grounding response: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:303
âš ï¸ **INLINE_PROMPTS**: F-string prompts: content = f"{document_name}:{dimension}:{evidence_text}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:309
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Missing calibration for evidence {i}, using original confidence")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:333
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Batch calibration failed: {reason}. Using fallback individual calibration.")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:392
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: calibrations = json.loads(response_content)
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:397
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Batch calibration returned {len(calibrations) if isinstance(calibrations, list...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:399
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"Batch calibration successful: processed {len(calibrations)} evidence pieces in 1 ...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:402
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Batch calibration JSON parsing failed: {str(e)}. Using fallback.")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:406
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Batch calibration failed: {str(e)}. Using fallback individual calibration.")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/score_grounding/grounding_evidence_generator.py:410

### sequential_synthesis
**Violations**: 7

âš ï¸ **MISSING_YAML**: No YAML prompt files found
   ğŸ“ /Volumes/code/discernus/discernus/agents/sequential_synthesis
ğŸ”¸ **EXCESSIVE_PARSING**: Regex parsing: Implements the THIN, framework-agnostic, sequential synthesis architecture.
   ğŸ“ /Volumes/code/discernus/discernus/agents/sequential_synthesis/agent.py:5
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Sequential synthesis pipeline failed: {e}", exc_info=True)...
   ğŸ“ /Volumes/code/discernus/discernus/agents/sequential_synthesis/agent.py:96
ğŸ”¸ **EXCESSIVE_PARSING**: String splitting: llm_response = llm_response.split("```json")[1].split("```")[0]
   ğŸ“ /Volumes/code/discernus/discernus/agents/sequential_synthesis/agent.py:155
ğŸ”¸ **EXCESSIVE_PARSING**: Response parsing: llm_response = llm_response.split("```json")[1].split("```")[0]
   ğŸ“ /Volumes/code/discernus/discernus/agents/sequential_synthesis/agent.py:155
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: return json.loads(llm_response)
   ğŸ“ /Volumes/code/discernus/discernus/agents/sequential_synthesis/agent.py:156
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Failed to parse JSON list from LLM response: {llm_response}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/sequential_synthesis/agent.py:158

### txtai_evidence_curator
**Violations**: 31

âš ï¸ **MISSING_YAML**: No YAML prompt files found
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Skipping task '{task_name}' - no provenance information")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:142
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Skipping task '{task_name}' - mathematical operation, needs transparency not evi...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:149
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"Evidence linking applied to {len(valid_tasks)}/{len(all_results)} tasks (Epic 280...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:151
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"txtai evidence curation failed: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:167
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"Task '{task_name}' (type: {task_type}) defaulting to evidence linking")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:229
ğŸ”¸ **EXCESSIVE_PARSING**: JSON parsing: evidence_json = json.loads(evidence_data.decode('utf-8'))
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:244
âš ï¸ **INLINE_PROMPTS**: F-string prompts: search_text = f"{evidence.get('document_name', '')} {evidence.get('dimension', '')} evidence: {evide...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:258
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"Built txtai index with {len(documents)} evidence pieces")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:279
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"Sample doc {i}: {doc.get('document_name', 'N/A')} - {doc.get('dimension', 'N/A')}...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:284
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Failed to build evidence index: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:289
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"No dimensional scores found for task '{task_name}'")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:324
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.info(f"Batch evidence synthesis successful: processed {len(valid_tasks)} tasks in 1 LLM ...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:355
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Batch synthesis failed: {reason}. Using fallback individual processing.")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:359
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Batch evidence synthesis failed: {str(e)}. Using fallback individual processing....
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:363
âš ï¸ **INLINE_PROMPTS**: F-string prompts: f"  - Document: {ev.document_name}, Dimension: {ev.dimension}, Quote: \"{ev.quote_text}\", Confidenc...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:379
âš ï¸ **INLINE_PROMPTS**: F-string prompts: finding_summary = f"Type: {finding_type}, Results: {json.dumps(task_result.get('results', {}), inden...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:385
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.debug(f"No dimensional scores found for task '{task_name}'")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:456
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"No evidence found for task '{task_name}' - checked {len(input_document_ids)} d...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:472
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Documents: {input_document_ids}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:473
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Dimensions: {relevant_dimensions}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:474
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Failed to generate narrative for task '{task_name}': {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:483
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Unknown txtai result format: {type(result)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:534
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Failed to retrieve document for result {result}: {e}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:538
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Evidence query failed: {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:562
âš ï¸ **INLINE_PROMPTS**: F-string prompts: f"Document: {ev.document_name}\nDimension: {ev.dimension}\nQuote: \"{ev.quote_text}\"\nConfidence: {...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:585
âš ï¸ **INLINE_PROMPTS**: F-string prompts: finding_summary = f"Task: {task_name}\nType: {finding_type}\nResults: {json.dumps(task_result.get('r...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:591
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.warning(f"Empty synthesis for task '{task_name}'. Reason: {reason}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:626
âš ï¸ **INLINE_PROMPTS**: F-string prompts: return f"// No synthesis generated for {task_name}. Reason: {reason}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:627
âš ï¸ **INLINE_PROMPTS**: F-string prompts: self.logger.error(f"Evidence synthesis failed for task '{task_name}': {str(e)}")...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:630
âš ï¸ **INLINE_PROMPTS**: F-string prompts: return f"// Error during synthesis for {task_name}: {str(e)}"...
   ğŸ“ /Volumes/code/discernus/discernus/agents/txtai_evidence_curator/agent.py:631

## Redundant Agent Analysis

### Evidence System
**Issue**: Multiple evidence agents
**Agents**: evidence_quality_measurement, txtai_evidence_curator, evidence_indexer_agent
