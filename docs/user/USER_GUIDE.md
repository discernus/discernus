# Discernus User Guide

Welcome to the Discernus User Guide. This document provides a detailed walkthrough of how to use the platform, from setting up your first experiment to understanding the output artifacts.

## Table of Contents

1.  [Installation](#installation)
2.  [Core Concepts](#core-concepts)
3.  [Running Your First Experiment](#running-your-first-experiment)
4.  [Understanding the Output](#understanding-the-output)
5.  [Advanced Usage](#advanced-usage)
6.  [Troubleshooting](#troubleshooting)

---

## 1. Installation

This section provides more detailed installation and setup instructions.

### Prerequisites

*   Python 3.13 or higher
*   Git
*   An API key for a supported LLM (currently Google Gemini)

### Step-by-Step Guide

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/your-repo/discernus.git
    cd discernus
    ```

2.  **Install Dependencies**
    The `make install` command sets up a virtual environment and installs all required Python packages from `requirements.txt`.
    ```bash
    make install
    ```

3.  **Configure Environment Variables**
    Discernus uses a `.env` file to manage API keys and other secrets.
    ```bash
    cp env.template .env
    ```
    Now, open the `.env` file and add your Google Gemini API key.

4.  **Verify Your Installation**
    Run the `make check` command to ensure that your environment is correctly configured and all necessary tools are available.
    ```bash
    make check
    ```
    If the check passes, you are ready to run experiments.

---

## 2. Core Concepts

Discernus is organized around three core concepts: **Frameworks**, **Corpora**, and **Experiments**.

*   **Frameworks**: These are the analytical lenses you want to apply to your texts. A framework is defined in a YAML file and specifies the dimensions, metrics, and scoring rubrics for your analysis. You can find examples in the `frameworks/` directory.
*   **Corpora**: This is the collection of text documents you want to analyze. Each corpus needs a `corpus_manifest.yaml` that lists the documents to be included. Examples are in the `corpus/` directory.
*   **Experiments**: An experiment brings together a framework and a corpus. It is defined by an `experiment.md` file that specifies the research questions, hypotheses, and the paths to the framework and corpus to be used. All experiments are located in the `projects/` directory.

---

## 3. Running Your First Experiment

The easiest way to get started is to run the `nano` experiment.

### Using the CLI

The `discernus` CLI is the primary way to interact with the system.

1.  **Navigate to the project root.**

2.  **Run the experiment:**
    ```bash
    discernus run projects/nano
    ```
    This command will:
    *   Validate the experiment, framework, and corpus specifications.
    *   Run the 5-phase pipeline (Validation, Analysis, Statistical, Evidence, Synthesis).
    *   Generate all output artifacts in a new directory under `projects/nano/runs/`.

3.  **Skip Validation for Faster Iteration**
    During development, you can use the `--skip-validation` flag to save time.
    ```bash
    discernus run projects/nano --skip-validation
    ```

---

## 4. Understanding the Output

After an experiment run completes, a new directory is created (e.g., `projects/nano/runs/20250924_120000/`). This directory contains:

*   **`artifacts/`**: The raw data generated by each phase of the pipeline.
    *   **`final_synthesis_report_*.md`**: The main research report with findings and analysis.
    *   **`statistical_analysis_*.json`**: Statistical analysis results and derived metrics.
    *   **`curated_evidence_*.json`**: Supporting evidence and quotes for the analysis.
    *   **`score_extraction_*.json`**: Dimensional scores for each document.
    *   **`marked_up_document_*.md`**: Documents with highlighted evidence.
    *   **`artifact_registry.json`**: Complete provenance registry for all artifacts.
*   **`logs/`**: Execution logs for debugging and provenance.
    *   **`agents.jsonl`**: Agent execution details and decisions.
    *   **`llm_interactions.jsonl`**: LLM interaction logs.
    *   **`system.jsonl`**: System events and operations.
*   **`README.md`**: A summary of the experiment run, including the configuration and key results.

The most important output is the final synthesis report, typically found in `artifacts/final_synthesis_report_*.md`.

### Exporting Data for Analysis

For researchers who need to perform additional statistical analysis or data manipulation, Discernus provides a CSV export feature that extracts structured data from the analysis artifacts.

```bash
# Export experiment data to CSV
discernus export-csv projects/your_experiment

# Export to custom file
discernus export-csv projects/your_experiment --output my_analysis.csv
```

**CSV Output Contains:**
- **Raw scores**: Dimension scores, salience, and confidence for each document
- **Derived metrics**: Calculated metrics (e.g., tension indices, cohesion components)
- **Evidence quotes**: Supporting text evidence for each dimension
- **Document tracking**: Document identifiers for data provenance

This CSV format allows you to:
- Import data into statistical software (R, Python, SPSS)
- Perform custom statistical analysis
- Create visualizations and charts
- Share structured data with collaborators

---

## 5. Advanced Usage

### Phase-Specific Runs

You can run specific phases of the pipeline for faster iteration or debugging.

```bash
# Run only analysis and statistical phases
discernus run projects/your_experiment --from analysis --to statistical

# Run only evidence and synthesis phases
discernus run projects/your_experiment --from evidence --to synthesis

# Run only validation phase
discernus run projects/your_experiment --from validation --to validation
```

This allows you to:
*   **Iterate quickly** on analysis without running expensive synthesis
*   **Debug specific phases** by running them in isolation
*   **Resume from cached results** when continuing from a specific phase

### Resume Functionality (v2.1 Enhanced)

Discernus v2.1 significantly improves resume functionality with robust artifact discovery and enhanced reliability. Resume is now production-ready for long-running experiments.

**Key Features:**
- ✅ **Robust Artifact Discovery**: Automatically detects artifacts from partially completed phases
- ✅ **Cross-Run Support**: Resume from any previous run, not just the most recent
- ✅ **Provenance Tracking**: Full lineage tracking across all resume operations
- ✅ **Smart Phase Detection**: Automatically identifies which phases can be resumed
- ✅ **Production Ready**: Extensively tested and reliable

**Automatic Resume:**
```bash
# Resume from the most recent run with completed phases
discernus run projects/your_experiment --resume --from statistical
```

**Specific Run Resume:**
```bash
# Resume from a specific run directory
discernus run projects/your_experiment --run-dir 20250926_045818 --from evidence
```

**How Resume Works:**

When you resume an experiment, Discernus:
1. **Identifies the source run** - Either automatically (most recent) or specified with `--run-dir`
2. **Copies completed phases** - All artifacts from completed phases are copied to the new run
3. **Discovers partial artifacts** - Artifacts from partially completed phases are automatically discovered and copied
4. **Merges artifact registries** - Registry entries are merged to ensure all artifacts are discoverable
5. **Tracks provenance** - Full lineage tracking in `provenance.json`
6. **Continues execution** - Starts from the specified phase using the copied artifacts

**Resume Use Cases:**
*   **Development Iteration**: Modify statistical analysis without re-running expensive analysis phase
*   **Debugging**: Test synthesis changes without re-running statistical phase
*   **Cost Optimization**: Resume from analysis phase after interruption
*   **Data Integrity**: All resume operations maintain complete audit trail
*   **Interrupted Experiments**: Automatically resume from where the experiment was interrupted

**Resume Provenance:**
All resume operations are tracked for audit and reproducibility:
```bash
# View resume provenance information
discernus artifacts projects/your_experiment --show-resume
```

This shows which runs were resumed, from which source runs, and when the resume operations occurred.

### Listing Experiments

To see all available experiments, use the `list` command:
```bash
discernus list
```

### Validating an Experiment

To validate an experiment's structure without running it, use the `validate` command:
```bash
discernus validate projects/your_experiment
```

### Checking Artifacts and Costs

To see experiment artifacts and cost breakdowns:
```bash
# Show artifacts and cache status
discernus artifacts projects/your_experiment

# Show cost breakdown
discernus costs projects/your_experiment --detailed
```

### System Status

To check system status and component availability:
```bash
discernus status
```

---

## 6. Troubleshooting

### Common Issues

*   **Authentication Errors**: Ensure your Google Cloud credentials are correctly configured:
    ```bash
    gcloud auth application-default login
    ```

*   **Validation Errors**: Check the error messages. They usually point to a specific issue in one of your specification files (framework, corpus, or experiment).

*   **Slow Runs**: The analysis phase can be time-consuming for large corpora. Consider using phase-specific runs for faster iteration:
    ```bash
    discernus run projects/your_experiment --from analysis --to statistical
    ```

*   **Command Not Found**: Make sure you're in the project directory or install globally:
    ```bash
    pip install -e .
    ```

### Getting Help

*   **System Status**: Check system components with `discernus status`
*   **Artifacts**: Review experiment artifacts with `discernus artifacts`
*   **Costs**: Check cost breakdown with `discernus costs --detailed`
*   **Logs**: Review execution logs in `runs/*/logs/` directories

For more detailed help, please open an issue on our GitHub repository.
