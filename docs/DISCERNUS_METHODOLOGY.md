# Discernus Methodology: Research Framework for Computational Text Analysis

**Version**: 1.0
**Status**: Active Standard
**Date**: September 2025

---

## Abstract

This document describes the research methodology and analytical framework implemented by the Discernus platform for systematic text analysis. The methodology consists of a five-phase research pipeline: (1) validation of research specifications, (2) framework-based dimensional analysis, (3) statistical analysis with computational verification, (4) evidence curation and fact-checking, and (5) evidence-integrated synthesis. The approach uses large language models for analytical reasoning while maintaining computational verification of all mathematical operations and complete provenance tracking for reproducibility.

---

## 1. Research Framework

### 1.1 Methodological Principles

The Discernus methodology implements a THIN research architecture where:

- **Language Model Intelligence**: Complex analytical reasoning, framework interpretation, and dimensional scoring are handled by large language models
- **Software Infrastructure**: Minimal orchestration, caching, and data management with no embedded analytical logic
- **Research Integrity**: All mathematical operations must be executed as code with full computational provenance
- **Academic Standards**: Outputs meet peer-review standards with complete methodology documentation

### 1.2 Input Specifications

The methodology requires three specification documents:

**Framework Specification (v10.0)**:

- Natural language description of analytical dimensions
- Scoring criteria and examples for each dimension
- Academic grounding and references
- Machine-readable YAML appendix with dimensional definitions

**Experiment Specification (v10.0)**:

- Research questions and hypotheses
- Statistical analysis plan
- Expected outcomes and deliverables
- Machine-readable YAML appendix with configuration

**Corpus Specification (v8.0.2)**:

- Document manifest with metadata
- File organization and structure
- Speaker attribution and context information
- Machine-readable YAML appendix with document listings

### 1.3 Validation Requirements

**Pre-execution Validation**:

- Specification compliance checking against Discernus standards
- Statistical prerequisites validation (sample size, group balance)
- Framework-corpus coherence assessment
- Issue classification (BLOCKING, QUALITY, SUGGESTION)

**Runtime Validation**:

- Mathematical verification through code execution
- Evidence quality assessment and confidence scoring
- Statistical methodology compliance
- Error handling and fail-fast behavior

**Post-execution Validation**:

- Provenance verification and audit trail completeness
- Output quality assessment against academic standards
- Reproducibility verification
- Peer review readiness evaluation

---

## 2. Processing Pipeline

### 2.1 Research Pipeline Overview

The methodology implements a five-phase research pipeline:

```
Validation → Analysis → Statistical → Evidence → Synthesis
     ↓           ↓           ↓           ↓           ↓
Specification  Framework   Mathematical  Evidence   Academic
Validation     Analysis    Analysis     Curation   Reports
```

Each phase produces specific research artifacts and maintains complete provenance tracking.

### 2.2 Phase 1: Validation

**Objective**: Validate research specifications and experimental design.

**Research Procedure**:

1. **Specification Validation**:
   - Validate framework specification against v10.0 standard
   - Validate experiment specification against v10.0 standard
   - Validate corpus specification against v8.0.2 standard
   - Check file existence and accessibility

2. **Statistical Prerequisites**:
   - Verify minimum sample size requirements
   - Validate group balance for comparative analysis
   - Check statistical power considerations
   - Assess framework-corpus coherence

3. **Issue Classification**:
   - **BLOCKING**: Prevents execution, must be resolved
   - **QUALITY**: Impacts result quality, should be addressed
   - **SUGGESTION**: Optimization opportunity, optional

**Output Artifacts**:
- Validation report with issues and recommendations
- Specification compliance documentation
- Statistical prerequisites assessment

### 2.3 Phase 2: Analysis

**Objective**: Apply analytical framework to corpus documents with computational verification.

**Research Procedure**:

1. **Framework Application**:
   - Parse framework specification and dimensional definitions
   - Apply dimensional scoring criteria to each document
   - Generate confidence and salience scores for each dimension

2. **Internal Ensemble Analysis**:
   - Execute three independent analytical approaches per document:
     - Evidence-First: Direct textual evidence and explicit statements
     - Context-Weighted: Rhetorical context and structural positioning
     - Pattern-Based: Repetition patterns and strategic emphasis
   - Calculate median scores across approaches for self-consistency

3. **Evidence Extraction**:
   - Extract supporting textual evidence for each dimensional score
   - Link evidence quotes to specific dimensions and confidence levels
   - Validate evidence quality and relevance

4. **Document Markup**:
   - Generate marked-up version of original text with dimensional annotations
   - Insert evidence markers and dimensional tags throughout document
   - Preserve original formatting while adding analytical markup

**Output Artifacts**:
- Dimensional scores (JSON format)
- Evidence database (JSON format)
- Marked-up document (Markdown format with dimensional annotations)
- Analysis audit trail (structured logs)

### 2.4 Phase 3: Statistical Analysis

**Objective**: Perform statistical analysis with computational verification.

**Research Procedure**:

1. **Statistical Planning**:
   - Generate statistical analysis plan based on experiment hypotheses
   - Identify appropriate statistical tests and methodologies
   - Plan effect size calculations and confidence intervals
   - Design multiple comparison correction strategies

2. **Statistical Execution**:
   - Execute hypothesis testing using appropriate methods
   - Calculate effect sizes and confidence intervals
   - Apply multiple comparison corrections where needed
   - Generate statistical visualizations and summaries

3. **Statistical Verification**:
   - Verify statistical calculations through independent code execution
   - Validate statistical assumptions and methodology compliance
   - Check for computational errors and edge cases
   - Confirm reproducibility of statistical results

**Output Artifacts**:
- Statistical analysis results (JSON format)
- Statistical verification artifacts (Python code)
- Statistical audit trail (structured logs)

### 2.5 Phase 4: Evidence Curation

**Objective**: Retrieve and validate evidence for synthesis.

**Research Procedure**:

1. **Evidence Retrieval**:
   - Retrieve supporting evidence for statistical findings
   - Validate evidence attribution and source accuracy
   - Organize evidence by statistical significance and relevance

2. **Evidence Quality Assessment**:
   - Assess evidence relevance and confidence
   - Validate evidence attribution and source accuracy
   - Check evidence-dimensional linkage
   - Verify evidence quality thresholds

**Output Artifacts**:
- Curated evidence database (JSON format)
- Evidence quality assessment (structured logs)
- Evidence audit trail (structured logs)

### 2.6 Phase 5: Synthesis

**Objective**: Generate evidence-integrated narrative synthesis.

**Research Procedure**:

1. **Narrative Synthesis**:
   - Generate comprehensive research report using statistical results
   - Integrate evidence quotes with proper attribution
   - Apply academic formatting and methodology documentation
   - Include limitations and methodological considerations

2. **Publication Preparation**:
   - Format research report for academic publication
   - Include complete methodology and limitations sections
   - Generate executive summary and key findings
   - Prepare supplementary materials and data files

**Output Artifacts**:
- Publication-ready research report (Markdown format)
- Synthesis audit trail (structured logs)
- Complete provenance documentation (structured format)

---

## 3. Research Quality Assurance

### 3.1 Pre-Execution Validation

**Specification Compliance**:
- Validate framework specification against v10.0 standard
- Validate experiment specification against v10.0 standard
- Validate corpus specification against v8.0.2 standard
- Check file existence and accessibility

**Statistical Prerequisites**:
- Verify minimum sample size requirements
- Validate group balance for comparative analysis
- Check statistical power considerations
- Assess framework-corpus coherence

**Issue Classification**:
- **BLOCKING**: Prevents execution, must be resolved
- **QUALITY**: Impacts result quality, should be addressed
- **SUGGESTION**: Optimization opportunity, optional

### 3.2 Runtime Validation

**Mathematical Verification**:
- Execute all calculations as executable code
- Validate computational work artifacts
- Verify score calculations and derived metrics
- Check statistical methodology compliance

**Evidence Quality**:
- Assess evidence relevance and confidence
- Validate evidence attribution and source accuracy
- Check evidence-dimensional linkage
- Verify evidence quality thresholds

**Error Handling**:
- Implement fail-fast behavior for critical errors
- Log all errors with complete context
- Provide detailed error reporting and recovery guidance
- Maintain system stability during processing

### 3.3 Post-Execution Validation

**Provenance Verification**:
- Validate complete audit trail integrity
- Check artifact completeness and accessibility
- Verify Git integration and version control
- Confirm reproducibility package completeness

**Output Quality**:
- Assess academic standards compliance
- Validate statistical methodology and reporting
- Check evidence integration and citation quality
- Verify publication readiness

**Reproducibility Testing**:
- Validate complete experiment replication capability
- Test artifact integrity and accessibility
- Verify specification compliance and execution
- Confirm output consistency and quality

---

## 4. Statistical Methodology

### 4.1 Analysis Procedures

**Dimensional Scoring**:
- Apply framework dimensions to each document
- Generate confidence and salience scores
- Execute internal ensemble analysis (3-run median)
- Validate score calculations through code execution

**Statistical Planning**:
- Generate statistical analysis plan based on experiment hypotheses
- Identify appropriate statistical tests and methodologies
- Plan effect size calculations and confidence intervals
- Design multiple comparison correction strategies

**Statistical Execution**:
- Execute hypothesis testing using appropriate methods
- Calculate effect sizes and confidence intervals
- Apply multiple comparison corrections where needed
- Generate statistical visualizations and summaries

**Statistical Verification**:
- Verify statistical calculations through independent code execution
- Validate statistical assumptions and methodology compliance
- Check for computational errors and edge cases
- Confirm reproducibility of statistical results

**Evidence Integration**:
- Link statistical findings to textual evidence
- Validate evidence attribution and source accuracy
- Organize evidence by statistical significance
- Ensure proper citation and attribution standards

### 4.2 Computational Verification

**Code Execution**:
- All mathematical operations executed as Python code
- Statistical calculations verified through computational execution
- Generated code includes full provenance and documentation
- Results validated against expected statistical properties

**Quality Control**:
- Implement confidence scoring for all calculations
- Validate statistical assumptions and methodology
- Check for computational errors and edge cases
- Ensure reproducibility and consistency

---

## 5. Output Specifications

### 5.1 Data Formats

**Dimensional Scores**: JSON format with document-level scores, confidence, and metadata
**Evidence Database**: JSON format with quotes, attribution, and dimensional linkage
**Marked-up Documents**: Markdown format with dimensional annotations and evidence markers
**Statistical Results**: JSON format with test results, effect sizes, and methodology
**Research Report**: Markdown format with academic structure and formatting

### 5.2 Provenance Documentation

**Audit Trails**: Structured logs of all processing steps and decisions
**Artifact Tracking**: Complete inventory of all inputs, outputs, and intermediate files
**Version Control**: Git-based tracking of all changes and modifications
**Reproducibility Package**: Complete experiment package for replication

### 5.3 Publication Standards

**Academic Formatting**: Proper methodology, results, and discussion sections
**Evidence Integration**: All claims supported by textual evidence and statistical results
**Methodology Documentation**: Complete description of analytical procedures
**Limitations and Considerations**: Transparent reporting of methodological constraints

---

## 6. Research Requirements

### 6.1 Input Requirements

**Framework Specification**: Natural language description of analytical dimensions with scoring criteria
**Experiment Specification**: Research questions, hypotheses, and statistical analysis plan
**Corpus Specification**: Document manifest with metadata and organizational structure

### 6.2 Quality Requirements

**Pre-execution Validation**: Validate all specifications and prerequisites
**Runtime Monitoring**: Monitor processing progress and error conditions
**Post-execution Verification**: Validate outputs and provenance completeness
**Academic Standards**: Ensure peer-review readiness and reproducibility

### 6.3 Output Requirements

**Research Report**: Publication-ready academic report with complete methodology
**Data Exports**: CSV format for external statistical software replication
**Provenance Documentation**: Complete audit trail and reproducibility package
**Evidence Integration**: All claims supported by textual evidence and statistical results

---

*This methodology document describes the research framework and analytical procedures implemented by the Discernus platform for systematic text analysis. For technical implementation details, see the [System Architecture documentation](architecture/DISCERNUS_SYSTEM_ARCHITECTURE.md). For usage instructions, see the [User Guide](user/USER_GUIDE.md) and [CLI Reference](user/CLI_REFERENCE.md).*
