# Batch Processing Regression Remediation Plan

## üö® Issue Summary

**Critical Regression**: The `CleanAnalysisOrchestrator` was rebuilt from scratch but lost the individual document processing pattern, defaulting to batch processing. This breaks multiple architectural assumptions and creates scalability issues.

## üîç Root Cause Analysis

### What Went Wrong
1. **Architecture Change**: New `CleanAnalysisOrchestrator` calls `analyze_batch()` with ALL documents at once
2. **Lost Pattern**: Working `ExperimentOrchestrator` calls `analyze_batch()` with single document in a loop
3. **Immediate Failure**: Path bug in statistical analysis (`/artifacts/artifacts` vs `/artifacts`)

### Evidence
- **PDAF Test**: Single analysis file with 4 documents (`num_documents: 4`)
- **CFF Test**: Mix of individual (48 files) and batch (38 files) - shows inconsistent behavior over time
- **Working Pattern**: `ExperimentOrchestrator` and deprecated `ThinOrchestrator` both use individual processing

## üéØ Impact Assessment

### 1. Analysis Stage
- ‚úÖ **Functional**: Batch processing works for small document sets
- ‚ùå **Scalability**: Cannot handle thousands of documents (context window limits)
- ‚ùå **Caching**: Loss of document-level content-addressable caching
- ‚ùå **Granularity**: Cannot re-analyze individual documents independently

### 2. Statistical Analysis Stage
- ‚ùå **Path Bug**: `artifacts_dir = self.experiment_path / "shared_cache" / "artifacts" / "artifacts"`
- ‚ùå **Immediate Failure**: "No raw analysis response found in artifacts directory"
- ‚ùå **DataFrame Conversion**: Assumes `analysis_results[0]` contains batch data

### 3. Synthesis Stage
- ‚ùå **Asset Validation**: Expects individual artifact hashes for provenance
- ‚ùå **Evidence Linkage**: Bundled evidence harder to trace to specific documents
- ‚ùå **RAG Integration**: Synthesis expects granular document-evidence relationships

### 4. Architectural Principles
- ‚ùå **THIN Caching**: Content-addressable storage broken at document level
- ‚ùå **Resumption**: Cannot resume from partial analysis completion
- ‚ùå **Cost Efficiency**: Re-analyzes all documents when any one changes

## üìã Remediation Strategy

### Phase 1: Test-Driven Development Setup
**Goal**: Establish comprehensive test coverage before making changes
**Duration**: 1-2 hours
**Cost**: $0 (no API calls)

#### 1.1 Unit Test Analysis Phase
- Mock `EnhancedAnalysisAgent.analyze_batch()` 
- Test individual document processing loop
- Test artifact storage for each document
- Test error handling and partial failures
- **Output**: `test_clean_analysis_orchestrator.py`

#### 1.2 Unit Test Statistical Analysis
- Mock analysis results with proper structure
- Test DataFrame conversion with individual documents
- Test path resolution for artifact loading
- **Output**: `test_statistical_analysis_integration.py`

#### 1.3 Unit Test Synthesis Integration
- Mock individual artifact hashes
- Test synthesis asset validation
- Test evidence linkage preservation
- **Output**: `test_synthesis_integration.py`

### Phase 2: Implementation
**Goal**: Implement individual processing with minimal disruption
**Duration**: 2-3 hours
**Cost**: $0 (no API calls during implementation)

#### 2.1 Fix Path Bug (Quick Win)
```python
# BEFORE (broken)
artifacts_dir = self.experiment_path / "shared_cache" / "artifacts" / "artifacts"

# AFTER (fixed)  
artifacts_dir = self.experiment_path / "shared_cache" / "artifacts"
```

#### 2.2 Import Individual Processing Pattern
- Copy proven pattern from `ExperimentOrchestrator._run_analysis_phase()`
- Adapt to `CleanAnalysisOrchestrator` architecture
- Preserve existing artifact storage integration
- Maintain audit logging and security boundaries

#### 2.3 Update DataFrame Conversion Logic
- Handle list of individual analysis results instead of single batch
- Aggregate document analyses from multiple files
- Preserve document-level provenance

### Phase 3: Unit Testing
**Goal**: Verify implementation with comprehensive test coverage
**Duration**: 1 hour
**Cost**: $0 (mocked dependencies)

#### 3.1 Test Individual Document Processing
- Verify loop through documents
- Check individual `analyze_batch()` calls with single documents
- Validate artifact storage per document

#### 3.2 Test Statistical Analysis Integration
- Verify DataFrame aggregation from multiple analysis files
- Test path resolution fixes
- Check statistical function execution

#### 3.3 Test Error Handling
- Partial analysis failures
- Missing artifacts
- Malformed responses

### Phase 4: Integration Testing with Mocks
**Goal**: Test end-to-end pipeline without API costs
**Duration**: 1 hour
**Cost**: $0 (mocked LLM calls)

#### 4.1 Mock LLM Responses
- Create realistic analysis JSON responses
- Mock statistical function generation
- Mock synthesis responses

#### 4.2 Full Pipeline Test
- Run complete orchestrator with mocked dependencies
- Verify artifact creation and linkage
- Test synthesis asset validation

### Phase 5: Limited Live Testing
**Goal**: Validate fixes with minimal API costs
**Duration**: 30 minutes
**Cost**: ~$2-5 (small test cases)

#### 5.1 Single Document Test
- Create minimal test experiment with 1 document
- Verify individual processing works end-to-end
- Check artifact structure and caching

#### 5.2 Two Document Test
- Test with 2 documents to verify individual processing
- Check statistical analysis aggregation
- Verify synthesis integration

### Phase 6: Full Experiment Validation
**Goal**: Confirm fix with original PDAF test
**Duration**: 15 minutes
**Cost**: ~$3-8 (full PDAF experiment)

#### 6.1 Re-run PDAF Test
- Execute `simple_test_pdaf` experiment
- Verify individual analysis files created
- Check synthesis completion
- Validate statistical analysis success

## üéØ Success Criteria

### Immediate Success (Phase 1-2)
- [ ] Path bug fixed in statistical analysis
- [ ] Individual document processing loop implemented
- [ ] All unit tests pass

### Integration Success (Phase 3-4)
- [ ] Mock pipeline runs end-to-end successfully  
- [ ] Multiple individual analysis artifacts created
- [ ] DataFrame aggregation works correctly
- [ ] Synthesis asset validation passes

### Production Success (Phase 5-6)
- [ ] PDAF test creates 4 individual analysis files (`num_documents: 1` each)
- [ ] Statistical analysis completes successfully
- [ ] Synthesis stage runs without asset validation errors
- [ ] Caching works at document level

## üîß Implementation Details

### Key Code Changes Required

#### 1. CleanAnalysisOrchestrator._run_analysis_phase()
```python
# BEFORE (batch processing)
analysis_result = analysis_agent.analyze_batch(
    framework_content=framework_content,
    corpus_documents=prepared_documents,  # ALL DOCUMENTS
    experiment_config=experiment_config,
    model=analysis_model
)
return [analysis_result]

# AFTER (individual processing)  
results = []
for doc in prepared_documents:
    analysis_result = analysis_agent.analyze_batch(
        framework_content=framework_content,
        corpus_documents=[doc],  # SINGLE DOCUMENT
        experiment_config=experiment_config,
        model=analysis_model
    )
    # Store individual artifact
    artifact_hash = self.artifact_storage.put_artifact(...)
    results.append(artifact_hash)
return results
```

#### 2. Statistical Analysis Path Fix
```python
# BEFORE (broken path)
artifacts_dir = self.experiment_path / "shared_cache" / "artifacts" / "artifacts"

# AFTER (correct path)
artifacts_dir = self.experiment_path / "shared_cache" / "artifacts"
```

#### 3. DataFrame Conversion Update
```python
# BEFORE (assumes single batch result)
analysis_result = analysis_results[0]

# AFTER (aggregates individual results)
all_document_analyses = []
for analysis_result in analysis_results:
    # Extract document analyses from each individual result
    doc_analyses = self._extract_document_analyses(analysis_result)
    all_document_analyses.extend(doc_analyses)
```

## üìä Risk Assessment

### Low Risk Changes
- Path bug fix (one line change)
- Unit test development (no production impact)

### Medium Risk Changes  
- Individual processing loop (well-tested pattern)
- DataFrame aggregation logic (testable in isolation)

### High Risk Changes
- None (using proven patterns from working orchestrator)

## üéØ Rollback Plan

If issues arise:
1. **Immediate**: Use `--use-legacy-orchestrator` flag to revert to `ExperimentOrchestrator`
2. **Code Rollback**: Git revert to restore batch processing if needed
3. **Hybrid Approach**: Keep both patterns and add configuration flag

## üìù Testing Strategy Summary

1. **Unit Tests First** - No API costs, fast feedback
2. **Integration Tests with Mocks** - Verify architecture without costs  
3. **Minimal Live Testing** - Small experiments to validate
4. **Full Validation** - Original experiment as final confirmation

This approach minimizes costs while ensuring comprehensive validation of the fix.

## üéØ Expected Outcomes

### Performance Improvements
- **Scalability**: Can handle thousands of documents
- **Caching**: Document-level caching reduces re-analysis costs
- **Resumption**: Failed experiments can resume from partial completion

### Architectural Improvements  
- **Provenance**: Clear document-to-artifact relationships
- **Synthesis**: Proper asset validation and evidence linkage
- **THIN Compliance**: Restored content-addressable caching model

### Cost Improvements
- **Development**: Test-driven approach minimizes expensive debugging cycles
- **Production**: Document-level caching reduces redundant API calls
- **Maintenance**: Clear architecture easier to debug and extend

---

**Total Estimated Cost**: $5-15 in API calls (vs $50+ for trial-and-error debugging)
**Total Estimated Time**: 6-8 hours (vs days of unstructured debugging)
**Risk Level**: Low (using proven patterns with comprehensive testing)
