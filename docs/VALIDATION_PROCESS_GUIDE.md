# Validation Process Guide
## Ensuring Research Quality in Discernus

### Overview

Discernus includes an automated validation system that ensures your research meets high methodological standards before analysis begins. This guide explains how the validation process works and how to prepare your materials for successful validation.

---

## What Gets Validated

### 1. Framework Specifications
Your analytical framework (e.g., `framework.md`) is validated to ensure it:
- Clearly defines what it measures
- Provides specific scoring criteria
- Includes sufficient evidence requirements
- Maintains internal consistency

### 2. Experiment Designs
Your experiment specification (e.g., `experiment.md`) is validated to ensure it:
- Contains falsifiable hypotheses
- Specifies an adequate dataset
- Includes appropriate analysis plans
- Demonstrates framework-experiment alignment

---

## The Validation Process

### Step 1: Automated Quality Assessment
When you submit your research materials, Discernus uses AI validation agents to:
- Check completeness against established quality standards
- Identify missing or unclear elements
- Assess internal consistency and coherence
- Verify practical applicability

### Step 2: Interactive Feedback
If validation identifies issues, you'll receive:
- **Specific feedback** on what needs improvement
- **Clear guidance** on how to address gaps
- **Quality thresholds** that must be met
- **Helpful examples** of successful submissions

### Step 3: Approval and Execution
Once validation passes, you'll see:
- **Confirmation** that your research meets quality standards
- **Execution plan** showing exactly what will be analyzed
- **Cost and time estimates** for your analysis
- **Opportunity to approve** before analysis begins

---

## Preparing for Successful Validation

### Framework Preparation Checklist
- [ ] **Clear identity**: Framework name, version, and purpose
- [ ] **Defined dimensions**: 2-8 analytical dimensions with clear descriptions
- [ ] **Scoring methodology**: Specific scales and interpretation guidelines
- [ ] **Evidence requirements**: What constitutes evidence for each score
- [ ] **Coherent structure**: Consistent terminology and logic throughout

### Experiment Preparation Checklist
- [ ] **Research foundation**: Clear question, literature context, theoretical justification
- [ ] **Testable hypotheses**: Specific, falsifiable predictions
- [ ] **Adequate dataset**: Sufficient sample size with clear selection criteria
- [ ] **Framework alignment**: Clear connection between framework and research goals
- [ ] **Analysis plan**: Appropriate methods and quality controls
- [ ] **Contingency planning**: Protocols for different types of results

---

## Common Validation Issues and Solutions

### Framework Issues
**Problem**: "Framework dimensions are not clearly distinct"
**Solution**: Provide explicit descriptions of how each dimension differs from others

**Problem**: "Scoring criteria are too vague"
**Solution**: Include specific examples of what constitutes low, medium, and high scores

**Problem**: "Evidence requirements are unclear"
**Solution**: Specify what textual evidence supports each type of score

### Experiment Issues
**Problem**: "Hypotheses are not falsifiable"
**Solution**: Ensure predictions can be proven wrong by potential evidence

**Problem**: "Sample size is inadequate"
**Solution**: Provide justification for sample size or expand the dataset

**Problem**: "Framework-experiment alignment is poor"
**Solution**: Clearly explain how framework dimensions relate to research variables

---

## Quality Standards

### Completion Thresholds
- **Frameworks**: Must meet 85% of quality requirements
- **Experiments**: Must meet 90% of quality requirements
- **Critical elements**: Must be 100% complete (scoring, hypotheses, analysis plans)

### Validation Outcomes
- **APPROVED**: Research meets all quality standards and can proceed
- **NEEDS REVISION**: Minor gaps identified with specific improvement guidance
- **REJECTED**: Significant issues requiring substantial revision

---

## Tips for Success

### Before Submission
1. **Review examples** of successful frameworks and experiments
2. **Test your framework** on a small sample to verify it works
3. **Get feedback** from colleagues before submitting
4. **Allow time** for potential revisions

### During Validation
1. **Read feedback carefully** - it's specific and actionable
2. **Address all issues** identified by the validation system
3. **Ask questions** if guidance is unclear
4. **Iterate quickly** - validation is designed to help, not hinder

### After Approval
1. **Review the execution plan** carefully before proceeding
2. **Confirm cost and time estimates** meet your constraints
3. **Understand what outputs** you'll receive
4. **Prepare for results** across different possible outcomes

---

## Getting Help

If you encounter issues during validation:
- **Check this guide** for common problems and solutions
- **Review the troubleshooting section** for technical issues
- **Consult example materials** to see successful patterns
- **Contact support** if you need personalized assistance

The validation system is designed to help ensure your research succeeds. By following these guidelines and responding to validation feedback, you'll be well-prepared to conduct high-quality computational social science research with Discernus. 