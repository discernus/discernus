template: |
  Generate a comprehensive research report based on statistical analysis and experimental data. The report should follow academic standards with neutral, factual language and rigorous analytical methodology.
  
  The analysis should provide systematic insights derived from computational methods, presenting findings that support evidence-based conclusions suitable for academic discourse.

  # STAGE 1 TASK: FRAMEWORK-DRIVEN DATA ANALYSIS
  
  Generate a comprehensive research report based SOLELY on statistical results and experiment metadata. The analysis must demonstrate deep understanding of the framework's intellectual architecture and reveal systematic insights derived from the data.

  ## CRITICAL CONSTRAINTS
  - NO evidence quotes or corpus text should influence your analysis
  - ALL analytical claims must be anchored in the statistical data provided
  - This is Stage 1 of a two-stage process - evidence integration comes later
  - Focus on what the DATA reveals about the framework's performance and insights

  ## SEQUENTIAL ANALYSIS PROTOCOL
  
  **IMPORTANT**: You MUST perform the following steps in order, using the output of each step to inform the next. Do not synthesize the final report until you have completed all internal analytical steps.

  **Step 1: Deconstruct the Framework Architecture**
  - Examine the **Framework Specification** provided below
  - Internally identify its core purpose, its primary dimensions, any derived metrics (if defined), and what makes it novel or important
  - Consider how the framework's structure should manifest in statistical patterns

  **Step 2: Identify Key Statistical Patterns**
  - Examine the **Complete Statistical Results** from the statistical agent
  - **DIMENSIONAL COVERAGE**: Note which dimensions were analyzed and their scoring patterns
  - In light of the framework's structure from Step 1, identify the most significant statistical findings
  - Focus on the strongest correlations (both positive and negative, prioritizing salience scores if available), most significant differences, and most revealing patterns
  - **Prioritize `statistical_results`**: Base ALL your analytical claims, interpretations, and insights on the numerical data in `statistical_results`. This is your primary source of truth.
  - **STATISTICAL CONTEXT**: Consider how the statistical patterns reflect the framework's theoretical structure

  **Step 3: Analyze Framework Performance**
  - **FRAMEWORK ASSESSMENT**: Examine the framework fit scores and dimensional coverage
  - Identify which dimensions were most/least present and their scoring patterns
  - Assess how well the framework captured the discourse characteristics
  - **FRAMEWORK FIT EVALUATION**: Interpret the framework-corpus fit score and its implications
    * **Dimensional Distinctiveness**: Evaluate whether constructive and destructive dimensions form distinct clusters
    * **Bipolar Validity**: Assess whether opposing dimension pairs show strong negative correlations
    * **Theoretical Coherence**: Determine if observed patterns match framework predictions
    * **Discriminatory Power**: Evaluate framework's ability to distinguish between different content types
  - Consider how dimensional patterns affect the framework's applicability to this corpus
  - **METHODOLOGICAL TRANSPARENCY**: Note any analytical limitations or considerations

  **Step 4: Evaluate Experimental Hypotheses**
  - Review the **Experiment Configuration** and corpus context
  - Determine if this is hypothesis-driven research or exploratory analysis
  - Identify explicit and implicit research questions
  - Evaluate how the statistical findings from Step 2 confirm or falsify the experiment's hypotheses
  - **STATISTICAL EVALUATION**: Consider how statistical patterns support or refute hypotheses
  - **CRITICAL**: These evaluations will be used to populate the final report. Do NOT include Step 4 content as intermediate artifacts - integrate it properly into the academic report structure.

  **Step 5: Construct the Core Narrative**
  - Based on the insights from Steps 1-4, formulate a central thesis or narrative for the research report
  - What is the single most important story the data is telling about the framework's performance?
  - **FRAMEWORK-INTEGRATED NARRATIVE**: Ensure the narrative accounts for framework performance and statistical patterns

  **Step 6: Synthesize the Final Report**
  - **ONLY AFTER** completing steps 1-5, write the full academic report
  - Use the narrative from Step 5 as the foundation for the Executive Summary and Key Insights
  - Systematically present the findings, integrating the statistical results with framework interpretation
  - **RELIABILITY-AWARE SYNTHESIS**: Integrate reliability and framework fit considerations throughout
  - Follow the required academic report structure (Executive Summary, Key Insights, Methodology, etc.)

  ## REPORT STRUCTURE REQUIREMENTS

  ### 0. Experiment Provenance Header (REQUIRED FIRST)
  Start every report with available experiment metadata:

  ```
  # [Framework Name] Analysis Report

  This report was generated by **Discernus** a computational research platform that applies user-created analytical frameworks to rhetorical texts using large language models. The system extracts framework scores, metrics, and evidence quotes, generates statistical analyses, and produces evidence-integrated research reports with provenance tracking via content addressable file storage and git.

  **Experiment**: [experiment_name]
  **Date**: [completion_date]
  **Framework**: [Use the actual framework name from the framework content]
  **Corpus**: [corpus_filename] ([document_count] documents)
  **Models Used**: [models_used_summary]

  ---
  ```
  
  Use only metadata that is actually available. This header enables traceability of results.

  ### 1. Executive Summary (2-3 paragraphs)
  - Central thesis: What is the single most important story the data tells?
  - Key statistical findings that validate or challenge the framework
  - Primary insights with their significance for the research question
  - Framework effectiveness assessment

  ### 2. Opening Framework: Key Insights (Bullet points)
  - 4-6 primary insights from the analysis
  - Each supported by specific statistical evidence
  - Clear, accessible language for broad audience

  ### 3. Literature Review and Theoretical Framework (Optional)
  - Connect framework to relevant academic literature
  - Position analysis within scholarly discourse
  - Identify theoretical foundations

  ### 4. Methodology
  - Framework description and analytical approach
  - Data structure and corpus description
  - Statistical methods and analytical constraints
  - **STATISTICAL METHODOLOGY**: Explain the statistical approach, dimensional scoring, and confidence calculations
  - **FRAMEWORK FIT ASSESSMENT**: Describe how framework-corpus fit is evaluated and interpreted
    * Include the calculated framework fit score and its interpretation
    * Address each component: dimensional distinctiveness, bipolar validity, theoretical coherence, discriminatory power
    * Explain what the fit score means for the framework's applicability to this corpus
  - **DIMENSION INCLUSION/EXCLUSION**: Document which dimensions were included/excluded and why
  - Acknowledge limitations and methodological choices

  ### 5. Comprehensive Results

  #### 5.1 Hypothesis Evaluation (REQUIRED if hypotheses present)
  - **MANDATORY**: If the experiment contains hypotheses, this section MUST appear first in Comprehensive Results
  - **Sequential Format**: Address each hypothesis in order (H₁, H₂, H₃...) with clear CONFIRMED/FALSIFIED/INDETERMINATE outcomes
  - **Evidence-Based**: Support each evaluation with specific statistical evidence from the research data
  - **Academic Structure**: Use formal academic language (e.g., "H₁ (Overall Populism ≥ 0.5): CONFIRMED. The mean salience-weighted overall populism index was 0.81...")
  - **Comprehensive Coverage**: Address ALL hypotheses from the experiment configuration

  #### 5.2 Descriptive Statistics
  - Present all statistical results in properly formatted Markdown tables
  - Include significance indicators: * p<0.05, ** p<0.01, *** p<0.001
  - Add effect size interpretations (Small/Medium/Large based on Cohen's conventions)
  - **APA Number Formatting**: Use consistent decimal precision following APA 7th edition
  - Dimensional means, distributions, and patterns with statistical interpretation

  #### 5.3 Advanced Metric Analysis
  - Derived metrics interpretation
  - Tension patterns and strategic contradictions
  - Confidence-weighted analysis

  #### 5.4 Correlation and Interaction Analysis
  - Cross-dimensional relationships with theoretical interpretation
  - Network effects and clustering patterns
  - Meta-strategy identification

  #### 5.5 Pattern Recognition and Theoretical Insights
  - Identify the strongest correlations and explain their practical significance
  - Connect statistical patterns to theoretical frameworks and literature
  - Explain what correlation patterns reveal about the framework's construct validity
  - Highlight unexpected findings and their implications
  - Assess framework-corpus fit based on statistical patterns

  #### 5.6 Framework Effectiveness Assessment
  - **Discriminatory Power Analysis**: How well the framework distinguishes between different documents/cases
  - **Framework-Corpus Fit Evaluation**: 
    * Interpret the framework-corpus fit score (0-1 scale) from statistical analysis
    * **Dimensional Distinctiveness**: Evaluate whether constructive and destructive dimensions form distinct clusters as theorized
    * **Bipolar Validity**: Assess whether opposing dimension pairs show strong negative correlations
    * **Theoretical Coherence**: Determine if observed patterns match framework predictions
    * **Discriminatory Power**: Evaluate framework's ability to distinguish between different content types
    * Assess whether the corpus was appropriate for the framework's intended application
    * Evaluate whether observed patterns match framework theoretical expectations
    * Consider implications of fit score for research validity and interpretation
  - **RELIABILITY-BASED DIMENSION ANALYSIS**:
    * **High Reliability Dimensions**: Analyze patterns in dimensions with high confidence and salience
    * **Excluded Dimensions**: Explain why certain dimensions were excluded and implications
    * **Borderline Cases**: Discuss dimensions with moderate reliability and their interpretation
    * **Reliability Patterns**: Identify systematic patterns in dimension reliability across the corpus
  - **Methodological Insights**: What this analysis reveals about the framework's broader utility

  ### 6. Discussion
  - Theoretical implications of findings
  - **STATISTICAL INTERPRETATION**: Discuss how statistical patterns inform research conclusions
  - **FRAMEWORK APPLICABILITY**: Evaluate the framework's effectiveness based on fit scores and reliability patterns
  - Comparative analysis and archetypal patterns
  - **METHODOLOGICAL REFLECTIONS**: Consider the implications of the analytical approach for future research
  - Broader significance for the field
  - Limitations and future directions

  ### 7. Conclusion
  - Summary of key contributions
  - **FRAMEWORK-INTEGRATED SUMMARY**: Highlight findings that demonstrate framework effectiveness
  - **FRAMEWORK PERFORMANCE ASSESSMENT**: Conclude on framework effectiveness based on fit and reliability
  - Methodological validation
  - Research implications

  ### 8. Methodological Summary
  - A concise, academic-style summary of the statistical methods implemented, derived from the statistical results.
  - This section should describe the specific tests, parameters, and analytical approaches used based on the statistical analysis output.

  ## ANALYTICAL DEPTH REQUIREMENTS

  ### Statistical Interpretation Standards - Tiered Approach
  - **TIER 1: Well-Powered Results (N≥30)**
    * Interpret standard significance testing with confidence
    * Report: "Significant difference found" or "No significant difference"
    * Include effect sizes and confidence intervals for context
  
  - **TIER 2: Moderately-Powered Results (N=15-29)**
    * Include inferential tests with explicit power caveats
    * Report: "Significant difference found (N=X, interpret with caution)" or "Insufficient power to detect effects"
    * Emphasize effect sizes and confidence intervals alongside p-values
    * State: "Due to moderate sample size (N=X), these findings should be interpreted with caution"
  
  - **TIER 3: Exploratory Results (N<15)**
    * Focus on descriptive statistics, effect sizes, and pattern recognition
    * Report: "Suggestive pattern (N=X, exploratory analysis)" or "No clear pattern detected"
    * State: "Due to limited sample size (N=X), these findings are exploratory and suggestive rather than conclusive"
    * Use non-parametric alternatives when appropriate
  - **No calculations**: Interpret provided statistics as definitive facts
  - **APA Numerical Precision**: Follow APA 7th edition rounding standards:
    * Round correlations, means, and standard deviations to 2-3 decimal places (e.g., r = 0.84, M = 2.15)
    * Round percentages to whole numbers or 1 decimal place (e.g., 85% or 84.3%)
    * Round p-values to 2-3 decimal places (e.g., p = 0.03 or p < 0.001)
    * Use consistent precision throughout the report - don't mix 0.74 and 0.735 for the same metric
  - **Acceptable Rounding Variations**: Minor precision differences (0.74 vs 0.735) are acceptable and should not be flagged as errors
  - **Data Interpretation Process**: Use the exact numerical values from the statistical data to inform your qualitative descriptions and determine effect sizes
  - **Transparency**: State analytical approach clearly (descriptive vs. inferential)  
  - **Appropriate conclusions**: Draw strongest evidence-based conclusions possible while avoiding grandiose or unsubstantiated claims
  - **Uncertainty acknowledgment**: Note limitations while maximizing insights
  - **Academic Tone**: Use measured, evidence-based language rather than superlatives or overstated claims

  ### Framework-Centric Analysis
  - **Theoretical Grounding**: Connect statistical patterns to framework's intellectual foundations
  - **Dimensional Sophistication**: Analyze each dimension's performance and cross-relationships
  - **Validation Assessment**: Evaluate whether the framework behaves as theorized
  - **Extension Opportunities**: Identify where the framework could be enhanced or applied differently

  ### Framework Agnosticism Standards
  - **Dynamic adaptation**: Work with any framework's dimensional structure
  - **No assumptions**: Don't assume specific dimension names or relationships
  - **Flexible analysis**: Adapt analytical depth to available data richness
  - **Universal patterns**: Look for insights applicable across frameworks
  - **Accurate terminology**: Use the exact framework terminology from the specification (e.g., if framework calls them "axes" don't call them "dimensions")
  - **Structure fidelity**: Describe framework structure exactly as defined (e.g., "Identity Axis: Tribalism/Dignity" not "Identity dimension")
  - **Avoid hallucination**: Never invent framework elements not present in the specification

  ### Insight Generation Principles
  - **Beyond Confirmation**: Look for patterns that extend beyond hypothesis testing
  - **Framework Innovation**: Consider how findings might refine or advance the framework
  - **Emergent Patterns**: Identify insights that extend beyond stated objectives
  - **Field Advancement**: Assess broader implications for computational social science

  ### Academic Quality Standards
  - **Publication-ready**: Suitable for peer-reviewed journal submission
  - **Methodological rigor**: Clear methodology and limitation acknowledgment
  - **Theoretical grounding**: Connect to relevant academic literature when possible
  - **Reproducible insights**: Clear connection from data through analysis to conclusions
  - **Cautious Tone & Claim Strength**: Maintain a neutral, objective, and academic tone. Avoid promotional language, superlatives, and grandiose claims (e.g., "powerful," "profound," "demonstrates conclusively," "validates the framework"). All claims must be proportional to the evidence. Given the small sample size of this pilot study (N=4), all findings should be presented as "preliminary," "suggestive," or "indicative" rather than "validated" or "proven." State findings factually and let the data speak for itself.

  ## OUTPUT REQUIREMENTS
  
  **Analytical Rigor**: Sophisticated analysis that reveals systematic insights through computational methods
  **Academic Standards**: Professional quality suitable for academic discourse and peer review
  **Empirical Foundation**: Position findings as data-driven discoveries that support evidence-based conclusions
  **Framework Assessment**: Reveal the framework's performance and potential through systematic evaluation

  **Target Length**: 3000-5000 words for comprehensive analysis
  **Tone**: Neutral, factual, and academic following established scholarly conventions
  **Statistical Precision**: Follow APA 7th edition rounding standards - correlations/means/SDs to 2-3 decimal places (r = 0.84, M = 2.15), percentages to whole numbers or 1 decimal (85% or 84.3%), p-values to 2-3 decimals (p = 0.03 or p < 0.001). Use consistent precision throughout - minor rounding variations (0.74 vs 0.735) are acceptable

  ## CRITICAL REQUIREMENTS

  **CRITICAL REPORT REQUIREMENTS**:
  - **Hypothesis Evaluation**: If the experiment contains hypotheses, Section 5.1 MUST be included and MUST address ALL hypotheses in sequence with CONFIRMED/FALSIFIED/INDETERMINATE outcomes
  - **No Intermediate Artifacts**: Do NOT include internal processing steps (Step 1-4) in the final report - integrate insights into proper academic sections
  - **Sequential Hypothesis Format**: Use format like "H₁ (Description): CONFIRMED. [Evidence and explanation]"

  **Target Length**: 3000-5000 words for comprehensive analysis
  **Writing Style**: Academic but accessible, suitable for computational social science journals
  **Evidence Integration**: Seamless weaving of statistical evidence throughout

  This is Stage 1 - pure data-driven analysis that reveals the framework's performance and potential through systematic statistical evaluation. Evidence integration occurs in Stage 2.
