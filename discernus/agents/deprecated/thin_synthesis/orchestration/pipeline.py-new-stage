    def _stage_5_classify_results(self, exec_response, request: ProductionPipelineRequest) -> ClassificationResponse:
        """Stage 5: Apply pattern classification rubric to calculated metrics."""
        self.logger.info("ðŸ“Š Stage 5: Classifying results...")
        
        try:
            # The full framework spec is passed in the experiment context. We need to parse it to get the rubric.
            experiment_context = json.loads(request.experiment_context)
            framework_config = experiment_context.get("framework_config", {})
            classification_rubric = framework_config.get("pattern_classifications", {})

            if not classification_rubric:
                self.logger.info("No classification rubric found in framework. Skipping classification.")
                return ClassificationResponse(success=True, classifications={})

            # The calculated metrics are in the exec_response
            # This is complex because of the nested structure. We need to find the actual results.
            stage_2_results = exec_response.get('stage_2_derived_metrics', {})
            statistical_results = stage_2_results.get('results', {})
            
            # The metrics might be in a specific task's output. We need to find them.
            calculated_metrics = {}
            for task_name, task_result in statistical_results.items():
                if isinstance(task_result, dict) and task_result.get('type') == 'derived_metrics_calculation':
                    metrics = task_result.get('result_value', {}).get('calculated_metrics', {})
                    # The values are lists, we need to handle this. For now, let's take the first value if it's a list.
                    for key, value in metrics.items():
                        if isinstance(value, list) and len(value) > 0:
                            calculated_metrics[key] = value[0]
                        else:
                            calculated_metrics[key] = value
            
            if not calculated_metrics:
                 self.logger.warning("No calculated metrics found to classify.")
                 return ClassificationResponse(success=True, classifications={})

            classification_request = ClassificationRequest(
                calculated_metrics=calculated_metrics,
                classification_rubric=classification_rubric
            )
            
            return self.classification_agent.classify(classification_request)

        except Exception as e:
            self.logger.error(f"Classification failed: {str(e)}")
            return ClassificationResponse(success=False, error_message=str(e))
