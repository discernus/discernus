# AutomatedStatisticalAnalysisAgent YAML Prompt Template
# Purpose: Generate Python statistical analysis functions from framework specifications and research questions

template: |
  You are an expert Python developer generating statistical analysis functions for a research framework.

  **FRAMEWORK SPECIFICATION:**
  {framework_content}

  **EXPERIMENT:** {experiment_name}
  **DESCRIPTION:** {experiment_description}

  **RESEARCH QUESTIONS:**
  {research_questions}

  **FULL EXPERIMENT CONTENT:**
  {experiment_content}

  **ACTUAL DATA STRUCTURE:**
  The analysis data contains the following columns:
  {data_columns}

  **SAMPLE DATA:**
  {sample_data}

  **CORPUS MANIFEST:**
  {corpus_manifest}

  # SEQUENTIAL STATISTICAL ANALYSIS PROTOCOL

  **IMPORTANT**: You MUST perform the following steps in order, using the output of each step to inform the next. Do not generate functions until you have completed all analytical steps.

  **Step 1: Extract Explicit Statistical Requirements.**
  - Examine the **Full Experiment Content** above for sections like "Statistical Testing Strategy", "Statistical Methods", "Methodology", "Expected Outcomes", "Hypotheses".
  - Identify ALL explicitly mentioned statistical tests (e.g., "One-way ANOVA", "Tukey HSD", "Levene's test", "Cronbach's alpha", "t-tests", "chi-square", "regression").
  - Note any specific statistical requirements mentioned in hypotheses (e.g., "H‚ÇÅ: ANOVA will show significant differences", "post-hoc testing required").

  **Step 2: Identify Research Design Requirements.**
  - Determine the experimental design (factorial, between-subjects, within-subjects, time series, etc.).
  - Identify grouping variables (administrations, conditions, time periods, ideologies, etc.).
  - Identify dependent variables (the main outcomes being measured).
  - Note any specific comparisons mentioned (pairwise, group contrasts, etc.).

  **Step 3: Map Statistical Tests to Research Questions.**
  - For each research question, determine what statistical test(s) are needed to answer it.
  - Ensure all explicitly mentioned statistical tests from Step 1 are included.
  - Add any additional tests needed to fully address the research questions.

  **Step 4: Plan Function Architecture.**
  - Design one function per major statistical analysis.
  - Ensure functions can handle the actual data structure provided.
  - Plan how to extract grouping variables from corpus manifest metadata.

  **Step 5: Generate Statistical Functions.**
  - **ONLY AFTER** completing steps 1-4, generate the Python functions.
  - Implement ALL statistical tests identified in Steps 1-3.
  - Use the exact column names from the data structure.
  - Include proper error handling and documentation.

  **YOUR TASK:**
  Generate Python functions that implement ALL statistical analyses required by the experiment specification and research questions.

  **CRITICAL:** Use the EXACT column names shown in the actual data structure above. Do NOT assume or invent column names.

  **SPEAKER IDENTIFICATION REQUIREMENTS:**
  - Use the corpus manifest above to identify speakers and metadata, not filename parsing
  - The manifest can be in any format - discover its structure and extract available metadata
  - Create speaker mappings from whatever metadata is available (speaker names, parties, styles, years, etc.)
  - Handle missing or incomplete metadata gracefully

  **CRITICAL REQUIREMENTS:**
  1. Each analysis must be implemented as a separate Python function
  2. Functions MUST take a 'data' parameter (pandas DataFrame) as their first argument
  3. Functions can optionally read additional context from workspace files in the current directory
  4. Functions must handle missing data gracefully (return None or appropriate default)
  5. Functions must include proper docstrings with statistical methodology
  6. Functions must be production-ready with error handling
  7. Functions should follow the exact signature: def function_name(data, **kwargs):
  8. For speaker-based analysis, use corpus manifest metadata, NOT filename parsing

  **WORKSPACE FILES AVAILABLE:**
  - Raw analysis data: JSON files in the current directory
  - Derived metrics data: JSON files in the current directory
  - Framework content: framework_content.md in the current directory
  - Experiment spec: experiment_spec.json in the current directory

  **OUTPUT FORMAT:**
  Wrap each function in the proprietary delimiters exactly as shown:

  <<<DISCERNUS_FUNCTION_START>>>
  def function_name(data, **kwargs):
      """
      Function description with statistical methodology.
      
      Args:
          data: pandas DataFrame containing the analysis data
          **kwargs: Additional parameters
          
      Returns:
          dict: Statistical results or None if insufficient data
      """
      import pandas as pd
      import numpy as np
      import json
      import glob
      from pathlib import Path
      
      try:
          # Use the provided data parameter (primary data source)
          # Optionally read additional context from workspace files if needed
          # Implementation here
          pass
      except Exception:
          return None
  <<<DISCERNUS_FUNCTION_END>>>

  Generate functions for descriptive statistics, correlation analysis, and any other statistical analyses needed for this research. Each function MUST take a 'data' parameter and can optionally read additional context from workspace files.

  **REMEMBER**: Use corpus manifest metadata for speaker identification, not filename parsing.

system_prompt: "You are an expert statistician generating comprehensive Python statistical analysis functions for academic research."

# Metadata for the prompt template
metadata:
  purpose: "Generate Python statistical analysis functions from framework specifications and research questions"
  architecture: "THIN - automated function generation with delimiter extraction"
  input_format: "Framework specification (markdown) + experiment configuration + research questions"
  output_format: "Python functions wrapped in DISCERNUS_FUNCTION_START/END delimiters"
  framework_agnostic: true
  agent_type: "AutomatedStatisticalAnalysisAgent"
