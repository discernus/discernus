#!/usr/bin/env python3
"""
Enhanced Synthesis Agent for Discernus THIN v2.0
================================================

Enhanced version of SynthesisAgent with:
- Mathematical spot-checking of analysis agent calculations
- Dual-LLM validation for numerical accuracy
- Enhanced synthesis with confidence assessment
- Direct function call interface (bypasses Redis coordination)

Implements the simplified 2-agent pipeline: AnalysisAgent â†’ SynthesisAgent
"""

import json
import base64
import hashlib
import yaml
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List, Optional
from litellm import completion

from discernus.core.security_boundary import ExperimentSecurityBoundary, SecurityError
from discernus.core.audit_logger import AuditLogger
from discernus.core.local_artifact_storage import LocalArtifactStorage


class EnhancedSynthesisAgentError(Exception):
    """Enhanced synthesis agent specific exceptions"""
    pass


class EnhancedSynthesisAgent:
    """
    Enhanced synthesis agent with mathematical spot-checking capabilities.
    
    Key enhancements over original SynthesisAgent:
    - Mathematical spot-checking of analysis results
    - Dual-LLM validation for numerical accuracy
    - Enhanced synthesis with confidence assessment
    - Direct function call interface (no Redis)
    - Comprehensive error detection and reporting
    """
    
    def __init__(self, 
                 security_boundary: ExperimentSecurityBoundary,
                 audit_logger: AuditLogger,
                 artifact_storage: LocalArtifactStorage):
        """
        Initialize enhanced synthesis agent.
        
        Args:
            security_boundary: Security boundary for file access
            audit_logger: Audit logger for comprehensive logging
            artifact_storage: Local artifact storage for caching
        """
        self.security = security_boundary
        self.audit = audit_logger
        self.storage = artifact_storage
        self.agent_name = "EnhancedSynthesisAgent"
        
        # Load enhanced prompt template
        self.prompt_template = self._load_prompt_template()
        
        print(f"ðŸ§  {self.agent_name} v2.2 initialized for integrated report synthesis")
        
        self.audit.log_agent_event(self.agent_name, "initialization", {
            "security_boundary": self.security.get_boundary_info(),
            "capabilities": ["consolidated_data_synthesis", "markdown_report_generation"]
        })
    
    def _load_prompt_template(self) -> str:
        """Load prompt template from YAML file."""
        prompt_path = Path(__file__).parent / "prompt.yaml"
        if not prompt_path.exists():
            raise FileNotFoundError("Could not find prompt.yaml for EnhancedSynthesisAgent")
        
        with open(prompt_path, 'r') as f:
            prompt_config = yaml.safe_load(f)
        
        return prompt_config['template']

    def synthesize_results(self, 
                          analysis_results: List[Dict[str, Any]],
                          experiment_config: Dict[str, Any],
                          model: str = "vertex_ai/gemini-2.5-pro") -> Dict[str, Any]:
        """
        Perform synthesis on raw analysis results - LLM handles extraction (THIN principle).
        """
        start_time = datetime.now(timezone.utc).isoformat()
        
        # Create deterministic synthesis_id for perfect caching (THIN principle)
        # Hash based on analysis results content only, not timestamp
        analysis_content_hash = hashlib.sha256(
            json.dumps(analysis_results, sort_keys=True).encode()
        ).hexdigest()
        synthesis_id = f"synthesis_{analysis_content_hash[:12]}_debug"  # Force cache miss for debugging
        
        self.audit.log_agent_event(self.agent_name, "synthesis_start", {
            "synthesis_id": synthesis_id,
            "num_analysis_batches": len(analysis_results),
            "model": model,
            "experiment": experiment_config.get("name", "unknown")
        })
        
        try:
            # Check if synthesis result is already cached (THIN perfect caching)
            for artifact_hash, artifact_info in self.storage.registry.items():
                if (artifact_info.get("metadata", {}).get("artifact_type") == "synthesis_result" and
                    artifact_info.get("metadata", {}).get("synthesis_id") == synthesis_id):
                    
                    # Cache hit! Return the cached synthesis result
                    print(f"ðŸ’¾ Cache hit for synthesis: {synthesis_id}")
                    cached_content = self.storage.get_artifact(artifact_hash)
                    cached_result = json.loads(cached_content.decode('utf-8'))
                    
                    self.audit.log_agent_event(self.agent_name, "cache_hit", {
                        "synthesis_id": synthesis_id,
                        "cached_artifact_hash": artifact_hash
                    })
                    
                    return {
                        "result_hash": artifact_hash,
                        "duration_seconds": 0.0,  # Instant cache hit
                        "synthesis_confidence": "cached",
                        "synthesis_report_markdown": cached_result.get("synthesis_report_markdown", "")
                    }
            
            # No cache hit - proceed with synthesis
            print(f"ðŸ” No cache hit for {synthesis_id} - performing synthesis...")
            
            # Prepare the synthesis prompt with raw analysis results
            synthesis_prompt = self.prompt_template.format(
                analysis_results=json.dumps(analysis_results, indent=2)
            )

            # Call the synthesis LLM
            self.audit.log_agent_event(self.agent_name, "llm_call_start", {
                "synthesis_id": synthesis_id, "type": "synthesis", "prompt_length": len(synthesis_prompt)
            })
            
            # Debug: Log first 2000 chars of prompt to see what we're sending
            print(f"ðŸ” DEBUG: First 2000 chars of synthesis prompt:")
            print(f"{synthesis_prompt[:2000]}...")
            print(f"ðŸ” DEBUG: Prompt ends with:")
            print(f"...{synthesis_prompt[-500:]}")

            response = completion(
                model=model,
                messages=[{"role": "user", "content": synthesis_prompt}],
                temperature=0.0,
                max_tokens=6000,  # Increased limit for complete synthesis report
                safety_settings=[
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
                ]
            )
            
            synthesis_content = response.choices[0].message.content
            
            # Check for None content from LLM response
            if synthesis_content is None:
                finish_reason = response.choices[0].finish_reason if response and response.choices else "unknown"
                completion_tokens = response.usage.completion_tokens if response and response.usage else "unknown"
                
                # Handle length-limited responses gracefully
                if finish_reason == 'length':
                    synthesis_content = f"[SYNTHESIS REPORT - Truncated due to length limit]\n\nThis synthesis was truncated after {completion_tokens} tokens. The analysis completed but exceeded the maximum response length. Key findings would be included above this notice."
                    print(f"âš ï¸  Synthesis truncated at {completion_tokens} tokens - using placeholder content")
                else:
                    raise EnhancedSynthesisAgentError(f"LLM returned None content - finish_reason: {finish_reason}, completion_tokens: {completion_tokens}")
            
            self.audit.log_agent_event(self.agent_name, "llm_call_complete", {
                "synthesis_id": synthesis_id, "type": "synthesis", "response_length": len(synthesis_content)
            })

            # Create comprehensive result artifact
            end_time = datetime.now(timezone.utc).isoformat()
            duration = self._calculate_duration(start_time, end_time)
            
            synthesis_artifact = {
                "synthesis_id": synthesis_id,
                "agent_name": self.agent_name,
                "agent_version": "enhanced_v2.2_integrated_report",
                "experiment_name": experiment_config.get("name", "unknown"),
                "model_used": model,
                "synthesis_report_markdown": synthesis_content,
                "execution_metadata": {
                    "start_time": start_time,
                    "end_time": end_time,
                    "duration_seconds": duration,
                },
                "input_metadata": {
                    "num_analysis_batches_synthesized": len(analysis_results)
                },
                "provenance": {
                    "security_boundary": self.security.get_boundary_info(),
                    "audit_session_id": self.audit.session_id
                }
            }
            
            # Store synthesis artifact and return with expected keys
            result_hash = self.storage.put_artifact(
                json.dumps(synthesis_artifact, indent=2).encode('utf-8'),
                {"artifact_type": "synthesis_result", "synthesis_id": synthesis_id}
            )
            
            return {
                "result_hash": result_hash,
                "duration_seconds": duration,
                "synthesis_confidence": "completed",  # Add basic confidence indicator
                "synthesis_report_markdown": synthesis_content  # Include for final report
            }

        except Exception as e:
            self.audit.log_agent_event(self.agent_name, "synthesis_failed", {"error": str(e)})
            raise EnhancedSynthesisAgentError(f"Synthesis failed: {e}")

    def _calculate_duration(self, start: str, end: str) -> float:
        """Calculates duration in seconds from ISO 8601 timestamps."""
        start_dt = datetime.fromisoformat(start)
        end_dt = datetime.fromisoformat(end)
        return (end_dt - start_dt).total_seconds() 