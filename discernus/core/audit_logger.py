#!/usr/bin/env python3
"""
Comprehensive Audit Logging System for Discernus THIN v2.0
==========================================================

Provides complete audit trail capture for all system operations:
- JSONL logging for all orchestrator and agent activities
- LLM interaction logging (prompts, responses, models, costs)
- Artifact chain tracking with cache status
- Real-time append-only logging for crash recovery

Ensures complete academic integrity and reproducibility.
"""

import json
import hashlib
import time
import traceback
import functools
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Callable
from .security_boundary import ExperimentSecurityBoundary


class AuditLogger:
    """
    Comprehensive audit logging system that captures all system activities
    for complete provenance and academic integrity.
    """
    
    def __init__(self, security_boundary: ExperimentSecurityBoundary, run_folder: Path, verbose_trace: bool = False):
        """
        Initialize audit logger for a specific experiment run.
        
        Args:
            security_boundary: Security boundary for file operations
            run_folder: The specific run folder for this experiment
            verbose_trace: Enable verbose call tracing for debugging
        """
        self.security = security_boundary
        self.run_folder = security_boundary.validate_path(run_folder)
        self.verbose_trace = verbose_trace
        
        # Create logs directory
        self.logs_dir = self.security.secure_mkdir(run_folder / "logs")
        
        # Define log file paths
        self.orchestrator_log = self.logs_dir / "orchestrator.jsonl"
        self.agent_log = self.logs_dir / "agents.jsonl"
        self.llm_log = self.logs_dir / "llm_interactions.jsonl"
        self.artifact_log = self.logs_dir / "artifacts.jsonl"
        self.system_log = self.logs_dir / "system.jsonl"
        self.cost_log = self.logs_dir / "costs.jsonl"
        self.trace_log = self.logs_dir / "trace.jsonl"
        
        # Initialize session metadata
        self.session_id = self._generate_session_id()
        self.start_time = self._get_timestamp()
        
        print(f"📋 Audit logging initialized: {self.logs_dir}")
        
        # Log session start
        self._log_system_event("audit_session_start", {
            "session_id": self.session_id,
            "experiment_root": str(security_boundary.experiment_root),
            "run_folder": str(self.run_folder),
            "start_time": self.start_time
        })
    
    def _generate_session_id(self) -> str:
        """Generate unique session ID for this audit session."""
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
        random_suffix = hashlib.sha256(str(datetime.now()).encode()).hexdigest()[:8]
        return f"{timestamp}_{random_suffix}"
    
    def _get_timestamp(self) -> str:
        """Get current timestamp in ISO format."""
        return datetime.now(timezone.utc).isoformat()
    
    def _append_to_log(self, log_file: Path, entry: Dict[str, Any]) -> None:
        """
        Append entry to JSONL log file (real-time, append-only).
        
        Args:
            log_file: Path to log file
            entry: Dictionary to log as JSON
        """
        try:
            # Add session metadata to every entry
            entry.update({
                "session_id": self.session_id,
                "timestamp": self._get_timestamp()
            })
            
            # Convert to JSON line
            json_line = json.dumps(entry, ensure_ascii=False, separators=(',', ':'))
            
            # Append to file (create if doesn't exist)
            with self.security.secure_open(log_file, 'a', encoding='utf-8') as f:
                f.write(json_line + '\n')
                f.flush()  # Ensure immediate write for crash recovery
                
        except Exception as e:
            print(f"⚠️ Audit logging error: {e}")
            # Don't fail the main process due to logging issues
    
    def log_orchestrator_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """
        Log orchestrator-level events.
        
        Args:
            event_type: Type of orchestrator event
            data: Event data dictionary
        """
        entry = {
            "log_type": "orchestrator",
            "event_type": event_type,
            "data": data
        }
        self._append_to_log(self.orchestrator_log, entry)
    
    def log_agent_event(self, agent_name: str, event_type: str, data: Dict[str, Any]) -> None:
        """
        Log agent execution events.
        
        Args:
            agent_name: Name of the agent (e.g., "AnalyseBatchAgent")
            event_type: Type of agent event
            data: Event data dictionary
        """
        entry = {
            "log_type": "agent",
            "agent_name": agent_name,
            "event_type": event_type,
            "data": data
        }
        self._append_to_log(self.agent_log, entry)
    
    def log_llm_interaction(self, 
                           model: str, 
                           prompt: str, 
                           response: str,
                           agent_name: str,
                           interaction_type: str = "completion",
                           metadata: Optional[Dict[str, Any]] = None) -> str:
        """
        Log complete LLM interaction with full details.
        
        Args:
            model: LLM model identifier
            prompt: Full prompt sent to LLM
            response: Full response from LLM
            agent_name: Which agent made the call
            interaction_type: Type of interaction (completion, chat, etc.)
            metadata: Additional metadata (cost, tokens, etc.)
        
        Returns:
            Interaction hash for reference
        """
        # Create interaction hash for reference
        interaction_data = f"{model}:{prompt}:{response}".encode('utf-8')
        interaction_hash = hashlib.sha256(interaction_data).hexdigest()[:16]
        
        entry = {
            "log_type": "llm_interaction",
            "interaction_hash": interaction_hash,
            "agent_name": agent_name,
            "model": model,
            "interaction_type": interaction_type,
            "prompt": prompt,
            "response": response,
            "prompt_length": len(prompt),
            "response_length": len(response),
            "metadata": metadata or {}
        }
        
        self._append_to_log(self.llm_log, entry)
        return interaction_hash
    
    def log_artifact_operation(self, 
                              operation: str,
                              artifact_hash: str,
                              artifact_type: str,
                              metadata: Optional[Dict[str, Any]] = None) -> None:
        """
        Log artifact storage/retrieval operations.
        
        Args:
            operation: Type of operation (store, retrieve, cache_hit)
            artifact_hash: SHA-256 hash of the artifact
            artifact_type: Type of artifact (framework, document, result, etc.)
            metadata: Additional metadata
        """
        entry = {
            "log_type": "artifact",
            "operation": operation,
            "artifact_hash": artifact_hash,
            "artifact_type": artifact_type,
            "metadata": metadata or {}
        }
        self._append_to_log(self.artifact_log, entry)
    
    def log_artifact_chain(self, 
                          stage: str,
                          input_hashes: List[str],
                          output_hash: str,
                          agent_name: str,
                          llm_interaction_hash: Optional[str] = None) -> None:
        """
        Log artifact transformation chain (input -> process -> output).
        
        Args:
            stage: Processing stage name
            input_hashes: List of input artifact hashes
            output_hash: Hash of produced output artifact
            agent_name: Agent that performed the transformation
            llm_interaction_hash: Reference to LLM interaction if applicable
        """
        entry = {
            "log_type": "artifact_chain",
            "stage": stage,
            "input_hashes": input_hashes,
            "output_hash": output_hash,
            "agent_name": agent_name,
            "llm_interaction_hash": llm_interaction_hash
        }
        self._append_to_log(self.artifact_log, entry)
    
    def _log_system_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """
        Log system-level events.
        
        Args:
            event_type: Type of system event
            data: Event data dictionary
        """
        entry = {
            "log_type": "system",
            "event_type": event_type,
            "data": data
        }
        self._append_to_log(self.system_log, entry)
    
    def log_error(self, error_type: str, error_message: str, 
                  context: Optional[Dict[str, Any]] = None) -> None:
        """
        Log error events with full context.
        
        Args:
            error_type: Type of error
            error_message: Error message
            context: Additional context information
        """
        entry = {
            "log_type": "error",
            "error_type": error_type,
            "error_message": error_message,
            "context": context or {}
        }
        self._append_to_log(self.system_log, entry)
    
    def log_performance_metric(self, metric_name: str, value: Union[float, int],
                              context: Optional[Dict[str, Any]] = None) -> None:
        """
        Log performance metrics.
        
        Args:
            metric_name: Name of the metric
            value: Metric value
            context: Additional context
        """
        entry = {
            "log_type": "performance",
            "metric_name": metric_name,
            "value": value,
            "context": context or {}
        }
        self._append_to_log(self.system_log, entry)
    
    def get_session_summary(self) -> Dict[str, Any]:
        """
        Get summary of current audit session.
        
        Returns:
            Dictionary with session summary
        """
        return {
            "session_id": self.session_id,
            "start_time": self.start_time,
            "current_time": self._get_timestamp(),
            "logs_directory": str(self.logs_dir),
            "log_files": {
                "orchestrator": str(self.orchestrator_log.relative_to(self.run_folder)),
                "agents": str(self.agent_log.relative_to(self.run_folder)),
                "llm_interactions": str(self.llm_log.relative_to(self.run_folder)),
                "artifacts": str(self.artifact_log.relative_to(self.run_folder)),
                "system": str(self.system_log.relative_to(self.run_folder)),
                "costs": str(self.cost_log.relative_to(self.run_folder))
            }
        }
    
    def log_cost(self, 
                 operation: str,
                 model: str,
                 tokens_used: int,
                 cost_usd: float,
                 agent_name: str,
                 interaction_hash: Optional[str] = None,
                 metadata: Optional[Dict[str, Any]] = None) -> None:
        """
        Log cost information for LLM operations.
        
        Args:
            operation: Type of operation (analysis, synthesis, validation, etc.)
            model: LLM model used
            tokens_used: Total tokens consumed
            cost_usd: Cost in USD
            agent_name: Agent that incurred the cost
            interaction_hash: Reference to LLM interaction
            metadata: Additional cost-related metadata
        """
        entry = {
            "log_type": "cost_tracking",
            "timestamp": self._get_timestamp(),
            "operation": operation,
            "agent_name": agent_name,
            "model": model,
            "tokens_used": tokens_used,
            "cost_usd": round(cost_usd, 6),  # 6 decimal places for precision
            "interaction_hash": interaction_hash,
            "metadata": metadata or {}
        }
        self._append_to_log(self.cost_log, entry)
    
    def get_session_costs(self) -> Dict[str, Any]:
        """
        Calculate total costs for the current session by reading cost log.
        
        Returns:
            Dictionary with cost breakdown and totals
        """
        if not self.llm_log.exists():
            return {
                "total_cost_usd": 0.0,
                "total_tokens": 0,
                "operations": {},
                "models": {},
                "agents": {}
            }
        
        total_cost = 0.0
        total_tokens = 0
        operations = {}
        models = {}
        agents = {}
        
        try:
            with open(self.llm_log, 'r') as f:
                for line in f:
                    if line.strip():
                        entry = json.loads(line)
                        
                        # Extract cost data from metadata
                        metadata = entry.get("metadata", {})
                        cost = metadata.get("response_cost_usd", 0.0)
                        tokens = metadata.get("total_tokens", 0)
                        
                        # Only process entries with cost data
                        if cost > 0 or tokens > 0:
                            operation = metadata.get("step", entry.get("interaction_type", "unknown"))
                            model = entry.get("model", "unknown")
                            agent = entry.get("agent_name", "unknown")
                            
                            # Aggregate totals
                            total_cost += cost
                            total_tokens += tokens
                            
                            # Aggregate by operation
                            if operation not in operations:
                                operations[operation] = {"cost_usd": 0.0, "tokens": 0, "calls": 0}
                            operations[operation]["cost_usd"] += cost
                            operations[operation]["tokens"] += tokens
                            operations[operation]["calls"] += 1
                            
                            # Aggregate by model
                            if model not in models:
                                models[model] = {"cost_usd": 0.0, "tokens": 0, "calls": 0}
                            models[model]["cost_usd"] += cost
                            models[model]["tokens"] += tokens
                            models[model]["calls"] += 1
                            
                            # Aggregate by agent
                            if agent not in agents:
                                agents[agent] = {"cost_usd": 0.0, "tokens": 0, "calls": 0}
                            agents[agent]["cost_usd"] += cost
                            agents[agent]["tokens"] += tokens
                            agents[agent]["calls"] += 1
                        
        except Exception as e:
            print(f"Warning: Error reading LLM interactions log: {e}")
        
        return {
            "total_cost_usd": round(total_cost, 6),
            "total_tokens": total_tokens,
            "operations": operations,
            "models": models,
            "agents": agents
        }
    
    def estimate_remaining_cost(self, 
                               documents_analyzed: int, 
                               total_documents: int,
                               synthesis_pending: bool = True) -> Dict[str, Any]:
        """
        Estimate remaining costs based on current usage patterns.
        
        Args:
            documents_analyzed: Number of documents already processed
            total_documents: Total documents in experiment
            synthesis_pending: Whether synthesis stage is still pending
            
        Returns:
            Cost estimation breakdown
        """
        current_costs = self.get_session_costs()
        
        if documents_analyzed == 0:
            return {
                "estimated_remaining_usd": 0.0,
                "estimated_total_usd": 0.0,
                "confidence": "low",
                "note": "No analysis completed yet - cannot estimate"
            }
        
        # Calculate per-document analysis cost
        analysis_operations = ["analysis", "document_processing", "framework_validation"]
        analysis_cost = sum(
            current_costs["operations"].get(op, {}).get("cost_usd", 0.0) 
            for op in analysis_operations
        )
        
        per_document_cost = analysis_cost / documents_analyzed if documents_analyzed > 0 else 0.0
        remaining_documents = total_documents - documents_analyzed
        estimated_analysis_remaining = per_document_cost * remaining_documents
        
        # Estimate synthesis cost (typically 10-20% of analysis cost)
        synthesis_cost_estimate = 0.0
        if synthesis_pending:
            if "synthesis" in current_costs["operations"]:
                # Use actual synthesis cost if we have it
                synthesis_cost_estimate = current_costs["operations"]["synthesis"]["cost_usd"]
            else:
                # Estimate as 15% of total analysis cost
                total_analysis_cost = analysis_cost + estimated_analysis_remaining
                synthesis_cost_estimate = total_analysis_cost * 0.15
        
        total_estimated_remaining = estimated_analysis_remaining + synthesis_cost_estimate
        total_estimated_experiment = current_costs["total_cost_usd"] + total_estimated_remaining
        
        return {
            "estimated_remaining_usd": round(total_estimated_remaining, 4),
            "estimated_total_usd": round(total_estimated_experiment, 4),
            "breakdown": {
                "remaining_analysis": round(estimated_analysis_remaining, 4),
                "estimated_synthesis": round(synthesis_cost_estimate, 4)
            },
            "confidence": "high" if documents_analyzed >= 3 else "medium",
            "per_document_cost": round(per_document_cost, 4)
        }
    
    def finalize_session(self) -> None:
        """Finalize the audit session and log completion."""
        end_time = self._get_timestamp()
        
        self._log_system_event("audit_session_end", {
            "session_id": self.session_id,
            "start_time": self.start_time,
            "end_time": end_time,
            "session_duration": self._calculate_duration(self.start_time, end_time)
        })
        
        print(f"📋 Audit session finalized: {self.session_id}")
    
    def _calculate_duration(self, start: str, end: str) -> float:
        """Calculate duration between timestamps in seconds."""
        try:
            start_dt = datetime.fromisoformat(start.replace('Z', '+00:00'))
            end_dt = datetime.fromisoformat(end.replace('Z', '+00:00'))
            return (end_dt - start_dt).total_seconds()
        except Exception:
            return 0.0
    
    # ========================================
    # VERBOSE TRACING SYSTEM (Phase 1)
    # ========================================
    
    def log_function_call(self, component: str, function_name: str, args: Dict[str, Any] = None, kwargs: Dict[str, Any] = None):
        """Log function call with parameters for verbose tracing."""
        if not self.verbose_trace:
            return
            
        # Get call stack for context
        stack = traceback.extract_stack()
        caller_frame = stack[-3] if len(stack) >= 3 else stack[-1]
        
        trace_entry = {
            "timestamp": self._get_timestamp(),
            "session_id": self.session_id,
            "event_type": "function_call",
            "component": component,
            "function": function_name,
            "caller": {
                "file": caller_frame.filename,
                "line": caller_frame.lineno,
                "function": caller_frame.name
            },
            "parameters": {
                "args": args or {},
                "kwargs": kwargs or {}
            }
        }
        
        self._append_to_log(self.trace_log, trace_entry)
        
        # Also print to console for immediate feedback
        print(f"🔍 TRACE: {component}.{function_name}() called from {caller_frame.filename}:{caller_frame.lineno}")
    
    def log_function_return(self, component: str, function_name: str, result: Any = None, duration: float = None):
        """Log function return with result for verbose tracing."""
        if not self.verbose_trace:
            return
            
        trace_entry = {
            "timestamp": self._get_timestamp(),
            "session_id": self.session_id,
            "event_type": "function_return",
            "component": component,
            "function": function_name,
            "result_type": type(result).__name__ if result is not None else "None",
            "duration_seconds": duration
        }
        
        # Include result summary for basic types
        if isinstance(result, (str, int, float, bool)):
            trace_entry["result_summary"] = str(result)[:100]
        elif isinstance(result, (list, dict)):
            trace_entry["result_summary"] = f"{type(result).__name__} with {len(result)} items"
        
        self._append_to_log(self.trace_log, trace_entry)
        
        # Also print to console for immediate feedback
        duration_str = f" ({duration:.3f}s)" if duration else ""
        print(f"🔍 TRACE: {component}.{function_name}() returned {trace_entry['result_type']}{duration_str}")
    
    def trace_calls(self, component: str = None):
        """
        Decorator for automatic function call/return tracing.
        
        Usage:
            @audit_logger.trace_calls("StatisticalAgent")
            def analyze_batch(self, ...):
                ...
        """
        def decorator(func: Callable) -> Callable:
            comp_name = component or func.__module__.split('.')[-1]
            
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                if not self.verbose_trace:
                    return func(*args, **kwargs)
                
                start_time = time.time()
                
                # Log function call
                self.log_function_call(
                    component=comp_name,
                    function_name=func.__name__,
                    args={f"arg_{i}": type(arg).__name__ for i, arg in enumerate(args)},
                    kwargs={k: type(v).__name__ for k, v in kwargs.items()}
                )
                
                try:
                    # Execute function
                    result = func(*args, **kwargs)
                    
                    # Log successful return
                    duration = time.time() - start_time
                    self.log_function_return(
                        component=comp_name,
                        function_name=func.__name__,
                        result=result,
                        duration=duration
                    )
                    
                    return result
                    
                except Exception as e:
                    # Log exception
                    duration = time.time() - start_time
                    trace_entry = {
                        "timestamp": self._get_timestamp(),
                        "session_id": self.session_id,
                        "event_type": "function_exception",
                        "component": comp_name,
                        "function": func.__name__,
                        "exception_type": type(e).__name__,
                        "exception_message": str(e),
                        "duration_seconds": duration
                    }
                    
                    self._append_to_log(self.trace_log, trace_entry)
                    print(f"🔍 TRACE: {comp_name}.{func.__name__}() raised {type(e).__name__}: {e}")
                    
                    raise
            
            return wrapper
        return decorator


def create_audit_logger(security_boundary: ExperimentSecurityBoundary, run_folder: Path) -> AuditLogger:
    """Create an audit logger instance."""
    return AuditLogger(security_boundary, run_folder) 