provider_defaults:
  vertex_ai:
    forbidden_params:
    - max_tokens
    required_params:
      safety_settings:
      - category: HARM_CATEGORY_HARASSMENT
        threshold: BLOCK_NONE
      - category: HARM_CATEGORY_HATE_SPEECH
        threshold: BLOCK_NONE
      - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
        threshold: BLOCK_NONE
      - category: HARM_CATEGORY_DANGEROUS_CONTENT
        threshold: BLOCK_NONE
    timeout: 180
  openai:
    forbidden_params:
    - max_tokens
    requires_pre_moderation: true
    timeout: 120
  anthropic:
    forbidden_params:
    - max_tokens
    timeout: 120
  mistral:
    forbidden_params:
    - max_tokens
    timeout: 120
  perplexity:
    forbidden_params:
    - max_tokens
    timeout: 120
    status: placeholder
  ollama:
    forbidden_params:
    - max_tokens
    timeout: 600
models:
  openrouter/perplexity/r1-1776:
    provider: openrouter
    performance_tier: specialized-reasoning
    context_window: 128000
    costs:
      input_per_million_tokens: 2.0
      output_per_million_tokens: 8.0
    utility_tier: 10
    task_suitability:
    - synthesis
    - validation
    tpm: 100000
    rpm: 100
    optimal_batch_size: 6
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
    notes: HEALTH CHECK FAILED (Empty Response). Requires investigation. Uncensored
      DeepSeek R1 fine-tune. Requires an OpenRouter API key.
  anthropic/claude-3-5-sonnet-20240620:
    provider: anthropic
    performance_tier: top-tier
    context_window: 200000
    costs:
      input_per_million_tokens: 3.0
      output_per_million_tokens: 15.0
    utility_tier: 1
    task_suitability:
    - synthesis
    - coordination
    - planning
    tpm: 40000
    rpm: 50
    optimal_batch_size: 8
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
    notes: Direct API access. Good for flexibility or if outside the GCP ecosystem.
  openai/gpt-4o:
    provider: openai
    performance_tier: top-tier
    context_window: 128000
    costs:
      input_per_million_tokens: 2.5
      output_per_million_tokens: 10.0
    utility_tier: 4
    task_suitability:
    - synthesis
    - code_interpreter
    tpm: 300000
    rpm: 5000
    optimal_batch_size: 6
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
  vertex_ai/gemini-2.5-pro:
    provider: vertex_ai
    performance_tier: top-tier
    context_window: 2000000
    costs:
      input_per_million_tokens: 1.25
      output_per_million_tokens: 10.0
    utility_tier: 3
    task_suitability:
    - synthesis
    - planning
    - code_interpreter
    tpm: 81920
    rpm: 800
    optimal_batch_size: 12
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
  vertex_ai/gemini-2.5-flash:
    provider: vertex_ai
    performance_tier: cost-effective
    context_window: 1000000
    costs:
      input_per_million_tokens: 0.3
      output_per_million_tokens: 2.5
    utility_tier: 5
    task_suitability:
    - code_generation
    - coordination
    tpm: 163840
    rpm: 800
    optimal_batch_size: 15
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
  anthropic/claude-3-haiku-20240307:
    provider: anthropic
    performance_tier: cost-effective
    context_window: 200000
    costs:
      input_per_million_tokens: 0.25
      output_per_million_tokens: 1.25
    utility_tier: 4
    task_suitability:
    - validation
    tpm: 25000
    rpm: 500
    optimal_batch_size: 10
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
  mistral/mistral-large-latest:
    provider: mistral
    performance_tier: local-fallback
    context_window: 32768
    costs:
      input_per_million_tokens: 2.0
      output_per_million_tokens: 6.0
    utility_tier: 98
    task_suitability:
    - synthesis
    tpm: 1000000
    rpm: 10000
    optimal_batch_size: 2
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
  ollama/jobautomation/OpenEuroLLM-Portuguese:
    provider: ollama
    performance_tier: local-specialized
    context_window: 8192
    costs:
      input_per_million_tokens: 0.0
      output_per_million_tokens: 0.0
    utility_tier: 97
    task_suitability:
    - synthesis
    tpm: 1000000
    rpm: 10000
    optimal_batch_size: 1
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
    notes: Portuguese language model. Context window is an assumption. The PDAF framework
      (~10k tokens) exceeds this model's context window. Use with extreme caution.
  ollama/mistral:
    provider: ollama
    performance_tier: local-general
    context_window: 32768
    costs:
      input_per_million_tokens: 0.0
      output_per_million_tokens: 0.0
    utility_tier: 3
    task_suitability:
    - development only
    tpm: 1000000
    rpm: 10000
    optimal_batch_size: 1
    timeout: 120
    last_updated: '2024-07-17'
    review_by: '2025-01-17'
    notes: 'Local Mistral 7B model. WARNING: Can be very slow with complex prompts.
      Consider using cloud models for production.'
  vertex_ai/claude-3-5-sonnet@20240620:
    provider: vertex_ai
    performance_tier: top-tier
    context_window: 200000
    costs:
      input_per_million_tokens: 3.0
      output_per_million_tokens: 15.0
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from vertex_ai
    auto_discovered: true
    regions:
      us-east5:
        tpm: 100000
        rpm: 100
      europe-west1:
        tpm: 100000
        rpm: 100
      asia-southeast1:
        tpm: 100000
        rpm: 100
  vertex_ai/claude-3-7-sonnet@20250219:
    provider: vertex_ai
    performance_tier: top-tier
    context_window: 200000
    costs:
      input_per_million_tokens: 3.0
      output_per_million_tokens: 15.0
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from vertex_ai
    auto_discovered: true
    regions:
      us-east5:
        tpm: 100000
        rpm: 100
      europe-west1:
        tpm: 100000
        rpm: 100
      global:
        tpm: 100000
        rpm: 100
  vertex_ai/claude-sonnet-4@20250514:
    provider: vertex_ai
    performance_tier: top-tier
    context_window: 200000
    costs:
      input_per_million_tokens: 3.0
      output_per_million_tokens: 15.0
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from vertex_ai
    auto_discovered: true
    regions:
      us-east5:
        tpm: 100000
        rpm: 100
      europe-west1:
        tpm: 100000
        rpm: 100
      asia-east1:
        tpm: 100000
        rpm: 100
      global:
        tpm: 100000
        rpm: 100
  perplexity/r1-1776:
    provider: openrouter
    performance_tier: general-purpose
    context_window: 128000
    costs:
      input_per_million_tokens: 2.0
      output_per_million_tokens: 8.0
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from openrouter
    auto_discovered: true
  mistralai/mistral-7b-instruct:
    provider: openrouter
    performance_tier: general-purpose
    context_window: 32768
    costs:
      input_per_million_tokens: 0.028
      output_per_million_tokens: 0.054
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from openrouter
    auto_discovered: true
  meta-llama/llama-3-8b-instruct:
    provider: openrouter
    performance_tier: general-purpose
    context_window: 8192
    costs:
      input_per_million_tokens: 0.03
      output_per_million_tokens: 0.06
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from openrouter
    auto_discovered: true
  meta-llama/llama-3-70b-instruct:
    provider: openrouter
    performance_tier: general-purpose
    context_window: 8192
    costs:
      input_per_million_tokens: 0.3
      output_per_million_tokens: 0.4
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from openrouter
    auto_discovered: true
  cohere/command-r-plus:
    provider: openrouter
    performance_tier: general-purpose
    context_window: 128000
    costs:
      input_per_million_tokens: 3.0
      output_per_million_tokens: 15.0
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from openrouter
    auto_discovered: true
  mistralai/mixtral-8x7b-instruct:
    provider: openrouter
    performance_tier: general-purpose
    context_window: 32768
    costs:
      input_per_million_tokens: 0.08
      output_per_million_tokens: 0.24
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from openrouter
    auto_discovered: true
  openai/gpt-4o-mini:
    provider: openai
    performance_tier: cost-effective
    context_window: 128000
    costs:
      input_per_million_tokens: 0.15
      output_per_million_tokens: 0.6
    utility_tier: 10
    task_suitability:
    - synthesis
    optimal_batch_size: 6
    last_updated: '2025-07-21'
    review_by: '2026-01-17'
    notes: Auto-discovered model from openai
    auto_discovered: true
